{"version":3,"file":"js/246.d6c4ddc5.js","mappings":"2GAAA,MAAMA,EAAc,EAAQ,OAE5BC,EAAOC,QAAUF,C,oBCFjB,MAAMG,EACJC,YAAaC,GACXC,KAAKC,MAAQF,GAAO,OAASF,EAAUK,MACzC,CAEAC,OAAQC,GACN,QAASA,GAASA,EAAMC,WAAaL,KAAKK,UAAYD,EAAMH,QAAUD,KAAKC,KAC7E,EAGFJ,EAAUS,UAAUD,SAAW,YAE/BR,EAAUK,OAAS,EAEnBP,EAAOC,QAAUC,C,wBCdjB,MAAMA,EAAY,EAAQ,OACpBU,EAAe,EAAQ,OACvBC,EAAc,EAAQ,OACtBC,EAAU,EAAQ,OAClBC,EAAY,EAAQ,OACpBC,EAAO,EAAQ,OACfC,EAAW,EAAQ,OAEzB,SAASC,EAAWZ,GAClB,OAAO,IAAIS,EAAUT,EACvB,CAEA,SAASa,EAAWb,GAClB,OAAO,IAAIJ,EAAUI,EACvB,CAEA,SAASc,EAASd,EAAOe,GACvB,MAAkC,kBAAvBA,GACgC,IAArCA,EAAmBC,QAAQ,KACtB,IAAIR,EAAQR,EAAOe,GAGrB,IAAIP,EAAQR,EAAO,KAAMP,EAAYmB,UAAUG,IAGjD,IAAIP,EAAQR,EAAO,KAAMe,EAClC,CAEA,SAASE,EAAUjB,GACjB,OAAO,IAAIW,EAASX,EACtB,CAEA,SAASkB,IACP,OAAOzB,EAAY0B,oBACrB,CAEA,SAASC,EAAQC,EAASC,EAAWC,GACnC,OAAO9B,EAAY+B,KAAKH,EAASC,EAAWC,EAC9C,CAEA,SAASC,EAAMH,EAASC,EAAWC,EAAQE,GACzC,OAAO,IAAIf,EAAKW,EAASC,EAAWC,EAAQE,GAAShC,EAAY0B,qBACnE,CAEA,SAASO,EAAUC,GACjB,OAAOpB,EAAYqB,KAAKnC,EAAakC,EACvC,CAEA,SAASE,EAAUF,GACjB,OAAOpB,EAAYqB,KAAKnC,EAAakC,EACvC,CAEA,MAAMlC,EAAc,CAClBmB,YACAC,YACAC,UACAG,WACAC,eACAE,SACAI,OACAE,WACAG,WACAV,qBAAsB,IAAIb,GAG5BZ,EAAOC,QAAUF,C,oBCjEjB,MAAMa,EACJJ,OAAQC,GACN,QAASA,GAASA,EAAMC,WAAaL,KAAKK,QAC5C,EAGFE,EAAaD,UAAUD,SAAW,eAClCE,EAAaD,UAAUL,MAAQ,GAE/BN,EAAOC,QAAUW,C,wBCTjB,MAAMG,EAAY,EAAQ,OAE1B,MAAMD,EACJX,YAAaG,EAAO8B,EAAUC,GAC5BhC,KAAKC,MAAQA,EACbD,KAAKgC,SAAWvB,EAAQwB,eACxBjC,KAAK+B,SAAW,GAEZA,GACF/B,KAAK+B,SAAWA,EAChB/B,KAAKgC,SAAWvB,EAAQyB,oBACfF,IACThC,KAAKgC,SAAWA,EAEpB,CAEA7B,OAAQC,GACN,QAASA,GAASA,EAAMC,WAAaL,KAAKK,UAAYD,EAAMH,QAAUD,KAAKC,OACzEG,EAAM2B,WAAa/B,KAAK+B,UAAY3B,EAAM4B,SAAS7B,OAAOH,KAAKgC,SACnE,EAGFvB,EAAQH,UAAUD,SAAW,UAE7BI,EAAQyB,mBAAqB,IAAIxB,EAAU,yDAC3CD,EAAQwB,eAAiB,IAAIvB,EAAU,2CAEvCf,EAAOC,QAAUa,C,oBC3BjB,MAAMC,EACJZ,YAAaqC,GACXnC,KAAKC,MAAQkC,CACf,CAEAhC,OAAQC,GACN,QAASA,GAASA,EAAMC,WAAaL,KAAKK,UAAYD,EAAMH,QAAUD,KAAKC,KAC7E,EAGFS,EAAUJ,UAAUD,SAAW,YAE/BV,EAAOC,QAAUc,C,wBCZjB,MAAMH,EAAe,EAAQ,OAE7B,MAAMI,EACJb,YAAawB,EAASC,EAAWC,EAAQE,GACvC1B,KAAKsB,QAAUA,EACftB,KAAKuB,UAAYA,EACjBvB,KAAKwB,OAASA,EAGZxB,KAAK0B,MADHA,GAGW,IAAInB,CAErB,CAEAJ,OAAQC,GAEN,QAASA,IAA6B,SAAnBA,EAAMC,WAAwBD,EAAMC,WACrDD,EAAMkB,QAAQnB,OAAOH,KAAKsB,UAAYlB,EAAMmB,UAAUpB,OAAOH,KAAKuB,YAClEnB,EAAMoB,OAAOrB,OAAOH,KAAKwB,SAAWpB,EAAMsB,MAAMvB,OAAOH,KAAK0B,MAChE,EAGFf,EAAKL,UAAUD,SAAW,OAC1BM,EAAKL,UAAUL,MAAQ,GAEvBN,EAAOC,QAAUe,C,oBC1BjB,MAAMC,EACJd,YAAasC,GACXpC,KAAKC,MAAQmC,CACf,CAEAjC,OAAQC,GACN,QAASA,GAASA,EAAMC,WAAaL,KAAKK,UAAYD,EAAMH,QAAUD,KAAKC,KAC7E,EAGFW,EAASN,UAAUD,SAAW,WAE9BV,EAAOC,QAAUgB,C,oBCZjB,SAASe,EAAUC,GACjB,IAAKA,EACH,OAAO,KAGT,GAA0B,cAAtBA,EAASvB,SACX,OAAOL,KAAKc,UAAUc,EAAS3B,OAGjC,GAA0B,iBAAtB2B,EAASvB,SACX,OAAOL,KAAKmB,eAGd,GAA0B,YAAtBS,EAASvB,SACX,OAAOL,KAAKe,QAAQa,EAAS3B,MAAO2B,EAASG,UAAY/B,KAAKa,UAAUe,EAASI,SAAS/B,QAG5F,GAA0B,cAAtB2B,EAASvB,SACX,OAAOL,KAAKa,UAAUe,EAAS3B,OAGjC,GAA0B,SAAtB2B,EAASvB,SAAqB,CAChC,MAAMiB,EAAUtB,KAAK2B,SAASC,EAASN,SACjCC,EAAYvB,KAAK2B,SAASC,EAASL,WACnCC,EAASxB,KAAK2B,SAASC,EAASJ,QAChCE,EAAQ1B,KAAK2B,SAASC,EAASF,OAErC,OAAO1B,KAAKyB,KAAKH,EAASC,EAAWC,EAAQE,EAC/C,CAEA,GAA0B,aAAtBE,EAASvB,SACX,OAAOL,KAAKkB,SAASU,EAAS3B,OAGhC,MAAM,IAAIoC,MAAM,oBAAoBT,EAASvB,WAC/C,CAEAV,EAAOC,QAAU+B,C,wBCrCjB,MAAMW,EAAO,EAAQ,OACfC,EAAe,EAAQ,OAE7B,MAAMC,UAAeF,EACnBxC,YAAa2C,GACXC,MAAMH,EAAcE,EACtB,EAGF9C,EAAOC,QAAU4C,C,wBCTjB,MAAMG,EAAM,EAAQ,QACd,aAAEC,GAAiB,EAAQ,QAC3B,UAAEC,GAAc,EAAQ,OAExBC,EAAsB,QAE5B,SAASC,EAAaC,GACpB,OAAOC,GACiB,cAAlBA,EAAK5C,SACA,KAGJ4C,EAAKhD,MAAMiD,WAAWJ,GAKpBE,EAAQnC,UAAUoC,EAAKhD,MAAMkD,MAAML,EAAoBM,SAJrD,IAMb,CAEA,SAASC,EAAaL,GACpB,MAAMM,EAAUP,EAAYC,GAE5B,OAAOvB,IACL,MAAMH,EAAUgC,EAAQ7B,EAAKH,SACvBC,EAAY+B,EAAQ7B,EAAKF,WACzBC,EAAS8B,EAAQ7B,EAAKD,QACtBE,EAAQ4B,EAAQ7B,EAAKC,OAE3B,OAAIJ,GAAWC,GAAaC,GAAUE,EAC7BsB,EAAQvB,KACbH,GAAWG,EAAKH,QAChBC,GAAaE,EAAKF,UAClBC,GAAUC,EAAKD,OACfE,GAASD,EAAKC,OAIXD,EAEX,CAEA,MAAMc,EACJzC,YAAayD,GAAO,QAAEC,EAAUV,EAAmB,QAAEW,EAAU,KAAI,QAAET,EAAUL,GAAQ,CAAC,GACtF,MAAMe,EAAS,IAAId,EAAa,CAC9BY,UACAC,UACAE,YAAaX,EACbY,kBAAkB,IAGpBL,EAAMM,KAAKH,GAEX,MAAMJ,EAAUD,EAAYL,GAEtBc,EAAY,IAAIjB,EAAU,CAC9BkB,YAAY,EACZD,UAAW,CAACrC,EAAMuC,EAAUC,KAC1BA,EAAS,KAAMX,EAAQ7B,GAAK,IAYhC,OARAiC,EAAOQ,GAAG,WAAWT,IACnBU,OAAOC,QAAQX,GAASY,SAAQ,EAAEC,EAAQnC,MACxC2B,EAAUS,KAAK,SAAUD,EAAQtB,EAAQnC,UAAUsB,GAAI,GACxD,IAEHuB,EAAOQ,GAAG,SAASM,GAAOV,EAAUW,QAAQD,KAC5Cd,EAAOG,KAAKC,GAELA,CACT,EAGFnE,EAAOC,QAAU2C,C,oBC3EjB,MAAMD,EACJxC,YAAa4E,EAAMjC,GACjBzC,KAAK0E,KAAOA,EACZ1E,KAAKyC,QAAUA,CACjB,CAEAkC,OAAQpB,EAAOd,GACb,MAAMmC,EAAS,IAAI5E,KAAK0E,KAAKnB,EAAOY,OAAOU,OAAO,CAAC,EAAG7E,KAAKyC,QAASA,IAYpE,OAVAc,EAAMW,GAAG,OAAO,KACTU,EAAOE,UACVF,EAAOL,KAAK,MACd,IAGFhB,EAAMW,GAAG,SAAUM,IACjBI,EAAOL,KAAK,QAASC,EAAG,IAGnBI,CACT,EAGFjF,EAAOC,QAAU0C,C,qCCtBjB,IAAIyC,EAAmB/E,MAAQA,KAAK+E,kBAAqBZ,OAAOa,OAAS,SAAUC,EAAGC,EAAGC,EAAGC,QAC7EC,IAAPD,IAAkBA,EAAKD,GAC3BhB,OAAOmB,eAAeL,EAAGG,EAAI,CAAEG,YAAY,EAAMC,IAAK,WAAa,OAAON,EAAEC,EAAI,GACnF,EAAI,SAAUF,EAAGC,EAAGC,EAAGC,QACTC,IAAPD,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,EACb,GACGM,EAAgBzF,MAAQA,KAAKyF,cAAiB,SAASP,EAAGtF,GAC1D,IAAK,IAAI8F,KAAKR,EAAa,YAANQ,GAAoBvB,OAAO7D,UAAUqF,eAAe9D,KAAKjC,EAAS8F,IAAIX,EAAgBnF,EAASsF,EAAGQ,EAC3H,EACAvB,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDwF,EAAa,EAAQ,OAAuB7F,E,mCCX5CuE,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQgG,iBAAc,EAOtB,MAAMA,EACF9F,cACIE,KAAK6F,SAAW,CAAC,CACrB,CACAC,WAAWC,GACP,GAAIA,EAAK3C,OAAS,EAAG,CACjB,MAAO4C,KAASC,GAAQF,EAClBG,EAAUlG,KAAK6F,SAASG,GAC9B,GAAIE,EAAS,CACT,MAAMC,EAAaD,EAAQJ,WAAWG,GACtC,GAAIE,EACA,OAAOA,EAAWC,MAAK,EAAG3C,UAAS4C,YAAY,CAAG5C,UAAS4C,MAAOA,EAAQ,KAElF,CACJ,CACA,OAAOrG,KAAKyD,QAAUzD,KAAKyD,QAAQ2C,MAAM3C,IAAY,CAAGA,UAAS4C,MAAO,MAAQ,IACpF,CACAC,WAAWP,EAAMtC,GACb,GAAoB,IAAhBsC,EAAK3C,OACLpD,KAAKyD,QAAUA,MAEd,CACD,MAAOuC,KAASC,GAAQF,EACxB,IAAIG,EAAUlG,KAAK6F,SAASG,GACvBE,IACDA,EAAUlG,KAAK6F,SAASG,GAAQ,IAAIJ,GAExCM,EAAQI,WAAWL,EAAMxC,EAC7B,CACJ,CACA8C,cAAcC,GACVxG,KAAKsG,WAAWE,EAAM,KAC1B,EAEJ5G,EAAQgG,YAAcA,C,qCC1CtBzB,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQgD,kBAAe,EAEvB,MAAMJ,EAAS,EAAQ,MACjBiE,EAA0B,EAAQ,OAClCC,EAAW,EAAQ,OACnBC,EAA2B,EAAQ,OACnCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,OACxCC,EAA0B,EAAQ,OAClCC,EAA+B,EAAQ,OACvCC,EAA6B,EAAQ,OACrCC,EAA0B,EAAQ,OAClCC,EAAgC,EAAQ,OACxCC,EAA4B,EAAQ,OACpCC,EAA4B,EAAQ,OACpCC,EAAuC,EAAQ,OAC/CC,EAA6B,EAAQ,OACrCC,EAAmB,EAAQ,OAC3BC,EAAS,EAAQ,OACjBC,EAAqB,EAAQ,OAInC,MAAM7E,UAAqB8D,EAAS7D,UAChC/C,YAAY2C,GACRC,MAAM,CAAEgF,oBAAoB,IAC5BjF,EAAUA,GAAW,CAAC,EACtBzC,KAAKyC,QAAUA,EACfzC,KAAK2H,eAAiB,IAAIJ,EAAiBK,eAAezD,OAAOU,OAAO,CAAEnB,OAAQ1D,MAAQyC,IAC1FzC,KAAK6H,KAAO,IAAIL,EAAOM,KAAK,CAAEnE,YAAalB,EAAQkB,YAAagE,eAAgB3H,KAAK2H,iBACrF3H,KAAK+H,WAAa,IAAIvF,EACtBxC,KAAKgI,YAAc,GACnBhI,KAAKiI,SAAW,GAChBjI,KAAKkI,oBAAsB,GAC3BlI,KAAKmI,UAAY,EACjBnI,KAAKoI,SAAW,GAChBpI,KAAKqI,eAAiBC,QAAQC,UAC9BvI,KAAKwI,4BACLxI,KAAKkE,GAAG,OAAO,KACyB,qBAAzBlE,KAAK+H,WAAWU,MACvBzI,KAAKuE,KAAK,QAAS,IAAIlC,MAAM,qBACjC,GAER,CAgBAqG,wBAAwBlF,EAASmF,EAAWC,EAASnG,GACjD,IAAIgB,EA0BAG,EAxBJ,GAAkB,wBAAd+E,EAAqC,CAErC,GAAkB,qBAAdA,IAAqCA,EAAUE,SAAS,SACxD,MAAM,IAAIpC,EAAwBqC,WAAW,kCAAkCH,IAAalC,EAAwBsC,YAAYC,yBAgBpI,GAbIJ,GAAWA,EAAQK,IAAI,SACvBL,EAAQvE,SAAQ,CAACpE,EAAOiJ,KACpB,GAAY,SAARA,EAAgB,CAChB,MAAMC,EAAa1B,EAAmB2B,MAAMnJ,GAC5C,IAAK,MAAMoJ,KAAQF,EAAW3D,IAAI,MAAO,wCAAyC,CAC9E,GAAI/B,EACA,MAAM,IAAIgD,EAAwBqC,WAAW,uDAAyDtF,EAASiD,EAAwBsC,YAAYO,+BAEvJ7F,EAAU4F,EAAKE,GACnB,CACJ,MAGH9F,KAAyB,OAAZhB,QAAgC,IAAZA,OAAqB,EAASA,EAAQ+G,gCACxE,MAAM,IAAI/C,EAAwBqC,WAAW,8CAA8CH,QAAgBnF,IAAWiD,EAAwBsC,YAAYC,wBAElK,CAGA,GAAIJ,GAAWA,EAAQK,IAAI,gBAAiB,CACxC,MAAMQ,EAAcb,EAAQpD,IAAI,gBAC1BkE,EAAQ,qBAAqBC,KAAKF,GACpCC,GAAsB,2CAAbA,EAAM,KACf9F,GAAmB,EAE3B,CACA,OAAO,IAAIhB,EAAauB,OAAOU,OAAO,CAAErB,UACpCC,UACAG,oBAAoBnB,GAAoB,CAAC,GACjD,CAMAkC,OAAOiF,GACH,MAAMhF,EAAS,IAAI8B,EAASmD,YAAY,CAAEnC,oBAAoB,IAC9DkC,EAAO1F,GAAG,SAAU4F,GAAUC,EAAOxF,KAAK,QAASuF,KACnDF,EAAO1F,GAAG,QAAS8F,GAASpF,EAAOqF,KAAKD,KACxCJ,EAAO1F,GAAG,OAAO,IAAMU,EAAOqF,KAAK,QACnC,MAAMF,EAASnF,EAAOf,KAAK,IAAIjB,EAAa5C,KAAKyC,UACjD,OAAOsH,CACX,CACAG,WAAWC,EAAOnG,EAAUC,GACxBjE,KAAK+H,WAAWqC,MAAMD,GACtBnK,KAAKqI,eACAjC,MAAK,IAAMnC,MAAa6F,GAAU7F,EAAS6F,IACpD,CAYAO,oBAAoBtE,EAAM9F,EAAOoG,EAAOiE,GACpC,IAAIC,GAAc,EAGlB,GAAID,GAAkBjE,EAAQrG,KAAKmI,UAAW,CAE1C,MAAMqC,EAAcxK,KAAK2H,eAAe8C,iBAAiBzK,KAAKmI,WAC1DqC,IAEIA,EAAYvK,OACZD,KAAKuE,KAAK,OAAQvE,KAAK6H,KAAKlE,YAAYlC,KAAK+I,EAAYvK,MAAOD,KAAK6H,KAAK6C,QAAS1K,KAAK6H,KAAK8C,OAAQ3K,KAAK6H,KAAK+C,oBAGnHJ,EAAYK,OAAOC,UAAW,EAC9B9K,KAAK2H,eAAeoD,QAAQP,EAAYQ,cAAgB,GAAK,CAACR,EAAYK,QAC1E7K,KAAK2H,eAAe8C,iBAAiBQ,OAAOjL,KAAKmI,UAAW,UAItDvB,EAAwBsE,sBAAsBC,6BAA6BnL,KAAK2H,eAAgB3H,KAAKoI,SAAUpI,KAAKmI,YAC1HnI,KAAK2H,eAAeyD,6BACfnB,KAAK,CAAE5D,MAAOrG,KAAKmI,UAAWpC,KAAM/F,KAAKoI,SAASjF,MAAM,EAAGnD,KAAKoI,SAAShF,UAC9EmH,GAAc,SAGRvK,KAAKqL,YAAYrL,KAAKmI,UAAWnI,KAAKoI,SAEpD,CACA,MAAMc,QAAYlJ,KAAK6H,KAAKyD,eAAevF,EAAKM,GAAQN,EAAMM,GACxDkF,QAAkBvL,KAAK6H,KAAK2D,qBAAqBzF,EAAMM,GAC7DrG,KAAK2H,eAAe8D,aAAapF,IAAS,EAC1C,IAAIqF,GAAY,EAEZjF,EAAwBqB,KAAK6D,eAAezC,IAAsB,aAAdqC,GAAoC,aAARrC,GAChFlJ,KAAKuE,KAAK,QAAS,IAAIkC,EAAwBqC,WAAW,kBAAkB7I,iCAAsCwG,EAAwBsC,YAAY6C,+BAI1J,IAAIC,GAAa,EACb7L,KAAK2H,eAAemE,gBAAgB1I,OAAS,IAC7CyI,EAAa7L,KAAK2H,eAAemE,gBAAgB9L,KAAK2H,eAAemE,gBAAgB1I,OAAS,GAAG2I,UAErG,IAAK,IAAIC,EAAIC,KAAKC,IAAI,EAAGlM,KAAK2H,eAAemE,gBAAgB1I,OAAS,GAAI4I,EAAIjG,EAAK3C,OAAS,EAAG4I,IAAK,CAChG,MAAMG,EAAmBnM,KAAK2H,eAAemE,gBAAgBE,KACrDhM,KAAK2H,eAAemE,gBAAgBE,SAAWhM,KAAKoM,YAAYrG,EAAK5C,MAAM,EAAG6I,EAAI,GAAIA,EAAGH,IACjG,IAAKM,EAAiBE,MAAO,CACzBrM,KAAK2H,eAAe8D,aAAapF,IAAS,EAC1CqF,GAAY,EACZ,KACJ,EACUG,GAAcM,EAAiBJ,WACrCF,GAAa,EAErB,CAMA,GAJI7L,KAAK6H,KAAKyE,UAAUjG,KACpBqF,GAAY,GAGZA,EACA,IAAK,MAAMa,KAAgB3J,EAAa4J,eAAgB,CACpD,MAAMC,QAAmBF,EAAaG,KAAK1M,KAAK2H,eAAgB3H,KAAK6H,KAAMqB,EAAKnD,EAAMM,GACtF,GAAIoG,EAAY,OAENF,EAAaI,OAAO3M,KAAK2H,eAAgB3H,KAAK6H,KAAMqB,EAAKnD,EAAM9F,EAAOoG,EAAOoG,GAE/EF,EAAaK,qBACb5M,KAAK2H,eAAekF,gBAAgBxG,IAAS,GAEjD,KACJ,CACJ,CAGU,IAAVA,GAAeyG,MAAMC,QAAQ9M,UACvBD,KAAK6H,KAAKmF,qBAAqB/M,GAGrCsK,GAAelE,EAAQrG,KAAKmI,WAE5BnI,KAAKuK,YAAYvK,KAAKmI,WAE1BnI,KAAKmI,UAAY9B,EACjBrG,KAAKoI,SAAWrC,EAEhB/F,KAAK2H,eAAesF,2BAA2BhC,OAAO5E,EAAQ,EAClE,CAKAkE,YAAYlE,GACRrG,KAAK2H,eAAekF,gBAAgB5B,OAAO5E,EAAO,GAClDrG,KAAK2H,eAAeuF,eAAejC,OAAO5E,EAAO,GACjDrG,KAAK2H,eAAe8D,aAAaR,OAAO5E,EAAO,GAC/CrG,KAAK2H,eAAeoD,QAAQE,OAAO5E,EAAO,GAC1CrG,KAAK2H,eAAewF,WAAWlC,OAAO5E,EAAQ,EAAG,GACjDrG,KAAK2H,eAAeyF,wBAAwBnC,OAAO5E,EAAO,GAC1DrG,KAAK2H,eAAe0F,iBAAiBpC,OAAO5E,EAAO,GACnDrG,KAAK2H,eAAemE,gBAAgBb,OAAO5E,EAAQ,EAAG,GACtDrG,KAAK2H,eAAe2F,aAAarC,OAAO5E,EAAOrG,KAAK2H,eAAe2F,aAAalK,OAASiD,EAE7F,CAUAgE,kBAAkBhE,EAAON,GACrB,IAAIwH,EAAWvN,KAAK2H,eAAeoD,QAAQ1E,GACtCkH,IACDA,EAAWvN,KAAK2H,eAAeoD,QAAQ1E,GAAS,CAACrG,KAAK6H,KAAKlE,YAAY7C,cAG3E,MAAM0M,EAAcxN,KAAK2H,eAAe8F,yBAAyBpH,GACjE,GAAImH,EAAa,CACb,IAAK,MAAMlM,KAAWiM,EAAU,CAC5B,MAAMG,QAAyB1N,KAAK6H,KAAK8F,oBAAoBtH,EAAON,GAC9D6H,EAAU5N,KAAK2H,eAAewF,WAAW9G,IAAUqH,GAAoB,EACvE1N,KAAK2H,eAAeoD,QAAQ1E,EAAQqH,EAAmB,GACvD,OAAO1N,KAAK6H,KAAKgG,uBAAuB9H,EAAMM,IACpD,GAAIuH,EACA,IAAK,MAAMlM,KAASkM,EAAQ,CAExB5N,KAAK2H,eAAe8D,aAAapF,IAAS,EAC1C,IAAK,MAAMyH,KAAiBN,EACpBM,EAAcC,QACd/N,KAAK2H,eAAeqG,SAAS3H,EAAOrG,KAAK6H,KAAKlE,YAAYlC,KAAKqM,EAActM,OAAQsM,EAAcvM,UAAWD,EAASI,IAGvH1B,KAAK2H,eAAeqG,SAAS3H,EAAOrG,KAAK6H,KAAKlE,YAAYlC,KAAKH,EAASwM,EAAcvM,UAAWuM,EAActM,OAAQE,GAGnI,KAEC,CAED,MAAMuM,EAAiBjO,KAAK2H,eAAeuG,+BAA+B7H,QAAcrG,KAAK6H,KAAK8F,oBAAoBtH,EAAON,GAAQ,GACrI,IAAK,MAAM+H,KAAiBN,EACpBM,EAAcC,QACdE,EAAehE,KAAK,CAChBzI,OAAQF,EACRC,UAAWuM,EAAcvM,UACzBD,QAASwM,EAActM,SAI3ByM,EAAehE,KAAK,CAChBzI,OAAQsM,EAActM,OACtBD,UAAWuM,EAAcvM,UACzBD,WAIhB,CACJ,CACAtB,KAAK2H,eAAe8F,yBAAyBxC,OAAO5E,EAAO,GAC3DrG,KAAK2H,eAAe2F,aAAarC,OAAO5E,EAAO,GAC/CrG,KAAK2H,eAAe0F,iBAAiBpC,OAAO5E,EAAO,EACvD,CAEA,MAAM8H,EAAcnO,KAAK2H,eAAeyG,yBAAyB/H,GACjE,GAAI8H,EAAa,CACb,IAAK,MAAM7M,KAAWiM,EAAU,CAI5B,MAAM7L,EAAkB,IAAV2E,GAAoC,cAArB/E,EAAQjB,UAC7BL,KAAK2H,eAAe0G,mBAAmD/M,EAA9BtB,KAAK6H,KAAK+C,kBAC3D5K,KAAK2H,eAAe8D,aAAapF,IAAS,EAC1C,IAAK,MAAMyH,KAAiBK,EACxBnO,KAAK2H,eAAeqG,SAAS3H,EAAOrG,KAAK6H,KAAKlE,YAAYlC,KAAKqM,EAAcxM,QAASwM,EAAcvM,UAAWuM,EAActM,OAAQE,GAE7I,CACA1B,KAAK2H,eAAeyG,yBAAyBnD,OAAO5E,EAAO,EAC/D,CACJ,CAQAgE,kBAAkBtE,EAAMM,EAAOwF,GAC3B,IAAK,MAAMU,KAAgB3J,EAAa4J,eACpC,SAAUD,EAAa+B,SAAStO,KAAK2H,eAAgB3H,KAAK6H,KAAM9B,EAAMM,EAAOwF,GACzE,MAAO,CAAEQ,OAAO,EAAMN,SAAUF,GAAcU,EAAagC,qBAGnE,MAAO,CAAElC,OAAO,EAAON,UAAU,EACrC,CAMAvD,4BAEIxI,KAAK+H,WAAWyG,QAAWvO,IACvB,MAAMoG,EAAQrG,KAAK+H,WAAW0G,MAAMrL,OAC9B2C,EAAQ,IAAI+G,MAAMzG,EAAQ,GAAGqI,KAAK,GAAIC,KAAI,CAACC,EAAG5C,IACzCA,IAAM3F,EAAQrG,KAAK+H,WAAWmB,IAAMlJ,KAAK+H,WAAW0G,MAAMzC,GAAG9C,MAExE,IAAKlJ,KAAK6O,sBAAsBxI,GAAQ,CACpC,MAAMyI,EAAa,IAAM9O,KAAK+O,cAAchJ,EAAM9F,EAAOoG,GAAO,GAChE,GAAKrG,KAAK2H,eAAe/D,kBACjB5D,KAAK2H,eAAeqH,YAAYlJ,WAAWC,EAAK5C,MAAM,GAAI,IAwB9DnD,KAAKqI,eAAiBrI,KAAKqI,eAAejC,KAAK0I,QAlB/C,GAAoB,aAAhB/I,EAAKM,GAAuB,CAC5B,IAAI4I,EAAOjP,KAAKgI,YAAY3B,GACvB4I,IACDA,EAAOjP,KAAKgI,YAAY3B,GAAS,IAErC4I,EAAKhF,KAAK6E,EACd,KACyB,UAAhB/I,EAAKM,IACgB,kBAAhBN,EAAKM,IAA2C,UAApBN,EAAKM,EAAQ,GAEnDrG,KAAKiI,SAASgC,KAAK,CAAEiF,IAAKJ,EAAY/I,KAAMA,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,KAGxEpD,KAAKkI,oBAAoB+B,KAAK,CAAEiF,IAAKJ,EAAY/I,SAQpD/F,KAAK2H,eAAe/D,kBAA8B,IAAVyC,IACzCrG,KAAKqI,eAAiBrI,KAAKqI,eACtBjC,MAAK,IAAMpG,KAAKmP,wBAE7B,GAEJnP,KAAK+H,WAAWqH,QAAWtF,IACvB9J,KAAKuE,KAAK,QAASuF,EAAM,CAEjC,CAMA+E,sBAAsBxI,GAClB,IAAK,IAAI2F,EAAI3F,EAAO2F,EAAI,EAAGA,IACvB,GAAyC,aAArChM,KAAK+H,WAAW0G,MAAMzC,EAAI,GAAG9C,IAC7B,OAAO,EAGf,OAAO,CACX,CAKAmB,4BAEI,IAAK,MAAM4E,KAAQjP,KAAKgI,YACpB,GAAIiH,EACA,IAAK,MAAMC,KAAOD,QACRC,IAKlBlP,KAAK2H,eAAesF,2BAA2BhC,OAAO,GAEtD,IAAK,MAAMiE,KAAOlP,KAAKkI,oBAAqB,CAGxC,GAAIlI,KAAKiI,SAAS7E,OAAS,EAAG,CAE1B,MAAMiM,EAAqB,GACrBC,EAAuB,GAC7B,IAAK,IAAItD,EAAI,EAAGA,EAAIhM,KAAKiI,SAAS7E,OAAQ4I,IAAK,CAC3C,MAAMuD,EAAUvP,KAAKiI,SAAS+D,GAC1BxE,EAAOM,KAAK0H,cAAcD,EAAQxJ,KAAMmJ,EAAInJ,QAC5CsJ,EAAmBpF,KAAKsF,GACxBD,EAAqBrF,KAAK+B,GAElC,CAEA,MAAMyD,EAAiBJ,EAAmBK,MAAK,CAACC,EAAMC,IAASD,EAAK5J,KAAK3C,OAASwM,EAAK7J,KAAK3C,SAE5F,IAAK,MAAMmM,KAAWE,QACZF,EAAQL,MAIlB,MAAMW,EAA6BP,EAAqBI,OAAO3B,UAC/D,IAAK,MAAM+B,KAASD,EAChB7P,KAAKiI,SAASgD,OAAO6E,EAAO,EAEpC,OACMZ,EAAIA,KACd,CACJ,EAEJtP,EAAQgD,aAAeA,EACvBA,EAAamN,wBAA0B,MACvCnN,EAAa4J,eAAiB,CAC1B,IAAI7F,EAAyBqJ,uBAC7B,IAAIjJ,EAA6BkJ,2BACjC,IAAIhJ,EAAwBiJ,sBAC5B,IAAIhJ,EAA8BiJ,4BAClC,IAAInJ,EAA2BoJ,yBAC/B,IAAIjJ,EAA0BkJ,wBAC9B,IAAIjJ,EAA0BkJ,wBAC9B,IAAIhJ,EAA2BiJ,yBAC/B,IAAI3J,EAAwBsE,sBAC5B,IAAI7D,EAAqCmJ,mCACzC,IAAI1J,EAAwB2J,sBAC5B,IAAI5J,EAA8B6J,4B,qCClctCvM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQgI,oBAAiB,EACzB,MAAMnB,EAA0B,EAAQ,OAClCkK,EAAe,EAAQ,OACvBC,EAAgB,EAAQ,OACxBC,EAAiB,EAAQ,OAI/B,MAAMjJ,EACF9H,YAAY2C,GAERzC,KAAK8Q,cAAgB,IAAIrK,EAAwBsK,cAAc,CAAEC,eAAgBvO,EAAQuO,eAAgBC,eAAgBxO,EAAQyO,wBACjIlR,KAAK4D,mBAAqBnB,EAAQmB,iBAClC5D,KAAKwD,QAAUf,EAAQe,QACvBxD,KAAKmR,wBAA0B1O,EAAQ0O,sBACvCnR,KAAKoR,mBAAqB3O,EAAQ2O,iBAClCpR,KAAKqR,eAAiB5O,EAAQ4O,gBAAkBR,EAAejO,aAAamN,wBAC5E/P,KAAKsR,eAAiB7O,EAAQ6O,aAC9BtR,KAAKgN,uBAAyBvK,EAAQuK,qBACtChN,KAAKmB,aAAesB,EAAQtB,aAC5BnB,KAAKuR,aAAe9O,EAAQ8O,aAC5BvR,KAAKwR,sBAAwB/O,EAAQ+O,sBACrCxR,KAAKyR,yCAA2ChP,EAAQgP,yCACxDzR,KAAKqO,oBAAqB,EAC1BrO,KAAK0R,qBAAuBC,WAAW3R,KAAKqR,gBAE5CrR,KAAK6M,gBAAkB,GACvB7M,KAAKkN,eAAiB,GACtBlN,KAAKyL,aAAe,GACpBzL,KAAK+K,QAAU,GACf/K,KAAKmN,WAAa,GAClBnN,KAAKoN,wBAA0B,GAC/BpN,KAAKyK,iBAAmB,GACxBzK,KAAKgP,YAAc,IAAI4B,EAAchL,YACrC5F,KAAKsN,aAAe,GACpBtN,KAAK8L,gBAAkB,GACvB9L,KAAKiN,2BAA6B,GAClCjN,KAAKqN,iBAAmB,GACxBrN,KAAKyN,yBAA2B,GAChCzN,KAAKoO,yBAA2B,GAChCpO,KAAKoL,6BAA+B,GACpCpL,KAAK0D,OAASjB,EAAQiB,OAClBjB,EAAQgB,SACRzD,KAAK4R,YAAc5R,KAAK6R,aAAapP,EAAQgB,SAC7CzD,KAAK4R,YAAYxL,MAAM3C,GAAYzD,KAAK8R,gBAAgBrO,MAGxDzD,KAAK4R,YAActJ,QAAQC,QAAQ,IAAI9B,EAAwBsL,wBAAwB/R,KAAKwD,QAAU,CAAE,QAASxD,KAAKwD,QAAS,mBAAmB,GAAS,CAAC,GAEpK,CAQA6G,mBAAmB5G,EAASuO,EAAeC,GACvC,OAAOjS,KAAK8Q,cAAc1H,MAAM3F,EAAS,CACrCD,QAASxD,KAAKwD,QACdyO,mBACAT,sBAAuBxR,KAAKwR,sBAC5BQ,gBACAX,eAAgBrR,KAAK0R,sBAE7B,CAMAI,gBAAgBrO,GACZ,MAAMyO,EAAgBzO,EAAQ0O,gBAAgB,YAC9C,GAAID,EAAe,CACf,GAAIlS,KAAK0R,sBAAwBQ,EAAgBlS,KAAK0R,qBAClD,MAAM,IAAIf,EAAa7H,WAAW,gCAAgCoJ,mCAA+ClS,KAAK0R,wBAAyBf,EAAa5H,YAAYqJ,0BAGxK,GAAIpS,KAAK0R,sBAAwBQ,EAAgBlS,KAAK0R,qBAClD,MAAM,IAAIf,EAAa7H,WAAW,2BAA2BoJ,kCAA8ClS,KAAK0R,wBAAyBf,EAAa5H,YAAYsJ,uBAEtKrS,KAAK0R,qBAAuBQ,CAEpC,CACJ,CAOA7H,iBAAiBtE,EAAMuM,EAAS,GAC5B,MAAMC,EAAexM,EAErB,MAAwC,kBAA1BA,EAAKA,EAAK3C,OAAS,GAC7B2C,EAAOA,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,GAGnCkP,IACAvM,EAAOA,EAAK5C,MAAM,GAAImP,IAG1B,MAAME,QAAoBxS,KAAKyS,2BAA2B1M,GACpDtC,EAAU+O,EAAY/O,QAE5B,IAAIiP,EAAajP,EAAQ0O,gBACzB,IAAK,IAAInG,EAAIwG,EAAYnM,MAAO2F,EAAIuG,EAAanP,OAASkP,EAAQtG,IAAK,CACnE,MAAM9C,EAAMqJ,EAAavG,GACnB2G,EAAkBD,EAAWxJ,GACnC,GAAIyJ,GAA8C,kBAApBA,GAAgC,aAAcA,EAAiB,CACzF,MAAMC,SAAuB5S,KAAK6R,aAAac,EAAiBD,GAAY,IAAOP,gBAC7EU,IAAc3J,KAAO0J,IACpBA,EAAc1J,GAAK,YAAY,eACpB,IAAd2J,GAAuB7G,IAAMuG,EAAanP,OAAS,EAAIkP,IACvDI,EAAaE,SAENF,EAAW,cAClBA,EAAWxJ,GAAO/E,OAAOU,OAAO,CAAC,EAAG6N,EAAWxJ,IAC3C,QAASyJ,IACTD,EAAWxJ,GAAK,OAASyJ,EAAgB,eAEtCD,EAAWxJ,GAAK,aACL,IAAd2J,GACA7S,KAAKgP,YAAY1I,WAAWiM,EAAapP,MAAM,EAAG6I,EAAIsG,GAAShK,QAAQC,QAAQ,IAAI9B,EAAwBsL,wBAAwBW,KAG/I,CACJ,CACA,OAAO,IAAIjM,EAAwBsL,wBAAwBW,EAC/D,CAaArI,iCAAiCtE,GAC7B,MAAM+M,EAAgB/M,EAAK3C,OAC3B,IACI2P,EADAP,EAAc,KAElB,EAAG,CACCO,GAAqC,EACjCP,GAAe,yBAA0BA,EAAY/O,QAAQ0O,gBAG7DK,EAAY/O,QAAU,IAAIgD,EAAwBsL,wBAAwBS,EAAY/O,QAAQ0O,gBAAgB,0BAG1GK,IAIAzM,EAAOA,EAAK5C,MAAM,EAAGqP,EAAYnM,MAAQ,IAE7CmM,QAAoBxS,KAAKgP,YAAYlJ,WAAWC,IAAS,CAAEtC,cAAezD,KAAK4R,YAAavL,MAAO,IAKvG,MAAM2M,EAAUjN,EAAKA,EAAK3C,OAAS,GACnC,GAAI4P,KAAWR,EAAY/O,QAAQ0O,gBAAiB,CAChD,MAAMc,EAAeT,EAAY/O,QAAQ0O,gBAAgBa,GACrDC,GAAwC,kBAAjBA,GAA6B,aAAcA,IAClEF,GAAqC,EAE7C,CACJ,OAASP,EAAYnM,MAAQ,IACgC,IAAtDmM,EAAY/O,QAAQ0O,gBAAgB,eACpCK,EAAYnM,QAAUyM,IACrBC,GAQR,OAL0B,IAAtBP,EAAYnM,QAC6C,IAAtDmM,EAAY/O,QAAQ0O,gBAAgB,eACpCK,EAAYnM,QAAUyM,IACzBN,EAAY/O,QAAU,IAAIgD,EAAwBsL,wBAAwB,CAAC,IAExES,CACX,CASAnI,oBAAoBtE,EAAM9F,EAAOoG,EAAOiE,SAC9BtK,KAAK0D,OAAOqL,cAAchJ,EAAM9F,EAAOoG,EAAOiE,EACxD,CAKAD,2CACI,GAAIrK,KAAKoL,6BAA6BhI,OAAS,EAAG,CAC9C,IAAK,MAAM8P,KAAsBlT,KAAKoL,mCAC5BpL,KAAK0D,OAAO2H,YAAY6H,EAAmB7M,MAAO6M,EAAmBnN,MAC3E/F,KAAK0D,OAAO6G,YAAY2I,EAAmB7M,OAG/C,OADArG,KAAKoL,6BAA6BH,OAAO,EAAGjL,KAAKoL,6BAA6BhI,SACvE,CACX,CAEI,OAAO,CAEf,CAMA4K,SAAS3H,EAAO5E,GACE,IAAV4E,IACArG,KAAKqO,oBAAqB,GAE9BrO,KAAK0D,OAAOuG,KAAKxI,EACrB,CAKA0R,UAAUrJ,GACN9J,KAAK0D,OAAOa,KAAK,QAASuF,EAC9B,CAKAsJ,YAAY3P,GACRzD,KAAK0D,OAAOa,KAAK,UAAWd,EAChC,CAOA4P,+BAA+BhN,GAC3B,IAAIiN,EAAStT,KAAKyN,yBAAyBpH,GAK3C,OAJKiN,IACDA,EAAS,GACTtT,KAAKyN,yBAAyBpH,GAASiN,GAEpCA,CACX,CAOApF,+BAA+B7H,GAC3B,IAAIiN,EAAStT,KAAKoO,yBAAyB/H,GAK3C,OAJKiN,IACDA,EAAS,GACTtT,KAAKoO,yBAAyB/H,GAASiN,GAEpCA,CACX,CAIAC,mBACI,OAAO3L,EAAe4L,eAAexT,KAAK0R,qBAC9C,CAUA+B,WAAWpN,EAAOqN,GAEd,MAAMC,EAAgB3T,KAAK+K,QAAQ1E,EAAQqN,GAO3C,GANIC,IACA3T,KAAK+K,QAAQ1E,GAASsN,EACtB3T,KAAKyL,aAAapF,IAAS,SACpBrG,KAAK+K,QAAQ1E,EAAQqN,IAG5B1T,KAAKoL,6BAA6BhI,OAClC,IAAK,MAAMkQ,KAAUtT,KAAKoL,6BAClBkI,EAAOjN,OAASA,EAAQqN,IACxBJ,EAAOjN,OAASqN,EAChBJ,EAAOvN,KAAKkF,OAAO5E,EAAOqN,IAKlC1T,KAAKyN,yBAAyBpH,EAAQqN,KACtC1T,KAAKyN,yBAAyBpH,GAASrG,KAAKyN,yBAAyBpH,EAAQqN,UACtE1T,KAAKyN,yBAAyBpH,EAAQqN,GAGrD,EAEJ9T,EAAQgI,eAAiBA,EACzBA,EAAe4L,eAAiB,CAC5B,EAAK,CACDI,oBAAoB,EACpBC,yBAAyB,EACzBC,0BAA0B,GAE9B,IAAK,CACDF,oBAAoB,EACpBC,yBAAyB,EACzBC,0BAA0B,G,qCC7TlC3P,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQkI,UAAO,EACf,MAAMrB,EAA0B,EAAQ,OAClCsN,EAAqB,EAAQ,OAC7BnN,EAA0B,EAAQ,OAElCoN,EAAmB,EAAQ,OAIjC,MAAMlM,EACFhI,YAAY2C,GACRzC,KAAK2H,eAAiBlF,EAAQkF,eAC9B3H,KAAK2D,YAAclB,EAAQkB,aAAe,IAAIoQ,EAAmBrU,YACjEM,KAAKiU,SAAWjU,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,SACtDlU,KAAK0K,QAAU1K,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,QACrDlU,KAAK2K,OAAS3K,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,OACpDlU,KAAKmU,QAAUnU,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,QACrDlU,KAAKoU,QAAUpU,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,OACzD,CAYAxL,uBAAuBjF,EAAS4Q,EAAYnL,EAAKoL,GAC7C,MAAMC,EAAQ9Q,EAAQ0O,gBAAgBjJ,GACtC,IAAKqL,EACD,OAAOD,EAEX,MAAME,EAAOD,EAAMF,GACnB,YAAgBhP,IAATmP,EAAqBF,EAAWE,CAC3C,CAYA9L,gCAAgCjF,EAASyF,GACrC,OAAOpB,EAAK2M,gBAAgBhR,EAAS,aAAcyF,EAAK,CAAE,QAAQ,GACtE,CAOAR,2BAA2BjF,EAASyF,GAChC,MAAMwL,EAAY5M,EAAK2M,gBAAgBhR,EAAS,QAASyF,EAAK,MAC9D,MAAkB,UAAdwL,EACO,KAEJA,CACX,CAOAhM,+BAA+BjF,EAASyF,GACpC,OAAOpB,EAAK2M,gBAAgBhR,EAAS,YAAayF,EAAKzF,EAAQ0O,gBAAgB,cAAgB,KACnG,CAOAzJ,gCAAgCjF,EAASyF,GACrC,OAAOpB,EAAK2M,gBAAgBhR,EAAS,aAAcyF,EAAKzF,EAAQ0O,gBAAgB,eAAiB,KACrG,CAOAzJ,6BAA6BjF,EAASyF,GAClC,QAASpB,EAAK2M,gBAAgBhR,EAAS,WAAYyF,EAAK,KAC5D,CAOAR,4BAA4BjF,EAASyF,GACjC,OAAOpB,EAAK2M,gBAAgBhR,EAAS,SAAUyF,EAAKzF,EAAQ0O,gBAAgB,WAAa,KAC7F,CAQAzJ,yBAAyBjF,EAASyF,EAAKqC,GAEnC,MAAqB,aAAdA,IAA6BzD,EAAK6M,sBAAsBlR,EAASyF,EAC5E,CAMAR,kBAAkBvG,GACd,OAAe,OAARA,GAAgBsE,EAAwBqB,KAAK8M,WAAWzS,EACnE,CAMAuG,qBAAqBmM,EAAQC,GACzB,GAAID,EAAOzR,OAAS0R,EAAS1R,OACzB,OAAO,EAEX,IAAK,IAAI4I,EAAI,EAAGA,EAAI6I,EAAOzR,OAAQ4I,IAC/B,GAAI6I,EAAO7I,KAAO8I,EAAS9I,GACvB,OAAO,EAGf,OAAO,CACX,CAOA3B,2BAA2BpK,GACvB,GAAID,KAAK2H,eAAeqF,qBAAsB,CAC1C,MAAM+H,EAAc,CAAC,EACrB,IAAK,MAAMR,KAAStU,EAChB,GAAIsU,GAA0B,kBAAVA,EAAoB,CACpC,MAAMxU,EAAKwU,EAAM,OACXS,EAAQT,EAAM,UACpB,GAAIxU,GAAMiV,EAAO,CACb,MAAMC,EAAqBF,EAAYhV,GACvC,GAAIkV,GAAsBA,IAAuBD,EAC7C,MAAM,IAAIvO,EAAwBqC,WAAW,gCAAgC/I,IAAM0G,EAAwBsC,YAAYmM,qBAE3HH,EAAYhV,GAAMiV,CACtB,CACJ,CAER,CACJ,CAUA3K,kBAAkB5G,EAASyF,EAAKjJ,EAAOoG,EAAON,GAE1C,GAA+C,UAA3C+B,EAAKqN,oBAAoB1R,EAASyF,GAClC,MAAO,CAAClJ,KAAK2D,YAAY5C,QAAQf,KAAKoV,kBAAkBnV,GAAQD,KAAKoU,UAEzE,MAAMI,SAAcvU,EACpB,OAAQuU,GACJ,IAAK,SAED,GAAc,OAAVvU,QAA4BoF,IAAVpF,EAClB,MAAO,GAGX,GAAI6M,MAAMC,QAAQ9M,GAGd,MAAI,UAAW6H,EAAKuN,yBAAyB5R,EAASyF,GAC7B,IAAjBjJ,EAAMmD,OACC,CAACpD,KAAK2K,QAGN3K,KAAK2H,eAAeoD,QAAQ1E,EAAQ,IAAM,UAGnDrG,KAAKgN,qBAAqB/M,GACzB,IAUX,GAPAwD,QAAgBzD,KAAKsV,+BAA+B7R,EAASyF,GAEzD,aAAcjJ,IACdwD,QAAgBzD,KAAK2H,eAAekK,aAAa5R,EAAM,mBAAoBD,KAAK2H,eAAe7B,WAAWC,EAAM,IAAIoM,kBAGxHlS,QAAcD,KAAKuV,gBAAgBtV,EAAO8F,EAAMM,EAAO5C,GACnD,WAAYxD,EAAO,CACnB,IAAIuV,EACAC,EACAC,EACAhB,EACAiB,EACJ,IAAKzM,KAAOjJ,EAAO,CACf,MAAM2V,EAAW3V,EAAMiJ,GACvB,OAAQA,GACJ,IAAK,SACDsM,EAAMI,EACN,MACJ,IAAK,YACDH,EAAgBG,EAChB,MACJ,IAAK,aACDF,EAAiBE,EACjB,MACJ,IAAK,QACDlB,EAAYkB,EACZ,MACJ,IAAK,SACDD,EAAaC,EACb,MACJ,QACI,MAAM,IAAInP,EAAwBqC,WAAW,wBAAwBI,iBAAmB2M,KAAKC,UAAU7V,KAAUwG,EAAwBsC,YAAYgN,sBAEjK,CAEA,GAAyE,gBAA/D/V,KAAKsL,eAAeoJ,EAAW3O,EAAMM,GAAO,EAAM5C,GACxD,MAAO,CAACzD,KAAK2D,YAAY5C,QAAQf,KAAKoV,kBAAkBI,GAAMxV,KAAKoU,UAGvE,GAAY,OAARoB,EACA,MAAO,GAEX,GAAmB,kBAARA,EACP,MAAM,IAAI/O,EAAwBqC,WAAW,uDAAuD+M,KAAKC,UAAUN,MAAS/O,EAAwBsC,YAAYiN,4BAGpK,GAAIhW,KAAK2H,eAAeqF,sBAAwB2I,GAAoC,kBAAfA,EACjE,MAAM,IAAIlP,EAAwBqC,WAAW,mDAAmD+M,KAAKC,UAAUH,MAAgBlP,EAAwBsC,YAAYkN,qBAGvK,GAAIR,EAAe,CACf,GAAmB,kBAARD,EACP,MAAM,IAAI/O,EAAwBqC,WAAW,4EAA4E+M,KAAKC,UAAUN,MAAS/O,EAAwBsC,YAAYmN,+BAEzL,IAAKzP,EAAwBsK,cAAcoF,iBAAiBV,EAAezV,KAAK2H,eAAe2J,aAAc7K,EAAwBsC,YAAYqN,gCAC7I,MAAO,IAGPpW,KAAK2H,eAAe6J,uBAAsE,IAA7CxR,KAAK2H,eAAe+J,wBACjE+D,EAAgBA,EAAcY,cAEtC,CACA,GAAIX,EAAgB,CAChB,GAAmB,kBAARF,EACP,MAAM,IAAInT,MAAM,6EAA6EwT,KAAKC,UAAUN,OAEhH,IAAK/O,EAAwBsK,cAAcuF,kBAAkBZ,EAAgB1V,KAAK2H,eAAe2J,cAC7F,MAAO,EAEf,CAEA,GAAImE,GAAiBC,GAAkB1V,KAAK2H,eAAe4J,aAAc,CACrE,GAAImD,EACA,MAAM,IAAIjO,EAAwBqC,WAAW,mEAAmE+M,KAC3GC,UAAU7V,MAAWwG,EAAwBsC,YAAYgN,sBAElE,OAAO/V,KAAKuW,oBAAoBvW,KAC3BwW,+BAA+BnQ,EAAOmP,EAAKC,EAAeC,GACnE,CACK,GAAID,EAAe,CACpB,GAAIf,EACA,MAAM,IAAIjO,EAAwBqC,WAAW,0DAA0D+M,KAAKC,UAAU7V,MAAWwG,EAAwBsC,YAAYgN,sBAEzK,MAAO,CAAC/V,KAAK2D,YAAY5C,QAAQyU,EAAKC,GAC1C,CACK,GAAIC,GAAkB1V,KAAK2H,eAAe4J,aAAc,CACzD,GAAImD,EACA,MAAM,IAAIjO,EAAwBqC,WAAW,2DAA2D+M,KAAKC,UAAU7V,MAAWwG,EAAwBsC,YAAYgN,sBAE1K,OAAO/V,KAAKuW,oBAAoBvW,KAC3BwW,+BAA+BnQ,EAAOmP,EAAKC,EAAeC,GACnE,CACK,GAAIhB,EAAW,CAChB,GAAyB,kBAAdA,EACP,MAAM,IAAIjO,EAAwBqC,WAAW,kDAAkD+M,KAAKC,UAAUpB,MAAejO,EAAwBsC,YAAY0N,qBAErK,MAAMC,EAAW1W,KAAK2W,sBAAsBlT,EAASiR,GACrD,IAAKgC,EACD,MAAM,IAAIjQ,EAAwBqC,WAAW,+BAA+B+M,KAAKC,UAAUpB,MAAejO,EAAwBsC,YAAY0N,qBAElJ,GAA0B,cAAtBC,EAASrW,SACT,MAAM,IAAIoG,EAAwBqC,WAAW,uBAAuB4N,EAASrW,cAAcqU,IAAajO,EAAwBsC,YAAY0N,qBAEhJ,MAAO,CAACzW,KAAK2D,YAAY5C,QAAQyU,EAAKkB,GAC1C,CAEA,aAAa1W,KAAK4W,YAAY,IAAInQ,EAAwBsL,wBAAwB,CAAC,GAAI7I,EAAKsM,EAAKnP,EAAON,EAC5G,CACK,GAAI,SAAU9F,EAAO,CAEtB,GAAIkE,OAAO4B,KAAK9F,GAAOmD,OAAS,EAC5B,MAAM,IAAIqD,EAAwBqC,WAAW,6DAA6DI,KAAQzC,EAAwBsC,YAAY8N,4BAG1J,MAAO,EACX,CACK,GAAI,UAAW5W,EAAO,CAEvB,GAAIkE,OAAO4B,KAAK9F,GAAOmD,OAAS,EAC5B,MAAM,IAAIqD,EAAwBqC,WAAW,8DAA8DI,KAAQzC,EAAwBsC,YAAY8N,4BAE3J,MAAMC,EAAY7W,EAAM,SAGxB,OAAI6M,MAAMC,QAAQ+J,GACW,IAArBA,EAAU1T,OACH,CAACpD,KAAK2K,QAGN3K,KAAK2H,eAAeoD,QAAQ1E,EAAQ,IAAM,SAKxCrG,KAAK4W,kBAAkB5W,KAAK2H,eAAe7B,WAAWC,GAAOmD,EAAK4N,EAAWzQ,EAAQ,EAAGN,EAAK5C,MAAM,GAAI,GAE5H,CACK,GAAI,aAAclD,GAAsC,mBAAtBA,EAAM,YAGzC,MAAO,GAEN,GAAI,WAAY6H,EAAKuN,+BAA+BrV,KAAK2H,eAAe7B,WAAWC,GAAOmD,GAAM,CAEjG,MAAM6N,EAAwB/W,KAAK2H,eAAeyF,wBAAwB/G,EAAQ,GAClF,OAAO0Q,EAAwB5S,OAAO6S,OAAOD,GAAyB,CAAC/W,KAAK2D,YAAY7C,YAC5F,CACK,MAAI,QAASb,GAEVkE,OAAO4B,KAAK9F,GAAOmD,OAAS,IAC5BK,QAAgBzD,KAAK2H,eAAe7B,WAAWC,EAAM,IAGrD,aAAc9F,IACdwD,QAAgBzD,KAAK2H,eAAekK,aAAa5R,EAAM,YAAawD,EAAQ0O,kBAEzD,WAAnBlS,EAAM,SACCD,KAAKuW,oBAAoBvW,KAAK2W,sBAAsBlT,EAASxD,EAAM,SAGnED,KAAKuW,oBAAoBvW,KAAKiX,eAAexT,EAASxD,EAAM,UAKnED,KAAK2H,eAAe8D,aAAapF,EAAQ,IACrCpG,GAA0B,kBAAVA,GAAoD,IAA9BkE,OAAO4B,KAAK9F,GAAOmD,OACrDpD,KAAK2H,eAAeoD,QAAQ1E,EAAQ,KACpCrG,KAAK2H,eAAeoD,QAAQ1E,EAAQ,GAAK,CAACrG,KAAK2D,YAAY7C,cAG5D,GAGnB,IAAK,SACD,OAAOd,KAAKuW,oBAAoBvW,KAAKkX,kBAAkB7Q,QAAarG,KAAKsV,+BAA+B7R,EAASyF,GAAMA,EAAKjJ,EAAO,OACvI,IAAK,UACD,OAAOD,KAAKuW,oBAAoBvW,KAAKkX,kBAAkB7Q,QAAarG,KAAKsV,+BAA+B7R,EAASyF,GAAMA,EAAKiO,QAAQlX,GAAOmX,WAAYpX,KAAK2D,YAAY9C,UAAUiH,EAAKuP,eAC3L,IAAK,SACD,OAAOrX,KAAKuW,oBAAoBvW,KAAKkX,kBAAkB7Q,QAAarG,KAAKsV,+BAA+B7R,EAASyF,GAAMA,EAAKjJ,EAAOD,KAAK2D,YAAY9C,UAAUZ,EAAQ,IAAM,GAAKA,EAAQ,KAAO6H,EAAKwP,YAAcxP,EAAKyP,cAC5N,QAEI,OADAvX,KAAK2H,eAAewL,UAAU,IAAI9Q,MAAM,yCAAyCmS,MAC1E,GAEnB,CAUAnK,qCAAqC5G,EAASyF,GAC1C,MAAMyJ,EAAkBlP,EAAQ0O,gBAAgBjJ,GAIhD,OAHIyJ,GAA8C,kBAApBA,GAAgC,aAAcA,IACxElP,QAAgBzD,KAAK2H,eAAekK,aAAac,EAAiBlP,EAAQ0O,iBAAiB,IAExF1O,CACX,CAKA8S,oBAAoBtT,GAChB,OAAOA,EAAO,CAACA,GAAQ,EAC3B,CAQAuU,gBAAgB/T,EAASyF,GACrB,MAAMuO,EAAWhU,EAAQiU,WAAWxO,GAAK,EAAMlJ,KAAK2H,eAAe4L,oBAEnE,OAAKkE,EAIe,MAAhBA,EAAS,IAA8B,MAAhBA,EAAS,GAC5BzX,KAAK2H,eAAewJ,sBACbnR,KAAK2D,YAAY7C,UAAU2W,EAASE,OAAO,IAG3C,KAIX7P,EAAK8M,WAAW6C,GACTzX,KAAK2D,YAAY9C,UAAU4W,GAG9BA,GAAYzX,KAAK2H,eAAe2J,cAChCtR,KAAK2H,eAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,0BAA0B2O,IAAYhR,EAAwBsC,YAAY6O,sBAMhJ,MAHQ,KApBJ,IAwBf,CAQAX,eAAexT,EAASyF,GACpB,GAAIA,EAAIhG,WAAW,MACf,OAAOlD,KAAK2D,YAAY7C,UAAUoI,EAAIyO,OAAO,IAEjD,MAAMxV,EAAMsB,EAAQiU,WAAWxO,GAAK,EAAOlJ,KAAK2H,eAAe4L,oBAC/D,IAAKzL,EAAK8M,WAAWzS,GAAM,CACvB,IAAIA,IAAOnC,KAAK2H,eAAe2J,aAI3B,OAAO,KAHPtR,KAAK2H,eAAewL,UAAU,IAAI9Q,MAAM,yBAAyBF,KAKzE,CACA,OAAOnC,KAAK2D,YAAY9C,UAAUsB,EACtC,CASAwU,sBAAsBlT,EAASyF,GAC3B,GAAIA,EAAIhG,WAAW,MACf,OAAOlD,KAAK2D,YAAY7C,UAAUoI,EAAIyO,OAAO,IAEjD,MAAME,EAAgB7X,KAAK2H,eAAe4L,mBAC1C,IAAIkE,EAAWhU,EAAQiU,WAAWxO,GAAK,EAAM2O,GAI7C,GAHIJ,IAAavO,IACbuO,EAAWhU,EAAQiU,WAAWxO,GAAK,EAAO2O,KAEzC/P,EAAK8M,WAAW6C,GAAW,CAC5B,IAAIA,IAAYzX,KAAK2H,eAAe2J,cAAiBmG,EAASvU,WAAW,KAIrE,OAAO,KAHPlD,KAAK2H,eAAewL,UAAU,IAAI9Q,MAAM,qBAAqBoV,KAKrE,CACA,OAAOzX,KAAK2D,YAAY9C,UAAU4W,EACtC,CAOAK,YAAY7X,EAAO+B,GACf,GAAqB,kBAAV/B,EAAoB,CAC3B,GAAI8X,OAAOC,SAAS/X,GAAQ,CACxB,MAAMgY,EAAYhY,EAAQ,IAAM,EAChC,OAAIgY,GAAejW,GAAYA,EAAS/B,QAAU6H,EAAKyP,WAI5CtX,EAAMiY,cAAc,IAAIC,QAAQ,aAAc,OAH9CJ,OAAO9X,GAAOmX,UAK7B,CAEI,OAAOnX,EAAQ,EAAI,MAAQ,MAEnC,CAEI,OAAOA,CAEf,CAUAiX,kBAAkB7Q,EAAO5C,EAASyF,EAAKjJ,EAAOmY,GAE1C,MAAMC,EAAcvQ,EAAKqN,oBAAoB1R,EAASyF,GACtD,GAAImP,EACA,GAAoB,QAAhBA,GACA,IAAKD,EACD,OAAOpY,KAAKiX,eAAexT,EAASzD,KAAK8X,YAAY7X,EAAOmY,SAG/D,GAAoB,WAAhBC,GACL,IAAKD,EACD,OAAOpY,KAAK2W,sBAAsBlT,EAASzD,KAAK8X,YAAY7X,EAAOmY,SAIvEA,EAAkBpY,KAAK2D,YAAY9C,UAAUwX,GAIrD,IAAKD,EAAiB,CAClB,MAAME,EAAkBxQ,EAAKyQ,wBAAwB9U,EAASyF,GACxDsP,EAAmB1Q,EAAK2Q,yBAAyBhV,EAASyF,GAChE,OAAIsP,GAAoBxY,KAAK2H,eAAe4J,aACjCvR,KAAKwW,+BAA+BnQ,EAAOrG,KAAK8X,YAAY7X,EAAOmY,GAAkBE,EAAiBE,GAGtGxY,KAAK2D,YAAY5C,QAAQf,KAAK8X,YAAY7X,EAAOmY,GAAkBE,EAElF,CAEA,OAAOtY,KAAK2D,YAAY5C,QAAQf,KAAK8X,YAAY7X,EAAOmY,GAAkBA,EAC9E,CAUA5B,+BAA+BnQ,EAAOpG,EAAO8B,EAAU2W,GACnD,GAAyC,kBAArC1Y,KAAK2H,eAAe4J,aAKpB,OAHKxP,IACDA,EAAW,IAER/B,KAAK2D,YAAY5C,QAAQd,EAAOD,KAAK2D,YAAY9C,UAAU,8BAA8BkB,KAAY2W,MAE3G,CAED,MAAMC,EAAY3Y,KAAK2D,YAAY7C,YAC7BY,EAAQ1B,KAAK4K,kBAMnB,OALA5K,KAAK2H,eAAeqG,SAAS3H,EAAOrG,KAAK2D,YAAYlC,KAAKkX,EAAW3Y,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,SAAUlU,KAAK2D,YAAY5C,QAAQd,GAAQyB,IAClJK,GACA/B,KAAK2H,eAAeqG,SAAS3H,EAAOrG,KAAK2D,YAAYlC,KAAKkX,EAAW3Y,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,YAAalU,KAAK2D,YAAY5C,QAAQgB,GAAWL,IAEhK1B,KAAK2H,eAAeqG,SAAS3H,EAAOrG,KAAK2D,YAAYlC,KAAKkX,EAAW3Y,KAAK2D,YAAY9C,UAAUiH,EAAKoM,IAAM,aAAclU,KAAK2D,YAAY5C,QAAQ2X,GAAYhX,IACvJiX,CACX,CACJ,CAMAvD,kBAAkBnV,GACd,OAAO+T,EAAiB/T,EAC5B,CAYAoK,qBAAqBnB,EAAKnD,EAAMM,EAAOuS,EAAcnV,GAEjD,GAAIsU,OAAOE,UAAU/O,GACjB,OAAOA,EAGX,IAAK0P,EAAc,CACf,MAAMC,EAAyB7Y,KAAK2H,eAAesF,2BAA2B5G,GAC9E,GAAIwS,EACA,OAAOA,CAEf,CACA,IAAKpS,EAAwBqB,KAAKgR,mBAAmB5P,GAAM,CACvDzF,EAAUA,SAAiBzD,KAAK2H,eAAe7B,WAAWC,GAC1D,IAAIgT,EAAWtV,EAAQ0O,gBAAgBjJ,GACnC6P,GAAgC,kBAAbA,IACnBA,EAAWA,EAAS,QAEpBtS,EAAwBqB,KAAK6D,eAAeoN,KAC5C7P,EAAM6P,EAEd,CACA,OAAOH,EAAe1P,EAAOlJ,KAAK2H,eAAesF,2BAA2B5G,GAAS6C,CACzF,CAQAmB,2BAA2BtE,EAAMM,GAC7B,aAAarG,KAAKsL,eAAejF,EAAQ,GAAKN,EAAKM,EAAQ,GAAIN,EAAMM,EAAQ,EACjF,CAUAgE,sBAAsB2O,EAAMjT,EAAMM,EAAO5C,GACrC,MAAMwV,EAAU,CAAC,EACjB,IAAK,MAAM/P,KAAO8P,EACdC,QAAcjZ,KAAKsL,eAAepC,EAAKnD,EAAMM,EAAQ,GAAG,EAAM5C,IAAYuV,EAAK9P,GAEnF,OAAO+P,CACX,CASA3M,UAAUjG,GACN,IAAK,IAAI2F,EAAI3F,EAAO2F,GAAK,EAAGA,IACxB,GAAIhM,KAAK2H,eAAe2F,aAAatB,IAAMhM,KAAK2H,eAAe0F,iBAAiBrB,GAC5E,OAAO,EAGf,OAAO,CACX,CAQA3B,0BAA0BhE,EAAON,GAC7B,IAAK,IAAIiG,EAAI3F,EAAQ,EAAG2F,EAAI,EAAGA,IAC3B,GAAoD,iBAA1ChM,KAAKsL,eAAevF,EAAKiG,GAAIjG,EAAMiG,GAAiB,CAE1D,MAAMkN,SAAoBtS,EAAwBsE,sBAAsBiO,oBAAoBnZ,KAAK2H,eAAgB5B,EAAMiG,IAAIkN,WAC3H,OAAItS,EAAwBsE,sBAAsBkO,wBAAwBF,IAC9D,EAEL7S,EAAQ2F,EAAI,CACvB,CAEJ,OAAQ,CACZ,CAMAqN,uBAAuB/X,GACnB,GAAyB,YAArBA,EAAQjB,SACR,MAAM,IAAIoG,EAAwBqC,WAAW,8CAA8CxH,EAAQrB,QAASwG,EAAwBsC,YAAYuQ,+BAExJ,CAKA1O,kBACI,OAAO5K,KAAK2H,eAAexG,cAAgBnB,KAAK2D,YAAYxC,cAChE,CAOAkJ,6BAA6BtE,EAAMM,GAE/B,IAAI3E,EAAQ1B,KAAK4K,kBAEjB,MAAM,WAAEsO,EAAY7S,MAAOkT,SAAyB3S,EAAwBsE,sBACvEiO,oBAAoBnZ,KAAK2H,eAAgB5B,EAAMM,GACpD,GAAI,WAAY6S,EAAY,CAExB,MAAMM,EAAsB5S,EAAwBsE,sBAAsBuO,uBAAuBP,EAAYK,EAAgBxT,GACvHwO,EAAQvU,KAAK2H,eAAeyF,wBAAwBmM,GAG1D,GAFA7X,EAAQ6S,EAAQA,EAAMiF,GAAuB,MAExC9X,EAAO,CACR,IAAIgY,EAAU,KACd,GAAI,QAASR,EAAY,CACrB,MAAMS,QAAqB3Z,KAAK4Z,gBAAgB7T,EAAKwT,GAAiBxT,EAAMwT,GACvD,OAAjBI,IACAD,QAAgB1Z,KAAKiX,qBAAqBjX,KAAK2H,eAAe7B,WAAWC,GAAO4T,GAExF,CACKD,IACDA,EAAU1Z,KAAK2D,YAAY7C,aAE1Bd,KAAK2H,eAAeyF,wBAAwBmM,KAC7CvZ,KAAK2H,eAAeyF,wBAAwBmM,GAAkB,CAAC,GAEnE7X,EAAQ1B,KAAK2H,eAAeyF,wBAAwBmM,GAAgBC,GAAuBE,CAC/F,CACJ,CACA,OAAOhY,CACX,CAeA2I,yBAAyBtE,EAAMM,GAC3B,IAAIwT,EAAiBxT,EACrB,IAAK,IAAI2F,EAAI3F,EAAQ,EAAG2F,EAAI,EAAGA,IAC3B,GAAuB,kBAAZjG,EAAKiG,GAAiB,CAC7B,MAAMT,QAAkBvL,KAAKsL,eAAevF,EAAKiG,GAAIjG,EAAMiG,GAC3D,GAAkB,aAAdT,EACA,OAAOS,EAEN,GAAkB,UAAdT,EAIL,OAAOsO,EAHPA,EAAiB7N,CAKzB,CAEJ,OAAO6N,CACX,CASAxP,sBAAsBnB,EAAKnD,EAAMM,GAC7B,MAAMsT,QAAqB3Z,KAAKsL,eAAepC,EAAKnD,EAAMM,GAC1D,MAAwB,UAAjBsT,EAA2B,KAAOA,CAC7C,EAEJ/Z,EAAQkI,KAAOA,EACfA,EAAKgS,IAAM,oCACXhS,EAAKuP,YAAcvP,EAAKgS,IAAM,UAC9BhS,EAAKwP,YAAcxP,EAAKgS,IAAM,UAC9BhS,EAAKyP,WAAazP,EAAKgS,IAAM,SAC7BhS,EAAKoM,IAAM,6C,mCC5xBX/P,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQma,gCAA6B,EAOrC,MAAMA,EACFC,sBACI,OAAO,CACX,CACA3P,aAAa6O,EAAYvR,EAAgBE,EAAM9B,EAAM9F,EAAOoG,GACxD,IAAItG,EAEJ,GAAI4H,EAAe8D,aAAapF,EAAQ,IAAMsB,EAAeoD,QAAQ1E,EAAQ,GAEzEtG,EAAK4H,EAAeoD,QAAQ1E,EAAQ,GAAG,OAEtC,CAED,MAAMsT,QAAqB9R,EAAK+R,gBAAgB7T,EAAKM,GAAQN,EAAMM,GAC7D4T,EAA2B,OAAjBN,QACJ9R,EAAKoP,qBAAqBtP,EAAe7B,WAAWC,GAAOA,EAAKM,IACtEwB,EAAKlE,YAAY7C,YAEvB,IAAKmZ,EAED,YADAtS,EAAe8D,aAAapF,IAAS,GAGzCtG,EAAKka,EAELtS,EAAeoD,QAAQ1E,EAAQ,GAAK,CAACtG,EACzC,CAGA,IAAIma,EAAMvS,EAAeoD,QAAQ1E,GAC5B6T,IACDA,EAAMvS,EAAeoD,QAAQ1E,GAAS,IAGrC6T,EAAIC,MAAMlX,GAASA,EAAK9C,OAAOJ,MAChCma,EAAIjQ,KAAKlK,SAGF4H,EAAeyS,uCACtBzS,EAAe8D,aAAapF,IAAS,EAE7C,EAEJzG,EAAQma,2BAA6BA,C,oCClDrC5V,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQya,2BAAwB,EAChC,MAAM5T,EAA0B,EAAQ,OAClCK,EAA0B,EAAQ,OAClCU,EAAS,EAAQ,OAMvB,MAAM6S,EACFL,sBACI,OAAO,CACX,CACA3P,aAAa6O,EAAYvR,EAAgBE,EAAM9B,EAAM9F,EAAOoG,GACxD,IAAKyG,MAAMC,QAAQ9M,GAAQ,CACvB,MAAMqa,EAAiB,WAAYpB,EAE7BzV,QAAgBkE,EAAe7B,WAAWC,GAC1CwU,EAAWxU,EAAKM,EAAQ,GACxBmU,EAAmBhT,EAAOM,KAAK2S,qBAAqBhX,EAAS8W,GACnE,GAAIC,EAAkB,CAElB,GAAI/T,EAAwBqB,KAAKgR,mBAAmB0B,GAChD,MAAM,IAAI/T,EAAwBqC,WAAW,kDAAkD0R,IAAoB/T,EAAwBsC,YAAY2R,yBAE3J,GAAgC,kBAArBF,EACP,MAAM,IAAI/T,EAAwBqC,WAAW,uCAAuC0R,IAAoB/T,EAAwBsC,YAAY2R,yBAGhJ,GAAqB,kBAAVza,EAAoB,CAE3B,GAA2D,QAAvDuH,EAAOM,KAAKqN,oBAAoB1R,EAAS8W,GACzC,MAAM,IAAI9T,EAAwBqC,WAAW,gGAAgG7I,IAASwG,EAAwBsC,YAAYgN,sBAG9L,MAAMhW,EAAK8H,EAAKoP,eAAexT,EAASxD,GACpCF,IACA4H,EAAeoD,QAAQ1E,EAAQ,GAAK,CAACtG,GAE7C,CAEA,MAAM4a,EAAgB9S,EAAK8O,sBAAsBlT,EAAS+W,GAC1D,GAAIG,EAAe,CACf,MAAMC,QAAoB/S,EAAK+O,YAAYnT,EAAS+W,QAAwB3S,EAAK+R,gBAAgB7T,EAAKM,GAAQN,EAAMM,GAAQA,EAAON,GACnI,GAAIuU,EAAgB,CAEhB,MAAMZ,QAAgB7R,EAAKgG,uBAAuB9H,EAAMM,EAAQ,GAChE,IAAK,MAAMwU,KAAcD,EACrBjT,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAKiY,EAASiB,EAAeE,EAAYhT,EAAK+C,mBAEtG,MAGI,IAAK,MAAMiQ,KAAcD,QACf9T,EAAwB2J,sBAAsBqK,sBAAsBnT,EAAgBE,EAAM9B,EAAMM,EAAQ,EAAGsU,EAAeE,GAAY,EAGxJ,CACJ,CACA,MAAMnH,EAAc4G,EAAiB,EAAI,QACnC3S,EAAeoH,cAAchJ,EAAK5C,MAAM,EAAG4C,EAAK3C,OAASsQ,GAAczT,EAAOoG,EAAQqN,GAAa,SAEnG/L,EAAeyS,oCACzB,CACAzS,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQya,sBAAwBA,C,qCCpEhClW,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQmb,8BAA2B,EACnC,MAAMtU,EAA0B,EAAQ,OAOxC,MAAMsU,EACFf,sBACI,OAAO,CACX,CACA3P,aAAa6O,EAAYvR,EAAgBE,EAAM9B,EAAM9F,EAAOoG,GACxD,MAAMtE,QAAiB8F,EAAK+R,gBAAgB7T,EAAKM,GAAQN,EAAMM,GAC/D,GAAIyG,MAAMC,QAAQ9M,GAEdA,EAAQA,EAAM0O,KAAKiH,IAAa,CAAG,SAAUA,EAAU,YAAa7T,UAEnE,CACD,GAAqB,kBAAV9B,EACP,MAAM,IAAIwG,EAAwBqC,WAAW,wCAAwC+M,KAAKC,UAAU7V,2BAAgCwG,EAAwBsC,YAAYiS,4BAE5K/a,EAAQ,CAAE,SAAUA,EAAO,YAAa8B,EAC5C,OACM4F,EAAeoH,cAAchJ,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,GAAInD,EAAOoG,EAAQ,GAAG,GACrFsB,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQmb,yBAA2BA,C,qCC7BnC5W,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQqb,0BAAuB,EAC/B,MAAMnU,EAA0B,EAAQ,OAClCU,EAAS,EAAQ,OAMvB,MAAMyT,EACFjB,sBACI,OAAO,CACX,CACA3P,aAAa6O,EAAYvR,EAAgBE,EAAM9B,EAAM9F,EAAOoG,GACxD,IAAKyG,MAAMC,QAAQ9M,GAAQ,CACvB,GAAqB,kBAAVA,EAAoB,CAE3B,MAAMwD,QAAgBkE,EAAe7B,WAAWC,GAC1CmV,EAAoB1T,EAAOM,KAAKqN,oBAAoB1R,EAASsC,EAAKM,EAAQ,IAE1EtG,EAA2B,WAAtBmb,QACCrT,EAAK8O,sBAAsBlT,EAASxD,SACpC4H,EAAKoP,eAAexT,EAASxD,GACzC,GAAIF,EAAI,CAEJ,MAAM6V,EAAW,CAAE,MAAuB,cAAhB7V,EAAGM,SAA2BN,EAAGE,MAAQA,SAC7D0H,EAAeoH,cAAchJ,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,GAAIwS,EAAUvP,EAAQ,GAAG,GAExFsB,EAAeoD,QAAQ1E,EAAQ,GAAK,CAACtG,EACzC,CACJ,KACK,CAGD,MAAMob,IAAuBxT,EAAeoD,QAAQ1E,EAAQ,GAEvD8U,UACMxT,EAAeoD,QAAQ1E,SAE5BsB,EAAeoH,cAAchJ,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,GAAInD,EAAOoG,EAAQ,GAAG,GAChF8U,IACDxT,EAAeoD,QAAQ1E,EAAQ,GAAKsB,EAAeoD,QAAQ1E,GAEnE,CAEA,MAAM+U,QAAoBvT,EAAK+R,gBAAgB7T,EAAKM,GAAQN,EAAMM,GAC5DmO,EAAuB,OAAhB4G,EACPvT,EAAK8O,4BAA4BhP,EAAe7B,WAAWC,GAAOqV,GAClE,KACF5G,SAEM1N,EAAwB2J,sBAAsBqK,sBAAsBnT,EAAgBE,EAAM9B,EAAMM,EAAQ,EAAGwB,EAAKsM,QAASK,GAAM,SAGnI7M,EAAeyS,oCACzB,CACAzS,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQqb,qBAAuBA,C,qCC3D/B9W,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQoQ,4BAAyB,EACjC,MAAMxI,EAAS,EAAQ,OAIvB,MAAMwI,EACFzB,oBACI,OAAO,CACX,CACA3B,mBACI,OAAO,CACX,CACAvC,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAC9C,OAAO7L,KAAK0M,KAAK/E,EAAgBE,EAAM,KAAM9B,EAAMM,EACvD,CACAgE,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,MAA8B,kBAAhBN,EAAKM,EACvB,CACAgE,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GACjD,IAAIkF,QAAkB1D,EAAK2D,qBAAqBzF,EAAMM,GAEtD,GAAkB,UAAdkF,EAAuB,CAGvB,IAAI8P,EAAc,KACdrQ,EAAgB,EACpB,IAAK,IAAIgB,EAAI3F,EAAQ,EAAG2F,EAAI,EAAGA,IAAK,CAChC,MAAMsP,EAAYvV,EAAKiG,GACvB,GAAyB,kBAAdsP,GAA+C,kBAAdA,EAAwB,CAChEtQ,EAAgBgB,EAChBqP,EAAcC,EACd,KACJ,CACJ,CACA,GAAoB,OAAhBD,EAAsB,CAEtB,MAAMrE,QAAenP,EAAK+O,kBAAkBjP,EAAe7B,WAAWC,GAAOsV,EAAapb,EAAOoG,EAAON,GACxG,IAAK,MAAMvE,KAAUwV,QACXhX,KAAKub,kBAAkB5T,EAAgBE,EAAMrG,EAAQvB,EAAOoG,EAAON,EAAK5C,MAAM,EAAG6H,GAAgBA,GAGrF,IAAlBgM,EAAO5T,cACDpD,KAAKub,kBAAkB5T,EAAgBE,EAAM,KAAM5H,EAAOoG,EAAON,EAAK5C,MAAM,EAAG6H,GAAgBA,EAE7G,CACJ,MACK,GAAkB,SAAdO,QAEC5D,EAAeoH,cAAchJ,EAAK5C,MAAM,GAAI,GAAIlD,EAAOoG,EAAQ,GAAG,QAEvE,QAAkBhB,IAAdkG,GAAyC,UAAdA,EAAuB,CAKvD,IAAK,IAAIS,EAAI3F,EAAQ,EAAG2F,EAAI,EAAGA,IAC3B,GAAuB,kBAAZjG,EAAKiG,GAAiB,CAC7BT,QAAkB1D,EAAKyD,eAAevF,EAAKiG,GAAIjG,EAAMiG,GACrD,KACJ,CAGJ,MAAMgG,QAAsBrK,EAAe7B,WAAWC,EAAK5C,MAAM,GAAI,IACrE,GAAI,UAAWqE,EAAOM,KAAKuN,yBAAyBrD,EAAezG,GAAY,CAG3E5D,EAAe8D,aAAapF,EAAQ,IAAK,EACzC,MAAM2Q,QAAenP,EAAK+O,kBAAkBjP,EAAe7B,WAAWC,GAAOwF,EAAWtL,EAAOoG,EAAON,GACtG,IAAK,MAAMvE,KAAUwV,QACXhX,KAAKub,kBAAkB5T,EAAgBE,EAAMrG,EAAQvB,EAAOoG,EAAON,EAAK5C,MAAM,GAAI,GAAIkD,EAAQ,GAGlF,IAAlB2Q,EAAO5T,cACDpD,KAAKub,kBAAkB5T,EAAgBE,EAAM,KAAM5H,EAAOoG,EAAON,EAAK5C,MAAM,GAAI,GAAIkD,EAAQ,EAE1G,MAGIsB,EAAe8L,WAAWpN,EAAO,SAE3BsB,EAAeoH,cAAchJ,EAAK5C,MAAM,GAAI,GAAIlD,EAAOoG,EAAQ,GAAG,GAExEsB,EAAeqH,YAAYzI,cAAcR,EAAK5C,MAAM,GAAI,GAEhE,CACJ,CACAkH,wBAAwB1C,EAAgBE,EAAM5H,EAAOub,EAAenV,EAAOoV,EAAczQ,GAErF,IAAIR,EAAc7C,EAAe8C,iBAAiBpE,GAClD,GAAsB,OAAlBmV,GAAyG,cAAxE3T,EAAK0N,gBAAgBiG,EAAeC,EAAcpV,IAAQ,UAAoB,CAC/G,GAAKmE,GAAgBA,EAAYvK,MAI5B,CAID,MAAMyb,EAAc7T,EAAKlE,YAAY7C,YACrC6G,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAK+I,EAAYvK,MAAO4H,EAAK6C,QAASgR,EAAa7T,EAAK+C,oBAExGJ,EAAYvK,MAAQyb,CACxB,KAZwC,CACpC,MAAMC,EAAW9T,EAAKlE,YAAY7C,YAClC0J,EAAc,CAAEvK,MAAO0b,EAAU3Q,gBAAeH,OAAQ8Q,EAC5D,CAYI1b,GACA0H,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAK+I,EAAYvK,MAAO4H,EAAKoM,SAAUhU,EAAO4H,EAAK+C,mBAE3G,MAISJ,IACDA,EAAc,CAAEQ,gBAAeH,OAAQhD,EAAK8C,SAGpDhD,EAAe8C,iBAAiBpE,GAASmE,CAC7C,EAEJ5K,EAAQoQ,uBAAyBA,C,qCCxHjC7L,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQsL,2BAAwB,EAChC,MAAM0Q,EAA+B,EAAQ,OACvCC,EAA0B,EAAQ,MAClCC,EAA6B,EAAQ,OACrCC,EAAyB,EAAQ,OACjCvU,EAAS,EAAQ,OAKvB,MAAM0D,EAMFxC,8BAA8BwQ,GAC1B,MAAO,WAAYA,IACV,SAAUA,GAAiD,IAAnC/U,OAAO4B,KAAKmT,GAAY9V,QAAoD,IAAnCe,OAAO4B,KAAKmT,GAAY9V,OACtG,CAMAsF,+BAA+BwQ,GAC3B,MAAO,WAAYA,IACV,SAAUA,GAAc/U,OAAO4B,KAAKmT,GAAY9V,OAAS,KACpD,SAAU8V,IAAe/U,OAAO4B,KAAKmT,GAAY9V,OAAS,EAC5E,CAQAsF,8BAA8BwQ,EAAY7S,EAAON,GAC7C,IAAIiW,EAAyB9Q,EAAsB8Q,uBAAuB9C,GACtElE,EAAQ,GACZ,IAAK,IAAIhJ,EAAI3F,EAAO2F,EAAIjG,EAAK3C,OAAQ4I,IAC5BgQ,GAA6C,kBAAZjW,EAAKiG,KACvCgJ,GAAS,IAAMjP,EAAKiG,IAGnBgQ,GAA6C,kBAAZjW,EAAKiG,KACvCgQ,GAAyB,GAGjC,OAAOhH,CACX,CAeAtM,iCAAiCf,EAAgB5B,EAAMM,GACnD,MAAMiO,EAAW,CACb4E,WAAY,CAAE,QAAQ,GACtB7S,QACAiO,UAAU,GAGd,IAAI2H,GAAsB,EAE1B,MAAMxY,QAAgBkE,EAAe7B,WAAWC,EAAM,GACtD,IAAK,IAAIiG,EAAI3F,EAAQ,EAAG2F,GAAK,EAAGA,IAC5B,GAAuB,kBAAZjG,EAAKiG,GAAiB,CAE7B,MAAMkQ,EAAiB1U,EAAOM,KAAK2M,gBAAgBhR,EAAS,aAAcsC,EAAKiG,IAAI,GACnF,GAAIkQ,GAAkBhR,EAAsB8Q,uBAAuBE,GAC/D,MAAO,CACHhD,WAAYgD,EACZ7V,MAAO2F,EAAI,EACXsI,UAAU,GAGlB,MAAM6H,EAAmB3U,EAAOM,KAAK2M,gBAAgBhR,EAAS,aAAcsC,EAAKiG,EAAI,IAAI,GACzF,GAAKmQ,EAQA,CAED,MAAM7B,EAAiB,WAAY6B,EAEnC,IAAK,MAAMC,KAAuBlR,EAAsBmR,mBACpD,GAAIF,EAAiBC,GACjB,OAAI9B,EAEIpP,EAAsBmR,mBAAmBD,GAAqBpC,sBACvD,CACHd,WAAYiD,EACZ9V,MAAO2F,EACPsI,UAAU,GAIPA,EAKP2H,EACO3H,EAGA,CACH4E,WAAYiD,EACZ9V,MAAO2F,EACPsI,UAAU,GAO9B,OAAOA,CACX,CA3CI,GAAI2H,EAEA,OAAO3H,EAGX2H,GAAsB,CAuC9B,CAEJ,OAAO3H,CACX,CAeA5L,0CAA0Cf,EAAgB5B,EAAMM,GAC5D,MAAMiW,QAAgBpR,EAAsBiO,oBAAoBxR,EAAgB5B,EAAMM,GACtF,OAAQiW,EAAQhI,YAAc,WAAYgI,EAAQpD,WACtD,CACA3K,oBACI,OAAO,CACX,CACA3B,mBACI,OAAO,CACX,CACAvC,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAC9C,cAAe7L,KAAK0M,KAAK/E,EAAgBE,EAAM,KAAM9B,EAAMM,EAC/D,CACAgE,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,MAAM6S,EAAa1R,EAAOM,KAAKuN,+BAA+B1N,EAAe7B,WAAWC,EAAM,GAAIA,EAAKM,EAAQ,IAC/G,IAAK,MAAMkW,KAAiBrR,EAAsBmR,mBAC9C,GAAInD,EAAWqD,GACX,MAAO,CACHrD,aACAoD,QAASpR,EAAsBmR,mBAAmBE,IAI9D,OAAO,IACX,CACAlS,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,EAAOoG,GACxD,OAAOA,EAAW6P,QAAQ3P,OAAOF,EAAWyM,WAAYvR,EAAgBE,EAAM9B,EAAM9F,EAAOoG,EAC/F,EAEJzG,EAAQsL,sBAAwBA,EAChCA,EAAsBmR,mBAAqB,CACvC,MAAO,IAAIT,EAA6B7B,2BACxC,SAAU,IAAI8B,EAAwBxB,sBACtC,YAAa,IAAIyB,EAA2Bf,yBAC5C,QAAS,IAAIgB,EAAuBd,qB,mCCzLxC9W,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQ8Q,iCAA8B,EAKtC,MAAMA,EACFnC,oBACI,OAAO,CACX,CACA3B,mBACI,OAAO,CACX,CACAvC,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAC9C,OAAO,CACX,CACAxB,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,OAAO,CACX,CACAgE,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GACjDsB,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQ8Q,4BAA8BA,C,qCCvBtCvM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQ6Q,2BAAwB,EAChC,MAAMhK,EAA0B,EAAQ,OAClCe,EAAS,EAAQ,OAKvB,MAAMiJ,EAaF/H,mCAAmCf,EAAgBE,EAAM9B,EAAMM,EAAO9E,EAAWC,EAAQuM,GACrF,MAAMyO,QAAwB3U,EAAK4U,mBAAmB1W,EAAMM,GACtDqH,QAAyB7F,EAAK8F,oBAAoBtH,EAAON,GACzD2W,EAAuBrW,EAAQqH,EAC/BH,EAAW5F,EAAeoD,QAAQyR,GACxC,GAAIjP,EAEA,IAAK,MAAMjM,KAAWiM,EAAU,CAE5B,MAAMoP,EAAUjP,GAAoB,EACpC,GAAIiP,EAAS,CACT,MAAM/O,EAASjG,EAAeoD,QAAQ2R,EAAuB,GAC7D,GAAI9O,EACA,IAAK,MAAMlM,KAASkM,EAEZG,GACAlG,EAAKwR,uBAAuB7X,GAC5BmG,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAKD,EAAQD,EAAWD,EAASI,KAGjFiG,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAKH,EAASC,EAAWC,EAAQE,SAMrFqM,GACAlG,EAAKwR,uBAAuB7X,GAC5BmG,EAAeuG,+BAA+BwO,EAAuB,GAAGzS,KAAK,CAAE3I,QAASE,EAAQD,YAAWC,OAAQF,KAGnHqG,EAAeuG,+BAA+BwO,EAAuB,GAChEzS,KAAK,CAAE3I,UAASC,YAAWC,UAG5C,KACK,CAED,MAAME,QAAcmG,EAAKgG,uBAAuB9H,EAAMyW,GAClDzO,GACAlG,EAAKwR,uBAAuB7X,GAC5BmG,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAKD,EAAQD,EAAWD,EAASI,KAGjFiG,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAKH,EAASC,EAAWC,EAAQE,GAEzF,CACJ,MAIIqM,GACAlG,EAAKwR,uBAAuB7X,GAEhCmG,EAAe0L,+BAA+BmJ,GAAiBvS,KAAK,CAAE1I,YAAWC,SAAQuM,WAEjG,CACAQ,oBACI,OAAO,CACX,CACA3B,mBACI,OAAO,CACX,CACAvC,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAC9C,MAAM3C,EAAMnD,EAAKM,GACjB,GAAI6C,EAAK,CACL,MAAMzF,QAAgBkE,EAAe7B,WAAWC,GAChD,IAAK4B,EAAe0F,iBAAiBhH,UAAgBwB,EAAK2P,gBAAgB/T,EAASsC,EAAKM,IAKpF,MAHsD,UAAlDmB,EAAOM,KAAKqN,oBAAoB1R,EAASyF,KACzCvB,EAAe0F,iBAAiBhH,EAAQ,IAAK,IAE1C,CAEf,CACA,OAAO,CACX,CACAgE,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,OAAON,EAAKM,EAChB,CACAgE,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,EAAOoG,GACxD,MAAM2O,EAAcrV,EAAKM,GACnB5C,QAAgBkE,EAAe7B,WAAWC,GAC1CxE,QAAkBsG,EAAK2P,gBAAgB/T,EAASyF,GACtD,GAAI3H,EAAW,CACX,MAAMqb,QAAgB/U,EAAK+O,YAAYnT,EAASyF,EAAKjJ,EAAOoG,EAAON,GACnE,GAAI6W,EAAQxZ,OACR,IAAK,IAAI5B,KAAUob,EAAS,CACxB,MAAM7O,EAAUvG,EAAOM,KAAK+U,kBAAkBpZ,EAAS2X,QAAmBvT,EAAK2D,qBAAqBzF,EAAMM,IAC1G,GAAIpG,EAAO,CAGP,MAAM6c,EAAqB,UAAWtV,EAAOM,KAAKuN,yBAAyB5R,EAASyF,GACpF,GAAI4T,GAAsB7c,EAAM,SAAU,CACtC,IAAM6c,IAAuBhQ,MAAMC,QAAQ9M,KAAWA,EAAM,UACpDA,EAAM,WAAa6M,MAAMC,QAAQ9M,EAAM,YACxCuB,IAAWqG,EAAK8C,OAAQ,CAC3B,MAAMH,EAAc3C,EAAKlE,YAAY7C,YACrC6G,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAK+I,EAAa3C,EAAK6C,QAAS7C,EAAK8C,OAAQ9C,EAAK+C,oBAClGjD,EAAeqG,SAAS3H,EAAOwB,EAAKlE,YAAYlC,KAAK+I,EAAa3C,EAAKoM,SAAUzS,EAAQqG,EAAK+C,oBAC9FpJ,EAASgJ,CACb,CAEA,GAAIuD,IAAYpG,EAAeyJ,iBAC3B,MAAM,IAAI3K,EAAwBqC,WAAW,mDAAmDI,IAAOzC,EAAwBsC,YAAYuQ,+BAEnJ,CACJ,OACM7I,EAAsBqK,sBAAsBnT,EAAgBE,EAAM9B,EAAMM,EAAO9E,EAAWC,EAAQuM,EAC5G,CAER,CACJ,EAEJnO,EAAQ6Q,sBAAwBA,C,mCCvIhCtM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQmd,yBAAsB,EAI9B,MAAMA,EACFjd,YAAYkd,GACRhd,KAAKgd,QAAUA,CACnB,CACAzO,oBACI,OAAO,CACX,CACA3B,mBACI,OAAO,CACX,CACAvC,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAC9C,OAAO,CACX,CACAxB,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,OAAO6C,IAAQlJ,KAAKgd,OACxB,EAEJpd,EAAQmd,oBAAsBA,C,qCCtB9B5Y,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQqQ,gCAA6B,EACrC,MAAMxJ,EAA0B,EAAQ,OAClCwW,EAAwB,EAAQ,OAItC,MAAMhN,UAAmCgN,EAAsBF,oBAC3Djd,cACI4C,MAAM,WACV,CACAkK,mBACI,OAAO,CACX,CACAvC,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GAE7CsB,EAAe/D,mBACX+D,EAAekF,gBAAgBxG,IAC5BsB,EAAeuF,eAAe7G,SACIhB,IAAlCsC,EAAeoD,QAAQ1E,KAC9BsB,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,yFAC5BrC,EAAwBsC,YAAYmU,8BAK5E,MAAMlL,EAAgBrK,EAAe7B,WAAWC,GAE1CtC,EAAUkE,EAAekK,aAAa5R,SAAc+R,GAAeG,iBACzExK,EAAeqH,YAAY1I,WAAWP,EAAK5C,MAAM,GAAI,GAAIM,GACzDkE,EAAeyL,YAAYnT,SACrB0H,EAAemK,sBAAsBrO,EAC/C,EAEJ7D,EAAQqQ,2BAA6BA,C,qCClCrC9L,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQwQ,8BAA2B,EACnC,MAAM6M,EAAwB,EAAQ,OAItC,MAAM7M,UAAiC6M,EAAsBF,oBACzDjd,cACI4C,MAAM,SACV,CACA2H,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GAEjDsB,EAAewF,WAAW9G,EAAQ,IAAK,CAC3C,EAEJzG,EAAQwQ,yBAA2BA,C,qCCfnCjM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQsQ,2BAAwB,EAChC,MAAMzJ,EAA0B,EAAQ,OAClCwW,EAAwB,EAAQ,OAItC,MAAM/M,UAA8B+M,EAAsBF,oBACtDjd,cACI4C,MAAM,MACV,CACAkK,mBACI,OAAO,CACX,CACAvC,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GAC5B,kBAAVpG,GACP0H,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,sBAAsB7I,KAAUwG,EAAwBsC,YAAYoU,mBAIxI,MAAMX,QAAwB3U,EAAK4U,mBAAmB1W,EAAMM,QAEZhB,IAA5CsC,EAAeoD,QAAQyR,KACnB7U,EAAeoD,QAAQyR,GAAiB,GAAG1R,SAE3CnD,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,8DAA8D/C,EAAKM,EAAQ,MAAOI,EAAwBsC,YAAY8N,6BAItLlP,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,yBAAyBnB,EACpFoD,QAAQyR,GAAiB,GAAGvc,eAAeA,KAAUwG,EAAwBsC,YAAYqU,sBAItGzV,EAAeoD,QAAQyR,GAAmB3U,EAAK0O,0BAA0B1O,EAAKoP,qBAAqBtP,EAAe7B,WAAWC,GAAO9F,GACxI,EAEJL,EAAQsQ,sBAAwBA,C,qCCrChC/L,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQuQ,iCAA8B,EACtC,MAAM1J,EAA0B,EAAQ,OAClCwW,EAAwB,EAAQ,OAItC,MAAM9M,UAAoC8M,EAAsBF,oBAC5Djd,cACI4C,MAAM,YACV,CACA2H,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GAC5B,kBAAVpG,GACP0H,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,4BAA4B7I,KAAUwG,EAAwBsC,YAAYsU,yBAE9I,MAAMC,QAAsBzV,EAAK0N,gBAAgBtV,EAAO8F,EAAMM,QAAasB,EAAe7B,WAAWC,IACjG,WAAYuX,GACZ3V,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,2CAA2C+M,KAAKC,UAAU7V,MAAWwG,EAAwBsC,YAAYsU,yBAEzK,UAAWC,GACX3V,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,0CAA0C+M,KAAKC,UAAU7V,MAAWwG,EAAwBsC,YAAYsU,yBAE5K1V,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQuQ,4BAA8BA,C,qCCzBtChM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQyQ,6BAA0B,EAClC,MAAM5J,EAA0B,EAAQ,OAClCwW,EAAwB,EAAQ,OAItC,MAAM5M,UAAgC4M,EAAsBF,oBACxDjd,cACI4C,MAAM,QACV,CACA2H,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GAC5B,kBAAVpG,GACP0H,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,kCAAkCI,QAAUjJ,KAAUwG,EAAwBsC,YAAYwU,qBAE1J,iBAAkB1V,EAAK0N,gBAAgBtV,EAAO8F,EAAMM,QAAasB,EAAe7B,WAAWC,KAC3F4B,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,qCAAqCI,KAAQzC,EAAwBsC,YAAYwU,qBAErJ5V,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQyQ,wBAA0BA,C,qCCrBlClM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQ0Q,6BAA0B,EAClC,MAAM7J,EAA0B,EAAQ,OAClCe,EAAS,EAAQ,OACjBV,EAA0B,EAAQ,OAClCmW,EAAwB,EAAQ,OAItC,MAAM3M,UAAgC2M,EAAsBF,oBACxDjd,cACI4C,MAAM,QACV,CACAkK,mBACI,OAAO,CACX,CACAvC,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GACjD,MAAM+U,EAAcrV,EAAKM,GAInB5C,QAAgBkE,EAAe7B,WAAWC,GAC1CxE,EAAYsG,EAAKsM,QACjBpG,EAAUvG,EAAOM,KAAK+U,kBAAkBpZ,EAAS2X,QAAmBvT,EAAK2D,qBAAqBzF,EAAMM,IAEpGmX,EAAW1Q,MAAMC,QAAQ9M,GAASA,EAAQ,CAACA,GACjD,IAAK,MAAMwd,KAAWD,EAAU,CACL,kBAAZC,GACP9V,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,wBAAwB2U,KAAYhX,EAAwBsC,YAAY2U,qBAE5I,MAAMlJ,EAAO3M,EAAK8O,sBAAsBlT,EAASga,GAC7CjJ,SACM1N,EAAwB2J,sBAAsBqK,sBAAsBnT,EAAgBE,EAAM9B,EAAMM,EAAO9E,EAAWiT,EAAMzG,EAEtI,CAEA,IAAI6E,EAAgBtK,QAAQC,QAAQ9E,GAChCka,GAAwB,EAC5B,IAAK,MAAMF,KAAWD,EAAS9N,OAAQ,CACnC,MAAMkO,EAAcpW,EAAOM,KAAK2M,gBAAgBhR,EAAS,WAAYga,EAAS,MAC1EG,IACAD,GAAwB,EACxB/K,EAAgBA,EAAcxM,MAAMyX,GAAMlW,EAAekK,aAAa+L,EAAaC,EAAE1L,mBAE7F,EAEIxK,EAAe/D,mBACX+Z,GAA0BhW,EAAe8J,2CACzC9J,EAAekF,gBAAgBxG,KAAUsB,EAAeoD,QAAQ1E,IACpEsB,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,qGAC5BrC,EAAwBsC,YAAYmU,8BAGxES,IAEA/K,EAAgBA,EAAcxM,MAAMyX,IAC1B,eAAgBA,EAAE1L,kBACpB0L,EAAE1L,gBAAgB,eAAgB,IAKE,IAApC0L,EAAE1L,gBAAgB,gBAClB0L,EAAE1L,gBAAgB,wBAA0B1O,EAAQ0O,iBAEjD0L,KAGXlW,EAAeqH,YAAY1I,WAAWP,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,GAAIwP,IAG1EjL,EAAeuF,eAAe7G,IAAS,CAC3C,EAEJzG,EAAQ0Q,wBAA0BA,C,qCC1ElCnM,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQ4Q,wCAAqC,EAC7C,MAAM/J,EAA0B,EAAQ,OAKxC,MAAM+J,EACFjC,oBACI,OAAO,CACX,CACA3B,mBACI,OAAO,CACX,CACAvC,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAC9C,MAAM3C,QAAYrB,EAAKyD,eAAevF,EAAKM,GAAQN,EAAMM,GACzD,QAAII,EAAwBqB,KAAKgR,mBAAmB5P,OAE3C2C,GACW,UAAR3C,EAOhB,CACAmB,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,OAAOI,EAAwBqB,KAAKgR,mBAAmB5P,EAC3D,CACAmB,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GACjD,MAAMyX,EAActN,EAAmCuN,qBAAqB7U,QACxD7D,IAAhByY,EACIA,UAAsB7d,IAAU6d,EAAYtJ,MAC5C7M,EAAewL,UAAU,IAAI1M,EAAwBqC,WAAW,2BAA2BI,kBAAoBjJ,KAAU6d,EAAYE,YAGpIrW,EAAe2J,cACpB3J,EAAewL,UAAU,IAAI9Q,MAAM,oBAAoB6G,kBAAoBjJ,OAE/E0H,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQ4Q,mCAAqCA,EAC7CA,EAAmCuN,qBAAuB,CACtD,SAAU,CAAEvJ,KAAM,SAAUwJ,UAAWvX,EAAwBsC,YAAYkN,qBAC3E,QAAS,KACT,WAAY,CAAEzB,KAAM,SAAUwJ,UAAWvX,EAAwBsC,YAAYkV,uBAC7E,OAAQ,KACR,SAAU,K,qCCjDd9Z,OAAOmB,eAAe1F,EAAS,aAAc,CAAEK,OAAO,IACtDL,EAAQ2Q,8BAA2B,EACnC,MAAM0M,EAAwB,EAAQ,OAItC,MAAM1M,UAAiC0M,EAAsBF,oBACzDjd,cACI4C,MAAM,SACV,CACA2H,eAAe1C,EAAgBE,EAAM9B,EAAMM,EAAOwF,GAE9C,MAAM3C,EAAMnD,EAAKM,GAIjB,OAHI6C,IAAQvB,EAAe2F,aAAajH,UAAgBrG,KAAK0M,KAAK/E,EAAgBE,EAAMqB,EAAKnD,EAAMM,KAC/FsB,EAAe2F,aAAajH,IAAS,GAElC3D,MAAM4L,SAAS3G,EAAgBE,EAAM9B,EAAMM,EAAOwF,EAC7D,CACAxB,WAAW1C,EAAgBE,EAAMqB,EAAKnD,EAAMM,GACxC,MAAmG,iBAAtFwB,EAAKyD,eAAevF,EAAKM,GAAQN,EAAK5C,MAAM,EAAG4C,EAAK3C,OAAS,GAAIiD,EAAQ,GAAG,EAC7F,CACAgE,aAAa1C,EAAgBE,EAAMqB,EAAKnD,EAAM9F,EAAOoG,GAMjDsB,EAAe2F,aAAajH,IAAS,SAE9BsB,EAAe8F,yBAAyBpH,UACxCsB,EAAeyG,yBAAyB/H,GAE/CsB,EAAe8D,aAAapF,IAAS,CACzC,EAEJzG,EAAQ2Q,yBAA2BA,C","sources":["webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/index.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/BlankNode.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/DataFactory.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/DefaultGraph.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/Literal.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/NamedNode.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/Quad.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/Variable.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/data-model/lib/fromTerm.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/parser-jsonld/index.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/parser-jsonld/lib/ParserStream.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/@rdfjs/sink/index.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/index.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/ContextTree.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/JsonLdParser.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/ParsingContext.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/Util.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIdentifier.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerIndex.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerLanguage.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/containerhandler/ContainerHandlerType.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerArrayValue.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerContainer.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerInvalidFallback.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/EntryHandlerPredicate.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeyword.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordContext.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordGraph.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordId.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordIncluded.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordNest.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordType.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordUnknownFallback.js","webpack://@zazuko/spex/./node_modules/@rdf-esm/formats-common/node_modules/jsonld-streaming-parser/lib/entryhandler/keyword/EntryHandlerKeywordValue.js"],"sourcesContent":["const DataFactory = require('./lib/DataFactory.js')\n\nmodule.exports = DataFactory\n","class BlankNode {\n  constructor (id) {\n    this.value = id || ('b' + (++BlankNode.nextId))\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nBlankNode.prototype.termType = 'BlankNode'\n\nBlankNode.nextId = 0\n\nmodule.exports = BlankNode\n","const BlankNode = require('./BlankNode.js')\nconst DefaultGraph = require('./DefaultGraph.js')\nconst fromTermRaw = require('./fromTerm.js')\nconst Literal = require('./Literal.js')\nconst NamedNode = require('./NamedNode.js')\nconst Quad = require('./Quad.js')\nconst Variable = require('./Variable.js')\n\nfunction namedNode (value) {\n  return new NamedNode(value)\n}\n\nfunction blankNode (value) {\n  return new BlankNode(value)\n}\n\nfunction literal (value, languageOrDatatype) {\n  if (typeof languageOrDatatype === 'string') {\n    if (languageOrDatatype.indexOf(':') === -1) {\n      return new Literal(value, languageOrDatatype)\n    }\n\n    return new Literal(value, null, DataFactory.namedNode(languageOrDatatype))\n  }\n\n  return new Literal(value, null, languageOrDatatype)\n}\n\nfunction variable (value) {\n  return new Variable(value)\n}\n\nfunction defaultGraph () {\n  return DataFactory.defaultGraphInstance\n}\n\nfunction triple (subject, predicate, object) {\n  return DataFactory.quad(subject, predicate, object)\n}\n\nfunction quad (subject, predicate, object, graph) {\n  return new Quad(subject, predicate, object, graph || DataFactory.defaultGraphInstance)\n}\n\nfunction fromTerm (original) {\n  return fromTermRaw.call(DataFactory, original)\n}\n\nfunction fromQuad (original) {\n  return fromTermRaw.call(DataFactory, original)\n}\n\nconst DataFactory = {\n  namedNode,\n  blankNode,\n  literal,\n  variable,\n  defaultGraph,\n  triple,\n  quad,\n  fromTerm,\n  fromQuad,\n  defaultGraphInstance: new DefaultGraph()\n}\n\nmodule.exports = DataFactory\n","class DefaultGraph {\n  equals (other) {\n    return !!other && other.termType === this.termType\n  }\n}\n\nDefaultGraph.prototype.termType = 'DefaultGraph'\nDefaultGraph.prototype.value = ''\n\nmodule.exports = DefaultGraph\n","const NamedNode = require('./NamedNode.js')\n\nclass Literal {\n  constructor (value, language, datatype) {\n    this.value = value\n    this.datatype = Literal.stringDatatype\n    this.language = ''\n\n    if (language) {\n      this.language = language\n      this.datatype = Literal.langStringDatatype\n    } else if (datatype) {\n      this.datatype = datatype\n    }\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value &&\n      other.language === this.language && other.datatype.equals(this.datatype)\n  }\n}\n\nLiteral.prototype.termType = 'Literal'\n\nLiteral.langStringDatatype = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString')\nLiteral.stringDatatype = new NamedNode('http://www.w3.org/2001/XMLSchema#string')\n\nmodule.exports = Literal\n","class NamedNode {\n  constructor (iri) {\n    this.value = iri\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nNamedNode.prototype.termType = 'NamedNode'\n\nmodule.exports = NamedNode\n","const DefaultGraph = require('./DefaultGraph.js')\n\nclass Quad {\n  constructor (subject, predicate, object, graph) {\n    this.subject = subject\n    this.predicate = predicate\n    this.object = object\n\n    if (graph) {\n      this.graph = graph\n    } else {\n      this.graph = new DefaultGraph()\n    }\n  }\n\n  equals (other) {\n    // `|| !other.termType` is for backwards-compatibility with old factories without RDF* support.\n    return !!other && (other.termType === 'Quad' || !other.termType) &&\n      other.subject.equals(this.subject) && other.predicate.equals(this.predicate) &&\n      other.object.equals(this.object) && other.graph.equals(this.graph)\n  }\n}\n\nQuad.prototype.termType = 'Quad'\nQuad.prototype.value = ''\n\nmodule.exports = Quad\n","class Variable {\n  constructor (name) {\n    this.value = name\n  }\n\n  equals (other) {\n    return !!other && other.termType === this.termType && other.value === this.value\n  }\n}\n\nVariable.prototype.termType = 'Variable'\n\nmodule.exports = Variable\n","function fromTerm (original) {\n  if (!original) {\n    return null\n  }\n\n  if (original.termType === 'BlankNode') {\n    return this.blankNode(original.value)\n  }\n\n  if (original.termType === 'DefaultGraph') {\n    return this.defaultGraph()\n  }\n\n  if (original.termType === 'Literal') {\n    return this.literal(original.value, original.language || this.namedNode(original.datatype.value))\n  }\n\n  if (original.termType === 'NamedNode') {\n    return this.namedNode(original.value)\n  }\n\n  if (original.termType === 'Quad') {\n    const subject = this.fromTerm(original.subject)\n    const predicate = this.fromTerm(original.predicate)\n    const object = this.fromTerm(original.object)\n    const graph = this.fromTerm(original.graph)\n\n    return this.quad(subject, predicate, object, graph)\n  }\n\n  if (original.termType === 'Variable') {\n    return this.variable(original.value)\n  }\n\n  throw new Error(`unknown termType ${original.termType}`)\n}\n\nmodule.exports = fromTerm\n","const Sink = require('@rdfjs/sink')\nconst ParserStream = require('./lib/ParserStream')\n\nclass Parser extends Sink {\n  constructor (options) {\n    super(ParserStream, options)\n  }\n}\n\nmodule.exports = Parser\n","const rdf = require('@rdfjs/data-model')\nconst { JsonLdParser } = require('jsonld-streaming-parser')\nconst { Transform } = require('readable-stream')\n\nconst relativeIriProtocol = 'null:'\n\nfunction termCleanup (factory) {\n  return term => {\n    if (term.termType !== 'NamedNode') {\n      return null\n    }\n\n    if (!term.value.startsWith(relativeIriProtocol)) {\n      return null\n    }\n\n    // remove dummy protocol workaround for relative IRIs\n    return factory.namedNode(term.value.slice(relativeIriProtocol.length))\n  }\n}\n\nfunction quadCleanup (factory) {\n  const cleanup = termCleanup(factory)\n\n  return quad => {\n    const subject = cleanup(quad.subject)\n    const predicate = cleanup(quad.predicate)\n    const object = cleanup(quad.object)\n    const graph = cleanup(quad.graph)\n\n    if (subject || predicate || object || graph) {\n      return factory.quad(\n        subject || quad.subject,\n        predicate || quad.predicate,\n        object || quad.object,\n        graph || quad.graph\n      )\n    }\n\n    return quad\n  }\n}\n\nclass ParserStream {\n  constructor (input, { baseIRI = relativeIriProtocol, context = null, factory = rdf } = {}) {\n    const parser = new JsonLdParser({\n      baseIRI,\n      context,\n      dataFactory: factory,\n      streamingProfile: false\n    })\n\n    input.pipe(parser)\n\n    const cleanup = quadCleanup(factory)\n\n    const transform = new Transform({\n      objectMode: true,\n      transform: (quad, encoding, callback) => {\n        callback(null, cleanup(quad))\n      }\n    })\n\n    parser.on('context', context => {\n      Object.entries(context).forEach(([prefix, iri]) => {\n        transform.emit('prefix', prefix, factory.namedNode(iri))\n      })\n    })\n    parser.on('error', err => transform.destroy(err))\n    parser.pipe(transform)\n\n    return transform\n  }\n}\n\nmodule.exports = ParserStream\n","class Sink {\n  constructor (Impl, options) {\n    this.Impl = Impl\n    this.options = options\n  }\n\n  import (input, options) {\n    const output = new this.Impl(input, Object.assign({}, this.options, options))\n\n    input.on('end', () => {\n      if (!output.readable) {\n        output.emit('end')\n      }\n    })\n\n    input.on('error', (err) => {\n      output.emit('error', err)\n    })\n\n    return output\n  }\n}\n\nmodule.exports = Sink\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __exportStar = (this && this.__exportStar) || function(m, exports) {\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(exports, p)) __createBinding(exports, m, p);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n__exportStar(require(\"./lib/JsonLdParser\"), exports);\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContextTree = void 0;\n/**\n * A tree structure that holds all contexts,\n * based on their position in the JSON object.\n *\n * Positions are identified by a path of keys.\n */\nclass ContextTree {\n    constructor() {\n        this.subTrees = {};\n    }\n    getContext(keys) {\n        if (keys.length > 0) {\n            const [head, ...tail] = keys;\n            const subTree = this.subTrees[head];\n            if (subTree) {\n                const subContext = subTree.getContext(tail);\n                if (subContext) {\n                    return subContext.then(({ context, depth }) => ({ context, depth: depth + 1 }));\n                }\n            }\n        }\n        return this.context ? this.context.then((context) => ({ context, depth: 0 })) : null;\n    }\n    setContext(keys, context) {\n        if (keys.length === 0) {\n            this.context = context;\n        }\n        else {\n            const [head, ...tail] = keys;\n            let subTree = this.subTrees[head];\n            if (!subTree) {\n                subTree = this.subTrees[head] = new ContextTree();\n            }\n            subTree.setContext(tail, context);\n        }\n    }\n    removeContext(path) {\n        this.setContext(path, null);\n    }\n}\nexports.ContextTree = ContextTree;\n//# sourceMappingURL=ContextTree.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.JsonLdParser = void 0;\n// tslint:disable-next-line:no-var-requires\nconst Parser = require('jsonparse');\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst stream_1 = require(\"stream\");\nconst EntryHandlerArrayValue_1 = require(\"./entryhandler/EntryHandlerArrayValue\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\nconst EntryHandlerInvalidFallback_1 = require(\"./entryhandler/EntryHandlerInvalidFallback\");\nconst EntryHandlerPredicate_1 = require(\"./entryhandler/EntryHandlerPredicate\");\nconst EntryHandlerKeywordContext_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordContext\");\nconst EntryHandlerKeywordGraph_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordGraph\");\nconst EntryHandlerKeywordId_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordId\");\nconst EntryHandlerKeywordIncluded_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordIncluded\");\nconst EntryHandlerKeywordNest_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordNest\");\nconst EntryHandlerKeywordType_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordType\");\nconst EntryHandlerKeywordUnknownFallback_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordUnknownFallback\");\nconst EntryHandlerKeywordValue_1 = require(\"./entryhandler/keyword/EntryHandlerKeywordValue\");\nconst ParsingContext_1 = require(\"./ParsingContext\");\nconst Util_1 = require(\"./Util\");\nconst http_link_header_1 = require(\"http-link-header\");\n/**\n * A stream transformer that parses JSON-LD (text) streams to an {@link RDF.Stream}.\n */\nclass JsonLdParser extends stream_1.Transform {\n    constructor(options) {\n        super({ readableObjectMode: true });\n        options = options || {};\n        this.options = options;\n        this.parsingContext = new ParsingContext_1.ParsingContext(Object.assign({ parser: this }, options));\n        this.util = new Util_1.Util({ dataFactory: options.dataFactory, parsingContext: this.parsingContext });\n        this.jsonParser = new Parser();\n        this.contextJobs = [];\n        this.typeJobs = [];\n        this.contextAwaitingJobs = [];\n        this.lastDepth = 0;\n        this.lastKeys = [];\n        this.lastOnValueJob = Promise.resolve();\n        this.attachJsonParserListeners();\n        this.on('end', () => {\n            if (typeof this.jsonParser.mode !== 'undefined') {\n                this.emit('error', new Error('Unclosed document'));\n            }\n        });\n    }\n    /**\n     * Construct a JsonLdParser from the given HTTP response.\n     *\n     * This will throw an error if no valid JSON response is received\n     * (application/ld+json, application/json, or something+json).\n     *\n     * For raw JSON responses, exactly one link header pointing to a JSON-LD context is required.\n     *\n     * This method is not responsible for handling redirects.\n     *\n     * @param baseIRI The URI of the received response.\n     * @param mediaType The received content type.\n     * @param headers Optional HTTP headers.\n     * @param options Optional parser options.\n     */\n    static fromHttpResponse(baseIRI, mediaType, headers, options) {\n        let context;\n        // Special cases when receiving something else than the JSON-LD media type\n        if (mediaType !== 'application/ld+json') {\n            // Only accept JSON or JSON extension types\n            if (mediaType !== 'application/json' && !mediaType.endsWith('+json')) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Unsupported JSON-LD media type ${mediaType}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n            // We need exactly one JSON-LD context in the link header\n            if (headers && headers.has('Link')) {\n                headers.forEach((value, key) => {\n                    if (key === 'link') {\n                        const linkHeader = http_link_header_1.parse(value);\n                        for (const link of linkHeader.get('rel', 'http://www.w3.org/ns/json-ld#context')) {\n                            if (context) {\n                                throw new jsonld_context_parser_1.ErrorCoded('Multiple JSON-LD context link headers were found on ' + baseIRI, jsonld_context_parser_1.ERROR_CODES.MULTIPLE_CONTEXT_LINK_HEADERS);\n                            }\n                            context = link.uri;\n                        }\n                    }\n                });\n            }\n            if (!context && !(options === null || options === void 0 ? void 0 : options.ignoreMissingContextLinkHeader)) {\n                throw new jsonld_context_parser_1.ErrorCoded(`Missing context link header for media type ${mediaType} on ${baseIRI}`, jsonld_context_parser_1.ERROR_CODES.LOADING_DOCUMENT_FAILED);\n            }\n        }\n        // Check if the streaming profile is present\n        let streamingProfile;\n        if (headers && headers.has('Content-Type')) {\n            const contentType = headers.get('Content-Type');\n            const match = /; *profile=([^\"]*)/.exec(contentType);\n            if (match && match[1] === 'http://www.w3.org/ns/json-ld#streaming') {\n                streamingProfile = true;\n            }\n        }\n        return new JsonLdParser(Object.assign({ baseIRI,\n            context,\n            streamingProfile }, options ? options : {}));\n    }\n    /**\n     * Parses the given text stream into a quad stream.\n     * @param {NodeJS.EventEmitter} stream A text stream.\n     * @return {RDF.Stream} A quad stream.\n     */\n    import(stream) {\n        const output = new stream_1.PassThrough({ readableObjectMode: true });\n        stream.on('error', (error) => parsed.emit('error', error));\n        stream.on('data', (data) => output.push(data));\n        stream.on('end', () => output.push(null));\n        const parsed = output.pipe(new JsonLdParser(this.options));\n        return parsed;\n    }\n    _transform(chunk, encoding, callback) {\n        this.jsonParser.write(chunk);\n        this.lastOnValueJob\n            .then(() => callback(), (error) => callback(error));\n    }\n    /**\n     * Start a new job for parsing the given value.\n     *\n     * This will let the first valid {@link IEntryHandler} handle the entry.\n     *\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        let flushStacks = true;\n        // When we go up the stack, emit all unidentified values\n        // We need to do this before the new job, because the new job may require determined values from the flushed jobs.\n        if (lastDepthCheck && depth < this.lastDepth) {\n            // Check if we had any RDF lists that need to be terminated with an rdf:nil\n            const listPointer = this.parsingContext.listPointerStack[this.lastDepth];\n            if (listPointer) {\n                // Terminate the list if the had at least one value\n                if (listPointer.value) {\n                    this.emit('data', this.util.dataFactory.quad(listPointer.value, this.util.rdfRest, this.util.rdfNil, this.util.getDefaultGraph()));\n                }\n                // Add the list id to the id stack, so it can be used higher up in the stack\n                listPointer.listId.listHead = true;\n                this.parsingContext.idStack[listPointer.listRootDepth + 1] = [listPointer.listId];\n                this.parsingContext.listPointerStack.splice(this.lastDepth, 1);\n            }\n            // Flush the buffer for lastDepth\n            // If the parent key is a special type of container, postpone flushing until that parent is handled.\n            if (await EntryHandlerContainer_1.EntryHandlerContainer.isBufferableContainerHandler(this.parsingContext, this.lastKeys, this.lastDepth)) {\n                this.parsingContext.pendingContainerFlushBuffers\n                    .push({ depth: this.lastDepth, keys: this.lastKeys.slice(0, this.lastKeys.length) });\n                flushStacks = false;\n            }\n            else {\n                await this.flushBuffer(this.lastDepth, this.lastKeys);\n            }\n        }\n        const key = await this.util.unaliasKeyword(keys[depth], keys, depth);\n        const parentKey = await this.util.unaliasKeywordParent(keys, depth);\n        this.parsingContext.emittedStack[depth] = true;\n        let handleKey = true;\n        // Keywords inside @reverse is not allowed apart from @context\n        if (jsonld_context_parser_1.Util.isValidKeyword(key) && parentKey === '@reverse' && key !== '@context') {\n            this.emit('error', new jsonld_context_parser_1.ErrorCoded(`Found the @id '${value}' inside an @reverse property`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_MAP));\n        }\n        // Skip further processing if one of the parent nodes are invalid.\n        // We use the validationStack to reuse validation results that were produced before with common key stacks.\n        let inProperty = false;\n        if (this.parsingContext.validationStack.length > 1) {\n            inProperty = this.parsingContext.validationStack[this.parsingContext.validationStack.length - 1].property;\n        }\n        for (let i = Math.max(1, this.parsingContext.validationStack.length - 1); i < keys.length - 1; i++) {\n            const validationResult = this.parsingContext.validationStack[i]\n                || (this.parsingContext.validationStack[i] = await this.validateKey(keys.slice(0, i + 1), i, inProperty));\n            if (!validationResult.valid) {\n                this.parsingContext.emittedStack[depth] = false;\n                handleKey = false;\n                break;\n            }\n            else if (!inProperty && validationResult.property) {\n                inProperty = true;\n            }\n        }\n        // Skip further processing if this node is part of a literal\n        if (this.util.isLiteral(depth)) {\n            handleKey = false;\n        }\n        // Get handler\n        if (handleKey) {\n            for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n                const testResult = await entryHandler.test(this.parsingContext, this.util, key, keys, depth);\n                if (testResult) {\n                    // Pass processing over to the handler\n                    await entryHandler.handle(this.parsingContext, this.util, key, keys, value, depth, testResult);\n                    // Flag that this depth is processed\n                    if (entryHandler.isStackProcessor()) {\n                        this.parsingContext.processingStack[depth] = true;\n                    }\n                    break;\n                }\n            }\n        }\n        // Validate value indexes on the root.\n        if (depth === 0 && Array.isArray(value)) {\n            await this.util.validateValueIndexes(value);\n        }\n        // When we go up the stack, flush the old stack\n        if (flushStacks && depth < this.lastDepth) {\n            // Reset our stacks\n            this.flushStacks(this.lastDepth);\n        }\n        this.lastDepth = depth;\n        this.lastKeys = keys;\n        // Clear the keyword cache at this depth, and everything underneath.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(depth - 1);\n    }\n    /**\n     * Flush the processing stacks at the given depth.\n     * @param {number} depth A depth.\n     */\n    flushStacks(depth) {\n        this.parsingContext.processingStack.splice(depth, 1);\n        this.parsingContext.processingType.splice(depth, 1);\n        this.parsingContext.emittedStack.splice(depth, 1);\n        this.parsingContext.idStack.splice(depth, 1);\n        this.parsingContext.graphStack.splice(depth + 1, 1);\n        this.parsingContext.graphContainerTermStack.splice(depth, 1);\n        this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        this.parsingContext.validationStack.splice(depth - 1, 2);\n        this.parsingContext.literalStack.splice(depth, this.parsingContext.literalStack.length - depth);\n        // TODO: just like the literal stack, splice all other stack until the end as well?\n    }\n    /**\n     * Flush buffers for the given depth.\n     *\n     * This should be called after the last entry at a given depth was processed.\n     *\n     * @param {number} depth A depth.\n     * @param {any[]} keys A stack of keys.\n     * @return {Promise<void>} A promise resolving if flushing is done.\n     */\n    async flushBuffer(depth, keys) {\n        let subjects = this.parsingContext.idStack[depth];\n        if (!subjects) {\n            subjects = this.parsingContext.idStack[depth] = [this.util.dataFactory.blankNode()];\n        }\n        // Flush values at this level\n        const valueBuffer = this.parsingContext.unidentifiedValuesBuffer[depth];\n        if (valueBuffer) {\n            for (const subject of subjects) {\n                const depthOffsetGraph = await this.util.getDepthOffsetGraph(depth, keys);\n                const graphs = (this.parsingContext.graphStack[depth] || depthOffsetGraph >= 0)\n                    ? this.parsingContext.idStack[depth - depthOffsetGraph - 1]\n                    : [await this.util.getGraphContainerValue(keys, depth)];\n                if (graphs) {\n                    for (const graph of graphs) {\n                        // Flush values to stream if the graph @id is known\n                        this.parsingContext.emittedStack[depth] = true;\n                        for (const bufferedValue of valueBuffer) {\n                            if (bufferedValue.reverse) {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.object, bufferedValue.predicate, subject, graph));\n                            }\n                            else {\n                                this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(subject, bufferedValue.predicate, bufferedValue.object, graph));\n                            }\n                        }\n                    }\n                }\n                else {\n                    // Place the values in the graphs buffer if the graph @id is not yet known\n                    const subGraphBuffer = this.parsingContext.getUnidentifiedGraphBufferSafe(depth - await this.util.getDepthOffsetGraph(depth, keys) - 1);\n                    for (const bufferedValue of valueBuffer) {\n                        if (bufferedValue.reverse) {\n                            subGraphBuffer.push({\n                                object: subject,\n                                predicate: bufferedValue.predicate,\n                                subject: bufferedValue.object,\n                            });\n                        }\n                        else {\n                            subGraphBuffer.push({\n                                object: bufferedValue.object,\n                                predicate: bufferedValue.predicate,\n                                subject,\n                            });\n                        }\n                    }\n                }\n            }\n            this.parsingContext.unidentifiedValuesBuffer.splice(depth, 1);\n            this.parsingContext.literalStack.splice(depth, 1);\n            this.parsingContext.jsonLiteralStack.splice(depth, 1);\n        }\n        // Flush graphs at this level\n        const graphBuffer = this.parsingContext.unidentifiedGraphsBuffer[depth];\n        if (graphBuffer) {\n            for (const subject of subjects) {\n                // A @graph statement at the root without @id relates to the default graph,\n                // unless there are top-level properties,\n                // others relate to blank nodes.\n                const graph = depth === 1 && subject.termType === 'BlankNode'\n                    && !this.parsingContext.topLevelProperties ? this.util.getDefaultGraph() : subject;\n                this.parsingContext.emittedStack[depth] = true;\n                for (const bufferedValue of graphBuffer) {\n                    this.parsingContext.emitQuad(depth, this.util.dataFactory.quad(bufferedValue.subject, bufferedValue.predicate, bufferedValue.object, graph));\n                }\n            }\n            this.parsingContext.unidentifiedGraphsBuffer.splice(depth, 1);\n        }\n    }\n    /**\n     * Check if at least one {@link IEntryHandler} validates the entry to true.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth A depth.\n     * @param {boolean} inProperty If the current depth is part of a valid property node.\n     * @return {Promise<{ valid: boolean, property: boolean }>} A promise resolving to true or false.\n     */\n    async validateKey(keys, depth, inProperty) {\n        for (const entryHandler of JsonLdParser.ENTRY_HANDLERS) {\n            if (await entryHandler.validate(this.parsingContext, this.util, keys, depth, inProperty)) {\n                return { valid: true, property: inProperty || entryHandler.isPropertyHandler() };\n            }\n        }\n        return { valid: false, property: false };\n    }\n    /**\n     * Attach all required listeners to the JSON parser.\n     *\n     * This should only be called once.\n     */\n    attachJsonParserListeners() {\n        // Listen to json parser events\n        this.jsonParser.onValue = (value) => {\n            const depth = this.jsonParser.stack.length;\n            const keys = (new Array(depth + 1).fill(0)).map((v, i) => {\n                return i === depth ? this.jsonParser.key : this.jsonParser.stack[i].key;\n            });\n            if (!this.isParsingContextInner(depth)) { // Don't parse inner nodes inside @context\n                const valueJobCb = () => this.newOnValueJob(keys, value, depth, true);\n                if (!this.parsingContext.streamingProfile\n                    && !this.parsingContext.contextTree.getContext(keys.slice(0, -1))) {\n                    // If an out-of-order context is allowed,\n                    // we have to buffer everything.\n                    // We store jobs for @context's and @type's separately,\n                    // because at the end, we have to process them first.\n                    // We also handle @type because these *could* introduce a type-scoped context.\n                    if (keys[depth] === '@context') {\n                        let jobs = this.contextJobs[depth];\n                        if (!jobs) {\n                            jobs = this.contextJobs[depth] = [];\n                        }\n                        jobs.push(valueJobCb);\n                    }\n                    else if (keys[depth] === '@type'\n                        || typeof keys[depth] === 'number' && keys[depth - 1] === '@type') { // Also capture @type with array values\n                        // Remove @type from keys, because we want it to apply to parent later on\n                        this.typeJobs.push({ job: valueJobCb, keys: keys.slice(0, keys.length - 1) });\n                    }\n                    else {\n                        this.contextAwaitingJobs.push({ job: valueJobCb, keys });\n                    }\n                }\n                else {\n                    // Make sure that our value jobs are chained synchronously\n                    this.lastOnValueJob = this.lastOnValueJob.then(valueJobCb);\n                }\n                // Execute all buffered jobs on deeper levels\n                if (!this.parsingContext.streamingProfile && depth === 0) {\n                    this.lastOnValueJob = this.lastOnValueJob\n                        .then(() => this.executeBufferedJobs());\n                }\n            }\n        };\n        this.jsonParser.onError = (error) => {\n            this.emit('error', error);\n        };\n    }\n    /**\n     * Check if the parser is currently parsing an element that is part of an @context entry.\n     * @param {number} depth A depth.\n     * @return {boolean} A boolean.\n     */\n    isParsingContextInner(depth) {\n        for (let i = depth; i > 0; i--) {\n            if (this.jsonParser.stack[i - 1].key === '@context') {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Execute all buffered jobs.\n     * @return {Promise<void>} A promise resolving if all jobs are finished.\n     */\n    async executeBufferedJobs() {\n        // Handle context jobs\n        for (const jobs of this.contextJobs) {\n            if (jobs) {\n                for (const job of jobs) {\n                    await job();\n                }\n            }\n        }\n        // Clear the keyword cache.\n        this.parsingContext.unaliasedKeywordCacheStack.splice(0);\n        // Handle non-context jobs\n        for (const job of this.contextAwaitingJobs) {\n            // Check if we have a type (with possible type-scoped context) that should be handled before.\n            // We check all possible parent nodes for the current job, from root to leaves.\n            if (this.typeJobs.length > 0) {\n                // First collect all applicable type jobs\n                const applicableTypeJobs = [];\n                const applicableTypeJobIds = [];\n                for (let i = 0; i < this.typeJobs.length; i++) {\n                    const typeJob = this.typeJobs[i];\n                    if (Util_1.Util.isPrefixArray(typeJob.keys, job.keys)) {\n                        applicableTypeJobs.push(typeJob);\n                        applicableTypeJobIds.push(i);\n                    }\n                }\n                // Next, sort the jobs from short to long key length (to ensure types higher up in the tree to be handled first)\n                const sortedTypeJobs = applicableTypeJobs.sort((job1, job2) => job1.keys.length - job2.keys.length);\n                // Finally, execute the jobs in order\n                for (const typeJob of sortedTypeJobs) {\n                    await typeJob.job();\n                }\n                // Remove the executed type jobs\n                // Sort first, so we can efficiently splice\n                const sortedApplicableTypeJobIds = applicableTypeJobIds.sort().reverse();\n                for (const jobId of sortedApplicableTypeJobIds) {\n                    this.typeJobs.splice(jobId, 1);\n                }\n            }\n            await job.job();\n        }\n    }\n}\nexports.JsonLdParser = JsonLdParser;\nJsonLdParser.DEFAULT_PROCESSING_MODE = '1.1';\nJsonLdParser.ENTRY_HANDLERS = [\n    new EntryHandlerArrayValue_1.EntryHandlerArrayValue(),\n    new EntryHandlerKeywordContext_1.EntryHandlerKeywordContext(),\n    new EntryHandlerKeywordId_1.EntryHandlerKeywordId(),\n    new EntryHandlerKeywordIncluded_1.EntryHandlerKeywordIncluded(),\n    new EntryHandlerKeywordGraph_1.EntryHandlerKeywordGraph(),\n    new EntryHandlerKeywordNest_1.EntryHandlerKeywordNest(),\n    new EntryHandlerKeywordType_1.EntryHandlerKeywordType(),\n    new EntryHandlerKeywordValue_1.EntryHandlerKeywordValue(),\n    new EntryHandlerContainer_1.EntryHandlerContainer(),\n    new EntryHandlerKeywordUnknownFallback_1.EntryHandlerKeywordUnknownFallback(),\n    new EntryHandlerPredicate_1.EntryHandlerPredicate(),\n    new EntryHandlerInvalidFallback_1.EntryHandlerInvalidFallback(),\n];\n//# sourceMappingURL=JsonLdParser.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ParsingContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst ErrorCoded_1 = require(\"jsonld-context-parser/lib/ErrorCoded\");\nconst ContextTree_1 = require(\"./ContextTree\");\nconst JsonLdParser_1 = require(\"./JsonLdParser\");\n/**\n * Data holder for parsing information.\n */\nclass ParsingContext {\n    constructor(options) {\n        // Initialize settings\n        this.contextParser = new jsonld_context_parser_1.ContextParser({ documentLoader: options.documentLoader, skipValidation: options.skipContextValidation });\n        this.streamingProfile = !!options.streamingProfile;\n        this.baseIRI = options.baseIRI;\n        this.produceGeneralizedRdf = !!options.produceGeneralizedRdf;\n        this.allowSubjectList = !!options.allowSubjectList;\n        this.processingMode = options.processingMode || JsonLdParser_1.JsonLdParser.DEFAULT_PROCESSING_MODE;\n        this.strictValues = !!options.strictValues;\n        this.validateValueIndexes = !!options.validateValueIndexes;\n        this.defaultGraph = options.defaultGraph;\n        this.rdfDirection = options.rdfDirection;\n        this.normalizeLanguageTags = options.normalizeLanguageTags;\n        this.streamingProfileAllowOutOfOrderPlainType = options.streamingProfileAllowOutOfOrderPlainType;\n        this.topLevelProperties = false;\n        this.activeProcessingMode = parseFloat(this.processingMode);\n        // Initialize stacks\n        this.processingStack = [];\n        this.processingType = [];\n        this.emittedStack = [];\n        this.idStack = [];\n        this.graphStack = [];\n        this.graphContainerTermStack = [];\n        this.listPointerStack = [];\n        this.contextTree = new ContextTree_1.ContextTree();\n        this.literalStack = [];\n        this.validationStack = [];\n        this.unaliasedKeywordCacheStack = [];\n        this.jsonLiteralStack = [];\n        this.unidentifiedValuesBuffer = [];\n        this.unidentifiedGraphsBuffer = [];\n        this.pendingContainerFlushBuffers = [];\n        this.parser = options.parser;\n        if (options.context) {\n            this.rootContext = this.parseContext(options.context);\n            this.rootContext.then((context) => this.validateContext(context));\n        }\n        else {\n            this.rootContext = Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(this.baseIRI ? { '@base': this.baseIRI, '@__baseDocument': true } : {}));\n        }\n    }\n    /**\n     * Parse the given context with the configured options.\n     * @param {JsonLdContext} context A context to parse.\n     * @param {JsonLdContextNormalized} parentContext An optional parent context.\n     * @param {boolean} ignoreProtection If @protected term checks should be ignored.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to the parsed context.\n     */\n    async parseContext(context, parentContext, ignoreProtection) {\n        return this.contextParser.parse(context, {\n            baseIRI: this.baseIRI,\n            ignoreProtection,\n            normalizeLanguageTags: this.normalizeLanguageTags,\n            parentContext,\n            processingMode: this.activeProcessingMode,\n        });\n    }\n    /**\n     * Check if the given context is valid.\n     * If not, an error will be thrown.\n     * @param {JsonLdContextNormalized} context A context.\n     */\n    validateContext(context) {\n        const activeVersion = context.getContextRaw()['@version'];\n        if (activeVersion) {\n            if (this.activeProcessingMode && activeVersion > this.activeProcessingMode) {\n                throw new ErrorCoded_1.ErrorCoded(`Unsupported JSON-LD version '${activeVersion}' under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.PROCESSING_MODE_CONFLICT);\n            }\n            else {\n                if (this.activeProcessingMode && activeVersion < this.activeProcessingMode) {\n                    throw new ErrorCoded_1.ErrorCoded(`Invalid JSON-LD version ${activeVersion} under active processing mode ${this.activeProcessingMode}.`, ErrorCoded_1.ERROR_CODES.INVALID_VERSION_VALUE);\n                }\n                this.activeProcessingMode = activeVersion;\n            }\n        }\n    }\n    /**\n     * Get the context at the given path.\n     * @param {keys} keys The path of keys to get the context at.\n     * @param {number} offset The path offset, defaults to 1.\n     * @return {Promise<JsonLdContextNormalized>} A promise resolving to a context.\n     */\n    async getContext(keys, offset = 1) {\n        const keysOriginal = keys;\n        // Ignore array keys at the end\n        while (typeof keys[keys.length - 1] === 'number') {\n            keys = keys.slice(0, keys.length - 1);\n        }\n        // Handle offset on keys\n        if (offset) {\n            keys = keys.slice(0, -offset);\n        }\n        // Determine the closest context\n        const contextData = await this.getContextPropagationAware(keys);\n        const context = contextData.context;\n        // Process property-scoped contexts (high-to-low)\n        let contextRaw = context.getContextRaw();\n        for (let i = contextData.depth; i < keysOriginal.length - offset; i++) {\n            const key = keysOriginal[i];\n            const contextKeyEntry = contextRaw[key];\n            if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n                const scopedContext = (await this.parseContext(contextKeyEntry, contextRaw, true)).getContextRaw();\n                const propagate = !(key in scopedContext)\n                    || scopedContext[key]['@context']['@propagate']; // Propagation is true by default\n                if (propagate !== false || i === keysOriginal.length - 1 - offset) {\n                    contextRaw = scopedContext;\n                    // Clean up final context\n                    delete contextRaw['@propagate'];\n                    contextRaw[key] = Object.assign({}, contextRaw[key]);\n                    if ('@id' in contextKeyEntry) {\n                        contextRaw[key]['@id'] = contextKeyEntry['@id'];\n                    }\n                    delete contextRaw[key]['@context'];\n                    if (propagate !== false) {\n                        this.contextTree.setContext(keysOriginal.slice(0, i + offset), Promise.resolve(new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw)));\n                    }\n                }\n            }\n        }\n        return new jsonld_context_parser_1.JsonLdContextNormalized(contextRaw);\n    }\n    /**\n     * Get the context at the given path.\n     * Non-propagating contexts will be skipped,\n     * unless the context at that exact depth is retrieved.\n     *\n     * This ONLY takes into account context propagation logic,\n     * so this should usually not be called directly,\n     * call {@link #getContext} instead.\n     *\n     * @param keys The path of keys to get the context at.\n     * @return {Promise<{ context: JsonLdContextNormalized, depth: number }>} A context and its depth.\n     */\n    async getContextPropagationAware(keys) {\n        const originalDepth = keys.length;\n        let contextData = null;\n        let hasApplicablePropertyScopedContext;\n        do {\n            hasApplicablePropertyScopedContext = false;\n            if (contextData && '@__propagateFallback' in contextData.context.getContextRaw()) {\n                // If a propagation fallback context has been set,\n                // fallback to that context and retry for the same depth.\n                contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized(contextData.context.getContextRaw()['@__propagateFallback']);\n            }\n            else {\n                if (contextData) {\n                    // If we had a previous iteration, jump to the parent of context depth.\n                    // We must do this because once we get here, last context had propagation disabled,\n                    // so we check its first parent instead.\n                    keys = keys.slice(0, contextData.depth - 1);\n                }\n                contextData = await this.contextTree.getContext(keys) || { context: await this.rootContext, depth: 0 };\n            }\n            // Allow non-propagating contexts to propagate one level deeper\n            // if it defines a property-scoped context that is applicable for the current key.\n            // @see https://w3c.github.io/json-ld-api/tests/toRdf-manifest#tc012\n            const lastKey = keys[keys.length - 1];\n            if (lastKey in contextData.context.getContextRaw()) {\n                const lastKeyValue = contextData.context.getContextRaw()[lastKey];\n                if (lastKeyValue && typeof lastKeyValue === 'object' && '@context' in lastKeyValue) {\n                    hasApplicablePropertyScopedContext = true;\n                }\n            }\n        } while (contextData.depth > 0 // Root context has a special case\n            && contextData.context.getContextRaw()['@propagate'] === false // Stop loop if propagation is true\n            && contextData.depth !== originalDepth // Stop loop if requesting exact depth of non-propagating\n            && !hasApplicablePropertyScopedContext);\n        // Special case for root context that does not allow propagation.\n        // Fallback to empty context in that case.\n        if (contextData.depth === 0\n            && contextData.context.getContextRaw()['@propagate'] === false\n            && contextData.depth !== originalDepth) {\n            contextData.context = new jsonld_context_parser_1.JsonLdContextNormalized({});\n        }\n        return contextData;\n    }\n    /**\n     * Start a new job for parsing the given value.\n     * @param {any[]} keys The stack of keys.\n     * @param value The value to parse.\n     * @param {number} depth The depth to parse at.\n     * @param {boolean} lastDepthCheck If the lastDepth check should be done for buffer draining.\n     * @return {Promise<void>} A promise resolving when the job is done.\n     */\n    async newOnValueJob(keys, value, depth, lastDepthCheck) {\n        await this.parser.newOnValueJob(keys, value, depth, lastDepthCheck);\n    }\n    /**\n     * Flush the pending container flush buffers\n     * @return {boolean} If any pending buffers were flushed.\n     */\n    async handlePendingContainerFlushBuffers() {\n        if (this.pendingContainerFlushBuffers.length > 0) {\n            for (const pendingFlushBuffer of this.pendingContainerFlushBuffers) {\n                await this.parser.flushBuffer(pendingFlushBuffer.depth, pendingFlushBuffer.keys);\n                this.parser.flushStacks(pendingFlushBuffer.depth);\n            }\n            this.pendingContainerFlushBuffers.splice(0, this.pendingContainerFlushBuffers.length);\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    /**\n     * Emit the given quad into the output stream.\n     * @param {number} depth The depth the quad was generated at.\n     * @param {Quad} quad A quad to emit.\n     */\n    emitQuad(depth, quad) {\n        if (depth === 1) {\n            this.topLevelProperties = true;\n        }\n        this.parser.push(quad);\n    }\n    /**\n     * Emit the given error into the output stream.\n     * @param {Error} error An error to emit.\n     */\n    emitError(error) {\n        this.parser.emit('error', error);\n    }\n    /**\n     * Emit the given context into the output stream under the 'context' event.\n     * @param {JsonLdContext} context A context to emit.\n     */\n    emitContext(context) {\n        this.parser.emit('context', context);\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedValuesBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedValuesBuffer}.\n     */\n    getUnidentifiedValueBufferSafe(depth) {\n        let buffer = this.unidentifiedValuesBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedValuesBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * Safely get or create the depth value of {@link ParsingContext.unidentifiedGraphsBuffer}.\n     * @param {number} depth A depth.\n     * @return {{predicate: Term; object: Term; reverse: boolean}[]} An element of\n     *                                                               {@link ParsingContext.unidentifiedGraphsBuffer}.\n     */\n    getUnidentifiedGraphBufferSafe(depth) {\n        let buffer = this.unidentifiedGraphsBuffer[depth];\n        if (!buffer) {\n            buffer = [];\n            this.unidentifiedGraphsBuffer[depth] = buffer;\n        }\n        return buffer;\n    }\n    /**\n     * @return IExpandOptions The expand options for the active processing mode.\n     */\n    getExpandOptions() {\n        return ParsingContext.EXPAND_OPTIONS[this.activeProcessingMode];\n    }\n    /**\n     * Shift the stack at the given offset to the given depth.\n     *\n     * This will override anything in the stack at `depth`,\n     * and this will remove anything at `depth + depthOffset`\n     *\n     * @param depth The target depth.\n     * @param depthOffset The origin depth, relative to `depth`.\n     */\n    shiftStack(depth, depthOffset) {\n        // Copy the id stack value up one level so that the next job can access the id.\n        const deeperIdStack = this.idStack[depth + depthOffset];\n        if (deeperIdStack) {\n            this.idStack[depth] = deeperIdStack;\n            this.emittedStack[depth] = true;\n            delete this.idStack[depth + depthOffset];\n        }\n        // Shorten key stack\n        if (this.pendingContainerFlushBuffers.length) {\n            for (const buffer of this.pendingContainerFlushBuffers) {\n                if (buffer.depth >= depth + depthOffset) {\n                    buffer.depth -= depthOffset;\n                    buffer.keys.splice(depth, depthOffset);\n                }\n            }\n        }\n        // Splice stacks\n        if (this.unidentifiedValuesBuffer[depth + depthOffset]) {\n            this.unidentifiedValuesBuffer[depth] = this.unidentifiedValuesBuffer[depth + depthOffset];\n            delete this.unidentifiedValuesBuffer[depth + depthOffset];\n        }\n        // TODO: also do the same for other stacks\n    }\n}\nexports.ParsingContext = ParsingContext;\nParsingContext.EXPAND_OPTIONS = {\n    1.0: {\n        allowPrefixForcing: false,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: false,\n    },\n    1.1: {\n        allowPrefixForcing: true,\n        allowPrefixNonGenDelims: false,\n        allowVocabRelativeToBase: true,\n    },\n};\n//# sourceMappingURL=ParsingContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Util = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst rdf_data_factory_1 = require(\"rdf-data-factory\");\nconst EntryHandlerContainer_1 = require(\"./entryhandler/EntryHandlerContainer\");\n// tslint:disable-next-line:no-var-requires\nconst canonicalizeJson = require('canonicalize');\n/**\n * Utility functions and methods.\n */\nclass Util {\n    constructor(options) {\n        this.parsingContext = options.parsingContext;\n        this.dataFactory = options.dataFactory || new rdf_data_factory_1.DataFactory();\n        this.rdfFirst = this.dataFactory.namedNode(Util.RDF + 'first');\n        this.rdfRest = this.dataFactory.namedNode(Util.RDF + 'rest');\n        this.rdfNil = this.dataFactory.namedNode(Util.RDF + 'nil');\n        this.rdfType = this.dataFactory.namedNode(Util.RDF + 'type');\n        this.rdfJson = this.dataFactory.namedNode(Util.RDF + 'JSON');\n    }\n    /**\n     * Helper function to get the value of a context entry,\n     * or fallback to a certain value.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} contextKey A pre-defined JSON-LD key in context entries.\n     * @param {string} key A context entry key.\n     * @param {string} fallback A fallback value for when the given contextKey\n     *                          could not be found in the value with the given key.\n     * @return {string} The value of the given contextKey in the entry behind key in the given context,\n     *                  or the given fallback value.\n     */\n    static getContextValue(context, contextKey, key, fallback) {\n        const entry = context.getContextRaw()[key];\n        if (!entry) {\n            return fallback;\n        }\n        const type = entry[contextKey];\n        return type === undefined ? fallback : type;\n    }\n    /**\n     * Get the container type of the given key in the context.\n     *\n     * Should any context-scoping bugs should occur related to this in the future,\n     * it may be required to increase the offset from the depth at which the context is retrieved by one (to 2).\n     * This is because containers act 2 levels deep.\n     *\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The container type.\n     */\n    static getContextValueContainer(context, key) {\n        return Util.getContextValue(context, '@container', key, { '@set': true });\n    }\n    /**\n     * Get the value type of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueType(context, key) {\n        const valueType = Util.getContextValue(context, '@type', key, null);\n        if (valueType === '@none') {\n            return null;\n        }\n        return valueType;\n    }\n    /**\n     * Get the language of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueLanguage(context, key) {\n        return Util.getContextValue(context, '@language', key, context.getContextRaw()['@language'] || null);\n    }\n    /**\n     * Get the direction of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The node type.\n     */\n    static getContextValueDirection(context, key) {\n        return Util.getContextValue(context, '@direction', key, context.getContextRaw()['@direction'] || null);\n    }\n    /**\n     * Check if the given key in the context is a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {boolean} If the context value has a @reverse key.\n     */\n    static isContextValueReverse(context, key) {\n        return !!Util.getContextValue(context, '@reverse', key, null);\n    }\n    /**\n     * Get the @index of the given key in the context.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key A context entry key.\n     * @return {string} The index.\n     */\n    static getContextValueIndex(context, key) {\n        return Util.getContextValue(context, '@index', key, context.getContextRaw()['@index'] || null);\n    }\n    /**\n     * Check if the given key refers to a reversed property.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The property key.\n     * @param {string} parentKey The parent key.\n     * @return {boolean} If the property must be reversed.\n     */\n    static isPropertyReverse(context, key, parentKey) {\n        // '!==' is needed because reversed properties in a @reverse container should cancel each other out.\n        return parentKey === '@reverse' !== Util.isContextValueReverse(context, key);\n    }\n    /**\n     * Check if the given IRI is valid.\n     * @param {string} iri A potential IRI.\n     * @return {boolean} If the given IRI is valid.\n     */\n    static isValidIri(iri) {\n        return iri !== null && jsonld_context_parser_1.Util.isValidIri(iri);\n    }\n    /**\n     * Check if the given first array (needle) is a prefix of the given second array (haystack).\n     * @param needle An array to check if it is a prefix.\n     * @param haystack An array to look in.\n     */\n    static isPrefixArray(needle, haystack) {\n        if (needle.length > haystack.length) {\n            return false;\n        }\n        for (let i = 0; i < needle.length; i++) {\n            if (needle[i] !== haystack[i]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /**\n     * Make sure that @id-@index pairs are equal over all array values.\n     * Reject otherwise.\n     * @param {any[]} value An array value.\n     * @return {Promise<void>} A promise rejecting if conflicts are present.\n     */\n    async validateValueIndexes(value) {\n        if (this.parsingContext.validateValueIndexes) {\n            const indexHashes = {};\n            for (const entry of value) {\n                if (entry && typeof entry === 'object') {\n                    const id = entry['@id'];\n                    const index = entry['@index'];\n                    if (id && index) {\n                        const existingIndexValue = indexHashes[id];\n                        if (existingIndexValue && existingIndexValue !== index) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Conflicting @index value for ${id}`, jsonld_context_parser_1.ERROR_CODES.CONFLICTING_INDEXES);\n                        }\n                        indexHashes[id] = index;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Convert a given JSON value to an RDF term.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param value A JSON value.\n     * @param {number} depth The depth the value is at.\n     * @param {string[]} keys The path of keys.\n     * @return {Promise<RDF.Term[]>} An RDF term array.\n     */\n    async valueToTerm(context, key, value, depth, keys) {\n        // Skip further processing if we have an @type: @json\n        if (Util.getContextValueType(context, key) === '@json') {\n            return [this.dataFactory.literal(this.valueToJsonString(value), this.rdfJson)];\n        }\n        const type = typeof value;\n        switch (type) {\n            case 'object':\n                // Skip if we have a null or undefined object\n                if (value === null || value === undefined) {\n                    return [];\n                }\n                // Special case for arrays\n                if (Array.isArray(value)) {\n                    // We handle arrays at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty context-based lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if ('@list' in Util.getContextValueContainer(context, key)) {\n                        if (value.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    await this.validateValueIndexes(value);\n                    return [];\n                }\n                // Handle property-scoped contexts\n                context = await this.getContextSelfOrPropertyScoped(context, key);\n                // Handle local context in the value\n                if ('@context' in value) {\n                    context = await this.parsingContext.parseContext(value['@context'], (await this.parsingContext.getContext(keys, 0)).getContextRaw());\n                }\n                // In all other cases, we have a hash\n                value = await this.unaliasKeywords(value, keys, depth, context); // Un-alias potential keywords in this hash\n                if ('@value' in value) {\n                    let val;\n                    let valueLanguage;\n                    let valueDirection;\n                    let valueType;\n                    let valueIndex; // We don't use the index, but we need to check its type for spec-compliance\n                    for (key in value) {\n                        const subValue = value[key];\n                        switch (key) {\n                            case '@value':\n                                val = subValue;\n                                break;\n                            case '@language':\n                                valueLanguage = subValue;\n                                break;\n                            case '@direction':\n                                valueDirection = subValue;\n                                break;\n                            case '@type':\n                                valueType = subValue;\n                                break;\n                            case '@index':\n                                valueIndex = subValue;\n                                break;\n                            default:\n                                throw new jsonld_context_parser_1.ErrorCoded(`Unknown value entry '${key}' in @value: ${JSON.stringify(value)}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                    }\n                    // Skip further processing if we have an @type: @json\n                    if (await this.unaliasKeyword(valueType, keys, depth, true, context) === '@json') {\n                        return [this.dataFactory.literal(this.valueToJsonString(val), this.rdfJson)];\n                    }\n                    // Validate @value\n                    if (val === null) {\n                        return [];\n                    }\n                    if (typeof val === 'object') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@value' can not be an object, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT_VALUE);\n                    }\n                    // Validate @index\n                    if (this.parsingContext.validateValueIndexes && valueIndex && typeof valueIndex !== 'string') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@index' must be a string, got '${JSON.stringify(valueIndex)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE);\n                    }\n                    // Validate @language and @direction\n                    if (valueLanguage) {\n                        if (typeof val !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`When an '@language' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_VALUE);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateLanguage(valueLanguage, this.parsingContext.strictValues, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_TAGGED_STRING)) {\n                            return [];\n                        }\n                        // Language tags are always normalized to lowercase in 1.0.\n                        if (this.parsingContext.normalizeLanguageTags || this.parsingContext.activeProcessingMode === 1.0) {\n                            valueLanguage = valueLanguage.toLowerCase();\n                        }\n                    }\n                    if (valueDirection) {\n                        if (typeof val !== 'string') {\n                            throw new Error(`When an '@direction' is set, the value of '@value' must be a string, got '${JSON.stringify(val)}'`);\n                        }\n                        if (!jsonld_context_parser_1.ContextParser.validateDirection(valueDirection, this.parsingContext.strictValues)) {\n                            return [];\n                        }\n                    }\n                    // Check @language and @direction\n                    if (valueLanguage && valueDirection && this.parsingContext.rdfDirection) {\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have '@language', '@direction' and '@type' in a value: '${JSON\n                                .stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueLanguage) { // Check @language\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@language' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return [this.dataFactory.literal(val, valueLanguage)];\n                    }\n                    else if (valueDirection && this.parsingContext.rdfDirection) { // Check @direction\n                        if (valueType) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Can not have both '@direction' and '@type' in a value: '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                        }\n                        return this.nullableTermToArray(this\n                            .createLanguageDirectionLiteral(depth, val, valueLanguage, valueDirection));\n                    }\n                    else if (valueType) { // Validate @type\n                        if (typeof valueType !== 'string') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`The value of an '@type' must be a string, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        const typeTerm = this.createVocabOrBaseTerm(context, valueType);\n                        if (!typeTerm) {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Invalid '@type' value, got '${JSON.stringify(valueType)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        if (typeTerm.termType !== 'NamedNode') {\n                            throw new jsonld_context_parser_1.ErrorCoded(`Illegal value type (${typeTerm.termType}): ${valueType}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPED_VALUE);\n                        }\n                        return [this.dataFactory.literal(val, typeTerm)];\n                    }\n                    // We don't pass the context, because context-based things like @language should be ignored\n                    return await this.valueToTerm(new jsonld_context_parser_1.JsonLdContextNormalized({}), key, val, depth, keys);\n                }\n                else if ('@set' in value) {\n                    // No other entries are allow in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @set for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    // No need to do anything here, this is handled at the deeper level.\n                    return [];\n                }\n                else if ('@list' in value) {\n                    // No other entries are allowed in this value\n                    if (Object.keys(value).length > 1) {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT);\n                    }\n                    const listValue = value[\"@list\"];\n                    // We handle lists at value level so we can emit earlier, so this is handled already when we get here.\n                    // Empty anonymous lists are emitted at this place, because our streaming algorithm doesn't detect those.\n                    if (Array.isArray(listValue)) {\n                        if (listValue.length === 0) {\n                            return [this.rdfNil];\n                        }\n                        else {\n                            return this.parsingContext.idStack[depth + 1] || [];\n                        }\n                    }\n                    else {\n                        // We only have a single list element here, so emit this directly as single element\n                        return await this.valueToTerm(await this.parsingContext.getContext(keys), key, listValue, depth - 1, keys.slice(0, -1));\n                    }\n                }\n                else if ('@reverse' in value && typeof value['@reverse'] === 'boolean') {\n                    // We handle reverse properties at value level so we can emit earlier,\n                    // so this is handled already when we get here.\n                    return [];\n                }\n                else if ('@graph' in Util.getContextValueContainer(await this.parsingContext.getContext(keys), key)) {\n                    // We are processing a graph container\n                    const graphContainerEntries = this.parsingContext.graphContainerTermStack[depth + 1];\n                    return graphContainerEntries ? Object.values(graphContainerEntries) : [this.dataFactory.blankNode()];\n                }\n                else if (\"@id\" in value) {\n                    // Use deeper context if the value node contains other properties next to @id.\n                    if (Object.keys(value).length > 1) {\n                        context = await this.parsingContext.getContext(keys, 0);\n                    }\n                    // Handle local context in the value\n                    if ('@context' in value) {\n                        context = await this.parsingContext.parseContext(value['@context'], context.getContextRaw());\n                    }\n                    if (value[\"@type\"] === '@vocab') {\n                        return this.nullableTermToArray(this.createVocabOrBaseTerm(context, value[\"@id\"]));\n                    }\n                    else {\n                        return this.nullableTermToArray(this.resourceToTerm(context, value[\"@id\"]));\n                    }\n                }\n                else {\n                    // Only make a blank node if at least one triple was emitted at the value's level.\n                    if (this.parsingContext.emittedStack[depth + 1]\n                        || (value && typeof value === 'object' && Object.keys(value).length === 0)) {\n                        return (this.parsingContext.idStack[depth + 1]\n                            || (this.parsingContext.idStack[depth + 1] = [this.dataFactory.blankNode()]));\n                    }\n                    else {\n                        return [];\n                    }\n                }\n            case 'string':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, null));\n            case 'boolean':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, Boolean(value).toString(), this.dataFactory.namedNode(Util.XSD_BOOLEAN)));\n            case 'number':\n                return this.nullableTermToArray(this.stringValueToTerm(depth, await this.getContextSelfOrPropertyScoped(context, key), key, value, this.dataFactory.namedNode(value % 1 === 0 && value < 1e21 ? Util.XSD_INTEGER : Util.XSD_DOUBLE)));\n            default:\n                this.parsingContext.emitError(new Error(`Could not determine the RDF type of a ${type}`));\n                return [];\n        }\n    }\n    /**\n     * If the context defines a property-scoped context for the given key,\n     * that context will be returned.\n     * Otherwise, the given context will be returned as-is.\n     *\n     * This should be used for valueToTerm cases that are not objects.\n     * @param context A context.\n     * @param key A JSON key.\n     */\n    async getContextSelfOrPropertyScoped(context, key) {\n        const contextKeyEntry = context.getContextRaw()[key];\n        if (contextKeyEntry && typeof contextKeyEntry === 'object' && '@context' in contextKeyEntry) {\n            context = await this.parsingContext.parseContext(contextKeyEntry, context.getContextRaw(), true);\n        }\n        return context;\n    }\n    /**\n     * If the given term is null, return an empty array, otherwise return an array with the single given term.\n     * @param term A term.\n     */\n    nullableTermToArray(term) {\n        return term ? [term] : [];\n    }\n    /**\n     * Convert a given JSON key to an RDF predicate term,\n     * based on @vocab.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node.\n     */\n    predicateToTerm(context, key) {\n        const expanded = context.expandTerm(key, true, this.parsingContext.getExpandOptions());\n        // Immediately return if the predicate was disabled in the context\n        if (!expanded) {\n            return null;\n        }\n        // Check if the predicate is a blank node\n        if (expanded[0] === '_' && expanded[1] === ':') {\n            if (this.parsingContext.produceGeneralizedRdf) {\n                return this.dataFactory.blankNode(expanded.substr(2));\n            }\n            else {\n                return null;\n            }\n        }\n        // Check if the predicate is a valid IRI\n        if (Util.isValidIri(expanded)) {\n            return this.dataFactory.namedNode(expanded);\n        }\n        else {\n            if (expanded && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid predicate IRI: ${expanded}`, jsonld_context_parser_1.ERROR_CODES.INVALID_IRI_MAPPING));\n            }\n            else {\n                return null;\n            }\n        }\n        return null;\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term or blank node,\n     * based on @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    resourceToTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const iri = context.expandTerm(key, false, this.parsingContext.getExpandOptions());\n        if (!Util.isValidIri(iri)) {\n            if (iri && this.parsingContext.strictValues) {\n                this.parsingContext.emitError(new Error(`Invalid resource IRI: ${iri}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(iri);\n    }\n    /**\n     * Convert a given JSON key to an RDF resource term.\n     * It will do this based on the @vocab,\n     * and fallback to @base.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param key A JSON key.\n     * @return {RDF.NamedNode} An RDF named node or null.\n     */\n    createVocabOrBaseTerm(context, key) {\n        if (key.startsWith('_:')) {\n            return this.dataFactory.blankNode(key.substr(2));\n        }\n        const expandOptions = this.parsingContext.getExpandOptions();\n        let expanded = context.expandTerm(key, true, expandOptions);\n        if (expanded === key) {\n            expanded = context.expandTerm(key, false, expandOptions);\n        }\n        if (!Util.isValidIri(expanded)) {\n            if (expanded && this.parsingContext.strictValues && !expanded.startsWith('@')) {\n                this.parsingContext.emitError(new Error(`Invalid term IRI: ${expanded}`));\n            }\n            else {\n                return null;\n            }\n        }\n        return this.dataFactory.namedNode(expanded);\n    }\n    /**\n     * Ensure that the given value becomes a string.\n     * @param {string | number} value A string or number.\n     * @param {NamedNode} datatype The intended datatype.\n     * @return {string} The returned string.\n     */\n    intToString(value, datatype) {\n        if (typeof value === 'number') {\n            if (Number.isFinite(value)) {\n                const isInteger = value % 1 === 0;\n                if (isInteger && (!datatype || datatype.value !== Util.XSD_DOUBLE)) {\n                    return Number(value).toString();\n                }\n                else {\n                    return value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n                }\n            }\n            else {\n                return value > 0 ? 'INF' : '-INF';\n            }\n        }\n        else {\n            return value;\n        }\n    }\n    /**\n     * Convert a given JSON string value to an RDF term.\n     * @param {number} depth The current stack depth.\n     * @param {JsonLdContextNormalized} context A JSON-LD context.\n     * @param {string} key The current JSON key.\n     * @param {string} value A JSON value.\n     * @param {NamedNode} defaultDatatype The default datatype for the given value.\n     * @return {RDF.Term} An RDF term or null.\n     */\n    stringValueToTerm(depth, context, key, value, defaultDatatype) {\n        // Check the datatype from the context\n        const contextType = Util.getContextValueType(context, key);\n        if (contextType) {\n            if (contextType === '@id') {\n                if (!defaultDatatype) {\n                    return this.resourceToTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else if (contextType === '@vocab') {\n                if (!defaultDatatype) {\n                    return this.createVocabOrBaseTerm(context, this.intToString(value, defaultDatatype));\n                }\n            }\n            else {\n                defaultDatatype = this.dataFactory.namedNode(contextType);\n            }\n        }\n        // If we don't find such a datatype, check the language from the context\n        if (!defaultDatatype) {\n            const contextLanguage = Util.getContextValueLanguage(context, key);\n            const contextDirection = Util.getContextValueDirection(context, key);\n            if (contextDirection && this.parsingContext.rdfDirection) {\n                return this.createLanguageDirectionLiteral(depth, this.intToString(value, defaultDatatype), contextLanguage, contextDirection);\n            }\n            else {\n                return this.dataFactory.literal(this.intToString(value, defaultDatatype), contextLanguage);\n            }\n        }\n        // If all else fails, make a literal based on the default content type\n        return this.dataFactory.literal(this.intToString(value, defaultDatatype), defaultDatatype);\n    }\n    /**\n     * Create a literal for the given value with the given language and direction.\n     * Auxiliary quads may be emitted.\n     * @param {number} depth The current stack depth.\n     * @param {string} value A string value.\n     * @param {string} language A language tag.\n     * @param {string} direction A direction.\n     * @return {Term} An RDF term.\n     */\n    createLanguageDirectionLiteral(depth, value, language, direction) {\n        if (this.parsingContext.rdfDirection === 'i18n-datatype') {\n            // Create a datatyped literal, by encoding the language and direction into https://www.w3.org/ns/i18n#.\n            if (!language) {\n                language = '';\n            }\n            return this.dataFactory.literal(value, this.dataFactory.namedNode(`https://www.w3.org/ns/i18n#${language}_${direction}`));\n        }\n        else {\n            // Reify the literal.\n            const valueNode = this.dataFactory.blankNode();\n            const graph = this.getDefaultGraph();\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'value'), this.dataFactory.literal(value), graph));\n            if (language) {\n                this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'language'), this.dataFactory.literal(language), graph));\n            }\n            this.parsingContext.emitQuad(depth, this.dataFactory.quad(valueNode, this.dataFactory.namedNode(Util.RDF + 'direction'), this.dataFactory.literal(direction), graph));\n            return valueNode;\n        }\n    }\n    /**\n     * Stringify the given JSON object to a canonical JSON string.\n     * @param value Any valid JSON value.\n     * @return {string} A canonical JSON string.\n     */\n    valueToJsonString(value) {\n        return canonicalizeJson(value);\n    }\n    /**\n     * If the key is not a keyword, try to check if it is an alias for a keyword,\n     * and if so, un-alias it.\n     * @param {string} key A key, can be falsy.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth to\n     * @param {boolean} disableCache If the cache should be disabled\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<string>} A promise resolving to the key itself, or another key.\n     */\n    async unaliasKeyword(key, keys, depth, disableCache, context) {\n        // Numbers can not be an alias\n        if (Number.isInteger(key)) {\n            return key;\n        }\n        // Try to grab from cache if it was already un-aliased before.\n        if (!disableCache) {\n            const cachedUnaliasedKeyword = this.parsingContext.unaliasedKeywordCacheStack[depth];\n            if (cachedUnaliasedKeyword) {\n                return cachedUnaliasedKeyword;\n            }\n        }\n        if (!jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            context = context || await this.parsingContext.getContext(keys);\n            let unliased = context.getContextRaw()[key];\n            if (unliased && typeof unliased === 'object') {\n                unliased = unliased['@id'];\n            }\n            if (jsonld_context_parser_1.Util.isValidKeyword(unliased)) {\n                key = unliased;\n            }\n        }\n        return disableCache ? key : (this.parsingContext.unaliasedKeywordCacheStack[depth] = key);\n    }\n    /**\n     * Unalias the keyword of the parent.\n     * This adds a safety check if no parent exist.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<any>} A promise resolving to the parent key, or another key.\n     */\n    async unaliasKeywordParent(keys, depth) {\n        return await this.unaliasKeyword(depth > 0 && keys[depth - 1], keys, depth - 1);\n    }\n    /**\n     * Un-alias all keywords in the given hash.\n     * @param {{[p: string]: any}} hash A hash object.\n     * @param {string[]} keys The path of keys.\n     * @param {number} depth The depth.\n     * @param {JsonLdContextNormalized} context A context to unalias with,\n     *                                           will fallback to retrieving the context for the given keys.\n     * @return {Promise<{[p: string]: any}>} A promise resolving to the new hash.\n     */\n    async unaliasKeywords(hash, keys, depth, context) {\n        const newHash = {};\n        for (const key in hash) {\n            newHash[await this.unaliasKeyword(key, keys, depth + 1, true, context)] = hash[key];\n        }\n        return newHash;\n    }\n    /**\n     * Check if we are processing a literal (including JSON literals) at the given depth.\n     * This will also check higher levels,\n     * because if a parent is a literal,\n     * then the deeper levels are definitely a literal as well.\n     * @param {number} depth The depth.\n     * @return {boolean} If we are processing a literal.\n     */\n    isLiteral(depth) {\n        for (let i = depth; i >= 0; i--) {\n            if (this.parsingContext.literalStack[i] || this.parsingContext.jsonLiteralStack[i]) {\n                return true;\n            }\n        }\n        return false;\n    }\n    /**\n     * Check how many parents should be skipped for checking the @graph for the given node.\n     *\n     * @param {number} depth The depth of the node.\n     * @param {any[]} keys An array of keys.\n     * @return {number} The graph depth offset.\n     */\n    async getDepthOffsetGraph(depth, keys) {\n        for (let i = depth - 1; i > 0; i--) {\n            if (await this.unaliasKeyword(keys[i], keys, i) === '@graph') {\n                // Skip further processing if we are already in an @graph-@id or @graph-@index container\n                const containers = (await EntryHandlerContainer_1.EntryHandlerContainer.getContainerHandler(this.parsingContext, keys, i)).containers;\n                if (EntryHandlerContainer_1.EntryHandlerContainer.isComplexGraphContainer(containers)) {\n                    return -1;\n                }\n                return depth - i - 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Check if the given subject is of a valid type.\n     * This should be called when applying @reverse'd properties.\n     * @param {Term} subject A subject.\n     */\n    validateReverseSubject(subject) {\n        if (subject.termType === 'Literal') {\n            throw new jsonld_context_parser_1.ErrorCoded(`Found illegal literal in subject position: ${subject.value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n        }\n    }\n    /**\n     * Get the default graph.\n     * @return {Term} An RDF term.\n     */\n    getDefaultGraph() {\n        return this.parsingContext.defaultGraph || this.dataFactory.defaultGraph();\n    }\n    /**\n     * Get the current graph, while taking into account a graph that can be defined via @container: @graph.\n     * If not within a graph container, the default graph will be returned.\n     * @param keys The current keys.\n     * @param depth The current depth.\n     */\n    async getGraphContainerValue(keys, depth) {\n        // Default to default graph\n        let graph = this.getDefaultGraph();\n        // Check if we are in an @container: @graph.\n        const { containers, depth: depthContainer } = await EntryHandlerContainer_1.EntryHandlerContainer\n            .getContainerHandler(this.parsingContext, keys, depth);\n        if ('@graph' in containers) {\n            // Get the graph from the stack.\n            const graphContainerIndex = EntryHandlerContainer_1.EntryHandlerContainer.getContainerGraphIndex(containers, depthContainer, keys);\n            const entry = this.parsingContext.graphContainerTermStack[depthContainer];\n            graph = entry ? entry[graphContainerIndex] : null;\n            // Set the graph in the stack if none has been set yet.\n            if (!graph) {\n                let graphId = null;\n                if ('@id' in containers) {\n                    const keyUnaliased = await this.getContainerKey(keys[depthContainer], keys, depthContainer);\n                    if (keyUnaliased !== null) {\n                        graphId = await this.resourceToTerm(await this.parsingContext.getContext(keys), keyUnaliased);\n                    }\n                }\n                if (!graphId) {\n                    graphId = this.dataFactory.blankNode();\n                }\n                if (!this.parsingContext.graphContainerTermStack[depthContainer]) {\n                    this.parsingContext.graphContainerTermStack[depthContainer] = {};\n                }\n                graph = this.parsingContext.graphContainerTermStack[depthContainer][graphContainerIndex] = graphId;\n            }\n        }\n        return graph;\n    }\n    /**\n     * Get the properties depth for retrieving properties.\n     *\n     * Typically, the properties depth will be identical to the given depth.\n     *\n     * The following exceptions apply:\n     * * When the parent is @reverse, the depth is decremented by one.\n     * * When @nest parents are found, the depth is decremented by the number of @nest parents.\n     * If in combination with the exceptions above an intermediary array is discovered,\n     * the depth is also decremented by this number of arrays.\n     *\n     * @param keys The current key chain.\n     * @param depth The current depth.\n     */\n    async getPropertiesDepth(keys, depth) {\n        let lastValidDepth = depth;\n        for (let i = depth - 1; i > 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                const parentKey = await this.unaliasKeyword(keys[i], keys, i);\n                if (parentKey === '@reverse') {\n                    return i;\n                }\n                else if (parentKey === '@nest') {\n                    lastValidDepth = i;\n                }\n                else {\n                    return lastValidDepth;\n                }\n            }\n        }\n        return lastValidDepth;\n    }\n    /**\n     * Get the key for the current container entry.\n     * @param key A key, can be falsy.\n     * @param keys The key chain.\n     * @param depth The current depth to get the key from.\n     * @return Promise resolving to the key.\n     *         Null will be returned for @none entries, with aliasing taken into account.\n     */\n    async getContainerKey(key, keys, depth) {\n        const keyUnaliased = await this.unaliasKeyword(key, keys, depth);\n        return keyUnaliased === '@none' ? null : keyUnaliased;\n    }\n}\nexports.Util = Util;\nUtil.XSD = 'http://www.w3.org/2001/XMLSchema#';\nUtil.XSD_BOOLEAN = Util.XSD + 'boolean';\nUtil.XSD_INTEGER = Util.XSD + 'integer';\nUtil.XSD_DOUBLE = Util.XSD + 'double';\nUtil.RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\n//# sourceMappingURL=Util.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIdentifier = void 0;\n/**\n * Container handler for @id.\n *\n * It assumes that the current key is the identifier of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerIdentifier {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        let id;\n        // First check if the child node already has a defined id.\n        if (parsingContext.emittedStack[depth + 1] && parsingContext.idStack[depth + 1]) {\n            // Use the existing identifier\n            id = parsingContext.idStack[depth + 1][0];\n        }\n        else {\n            // Create the identifier\n            const keyUnaliased = await util.getContainerKey(keys[depth], keys, depth);\n            const maybeId = keyUnaliased !== null\n                ? await util.resourceToTerm(await parsingContext.getContext(keys), keys[depth])\n                : util.dataFactory.blankNode();\n            // Do nothing if the id is invalid\n            if (!maybeId) {\n                parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n                return;\n            }\n            id = maybeId;\n            // Insert the id into the stack so that buffered children can make us of it.\n            parsingContext.idStack[depth + 1] = [id];\n        }\n        // Insert the id into the stack so that parents can make use of it.\n        // Insert it as an array because multiple id container entries may exist\n        let ids = parsingContext.idStack[depth];\n        if (!ids) {\n            ids = parsingContext.idStack[depth] = [];\n        }\n        // Only insert the term if it does not exist yet in the array.\n        if (!ids.some((term) => term.equals(id))) {\n            ids.push(id);\n        }\n        // Flush any pending flush buffers\n        if (!await parsingContext.handlePendingContainerFlushBuffers()) {\n            parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n        }\n    }\n}\nexports.ContainerHandlerIdentifier = ContainerHandlerIdentifier;\n//# sourceMappingURL=ContainerHandlerIdentifier.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerIndex = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @index.\n *\n * This will ignore the current key and add this entry to the parent node.\n */\nclass ContainerHandlerIndex {\n    canCombineWithGraph() {\n        return true;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            const graphContainer = '@graph' in containers;\n            // Check if the container is a property-based container by checking if there is a valid @index.\n            const context = await parsingContext.getContext(keys);\n            const indexKey = keys[depth - 1];\n            const indexPropertyRaw = Util_1.Util.getContextValueIndex(context, indexKey);\n            if (indexPropertyRaw) {\n                // Validate the @index value\n                if (jsonld_context_parser_1.Util.isPotentialKeyword(indexPropertyRaw)) {\n                    throw new jsonld_context_parser_1.ErrorCoded(`Keywords can not be used as @index value, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                if (typeof indexPropertyRaw !== 'string') {\n                    throw new jsonld_context_parser_1.ErrorCoded(`@index values must be strings, got: ${indexPropertyRaw}`, jsonld_context_parser_1.ERROR_CODES.INVALID_TERM_DEFINITION);\n                }\n                // When @index is used, values must be node values, unless @type: @id is defined in the context\n                if (typeof value !== 'object') {\n                    // Error if we don't have @type: @id\n                    if (Util_1.Util.getContextValueType(context, indexKey) !== '@id') {\n                        throw new jsonld_context_parser_1.ErrorCoded(`Property-based index containers require nodes as values or strings with @type: @id, but got: ${value}`, jsonld_context_parser_1.ERROR_CODES.INVALID_VALUE_OBJECT);\n                    }\n                    // Add an @id to the stack, so our expanded @index value can make use of it\n                    const id = util.resourceToTerm(context, value);\n                    if (id) {\n                        parsingContext.idStack[depth + 1] = [id];\n                    }\n                }\n                // Expand the @index value\n                const indexProperty = util.createVocabOrBaseTerm(context, indexPropertyRaw);\n                if (indexProperty) {\n                    const indexValues = await util.valueToTerm(context, indexPropertyRaw, await util.getContainerKey(keys[depth], keys, depth), depth, keys);\n                    if (graphContainer) {\n                        // When we're in a graph container, attach the index to the graph identifier\n                        const graphId = await util.getGraphContainerValue(keys, depth + 1);\n                        for (const indexValue of indexValues) {\n                            parsingContext.emitQuad(depth, util.dataFactory.quad(graphId, indexProperty, indexValue, util.getDefaultGraph()));\n                        }\n                    }\n                    else {\n                        // Otherwise, attach the index to the node identifier\n                        for (const indexValue of indexValues) {\n                            await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, indexProperty, indexValue, false);\n                        }\n                    }\n                }\n            }\n            const depthOffset = graphContainer ? 2 : 1;\n            await parsingContext.newOnValueJob(keys.slice(0, keys.length - depthOffset), value, depth - depthOffset, true);\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerIndex = ContainerHandlerIndex;\n//# sourceMappingURL=ContainerHandlerIndex.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerLanguage = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * Container handler for @language.\n *\n * It assumes that the current key is the language of the current value.\n * This will add this value to the parent node.\n */\nclass ContainerHandlerLanguage {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        const language = await util.getContainerKey(keys[depth], keys, depth);\n        if (Array.isArray(value)) {\n            // No type-checking needed, will be handled on each value when this handler is called recursively.\n            value = value.map((subValue) => ({ '@value': subValue, '@language': language }));\n        }\n        else {\n            if (typeof value !== 'string') {\n                throw new jsonld_context_parser_1.ErrorCoded(`Got invalid language map value, got '${JSON.stringify(value)}', but expected string`, jsonld_context_parser_1.ERROR_CODES.INVALID_LANGUAGE_MAP_VALUE);\n            }\n            value = { '@value': value, '@language': language };\n        }\n        await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n        parsingContext.emittedStack[depth] = false; // We have emitted a level higher\n    }\n}\nexports.ContainerHandlerLanguage = ContainerHandlerLanguage;\n//# sourceMappingURL=ContainerHandlerLanguage.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ContainerHandlerType = void 0;\nconst EntryHandlerPredicate_1 = require(\"../entryhandler/EntryHandlerPredicate\");\nconst Util_1 = require(\"../Util\");\n/**\n * Container handler for @type.\n *\n * This will add this entry to the parent node, and use the current key as an rdf:type value.\n */\nclass ContainerHandlerType {\n    canCombineWithGraph() {\n        return false;\n    }\n    async handle(containers, parsingContext, util, keys, value, depth) {\n        if (!Array.isArray(value)) {\n            if (typeof value === 'string') {\n                // Determine the @type of the container\n                const context = await parsingContext.getContext(keys);\n                const containerTypeType = Util_1.Util.getContextValueType(context, keys[depth - 1]);\n                // String values refer to node references\n                const id = containerTypeType === '@vocab'\n                    ? await util.createVocabOrBaseTerm(context, value)\n                    : await util.resourceToTerm(context, value);\n                if (id) {\n                    // Handle the value of this node as @id, which will also cause the predicate from above to be emitted.\n                    const subValue = { '@id': id.termType === 'NamedNode' ? id.value : value };\n                    await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), subValue, depth - 1, true);\n                    // Set the id in the stack so it can be used for the rdf:type handling later on\n                    parsingContext.idStack[depth + 1] = [id];\n                }\n            }\n            else {\n                // Other values are handled by handling them as a proper job\n                // Check needed for cases where entries don't have an explicit @id\n                const entryHasIdentifier = !!parsingContext.idStack[depth + 1];\n                // Handle the value of this node, which will also cause the predicate from above to be emitted.\n                if (!entryHasIdentifier) {\n                    delete parsingContext.idStack[depth]; // Force new (blank node) identifier\n                }\n                await parsingContext.newOnValueJob(keys.slice(0, keys.length - 1), value, depth - 1, true);\n                if (!entryHasIdentifier) {\n                    parsingContext.idStack[depth + 1] = parsingContext.idStack[depth]; // Copy the id to the child node, for @type\n                }\n            }\n            // Identify the type to emit.\n            const keyOriginal = await util.getContainerKey(keys[depth], keys, depth);\n            const type = keyOriginal !== null\n                ? util.createVocabOrBaseTerm(await parsingContext.getContext(keys), keyOriginal)\n                : null;\n            if (type) {\n                // Push the type to the stack using the rdf:type predicate\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth + 1, util.rdfType, type, false);\n            }\n            // Flush any pending flush buffers\n            await parsingContext.handlePendingContainerFlushBuffers();\n        }\n        parsingContext.emittedStack[depth] = false; // Don't emit the predicate owning this container.\n    }\n}\nexports.ContainerHandlerType = ContainerHandlerType;\n//# sourceMappingURL=ContainerHandlerType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerArrayValue = void 0;\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of an array.\n */\nclass EntryHandlerArrayValue {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return typeof keys[depth] === 'number';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        let parentKey = await util.unaliasKeywordParent(keys, depth);\n        // Check if we have an anonymous list\n        if (parentKey === '@list') {\n            // Our value is part of an array\n            // Determine the list root key\n            let listRootKey = null;\n            let listRootDepth = 0;\n            for (let i = depth - 2; i > 0; i--) {\n                const keyOption = keys[i];\n                if (typeof keyOption === 'string' || typeof keyOption === 'number') {\n                    listRootDepth = i;\n                    listRootKey = keyOption;\n                    break;\n                }\n            }\n            if (listRootKey !== null) {\n                // Emit the given objects as list elements\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), listRootKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, listRootDepth), listRootDepth);\n                }\n            }\n        }\n        else if (parentKey === '@set') {\n            // Our value is part of a set, so we just add it to the parent-parent\n            await parsingContext.newOnValueJob(keys.slice(0, -2), value, depth - 2, false);\n        }\n        else if (parentKey !== undefined && parentKey !== '@type') {\n            // Buffer our value using the parent key as predicate\n            // Determine the first parent key that is *not* an array key\n            // This is needed in case we have an @list container with nested arrays,\n            // where each of them should produce nested RDF lists.\n            for (let i = depth - 1; i > 0; i--) {\n                if (typeof keys[i] !== 'number') {\n                    parentKey = await util.unaliasKeyword(keys[i], keys, i);\n                    break;\n                }\n            }\n            // Check if the predicate is marked as an @list in the context\n            const parentContext = await parsingContext.getContext(keys.slice(0, -1));\n            if ('@list' in Util_1.Util.getContextValueContainer(parentContext, parentKey)) {\n                // Our value is part of an array\n                // Emit the given objects as list elements\n                parsingContext.emittedStack[depth + 1] = true; // Ensure the creation of bnodes for empty nodes\n                const values = await util.valueToTerm(await parsingContext.getContext(keys), parentKey, value, depth, keys);\n                for (const object of values) {\n                    await this.handleListElement(parsingContext, util, object, value, depth, keys.slice(0, -1), depth - 1);\n                }\n                // If no values were found, emit a falsy list element to force an empty RDF list to be emitted.\n                if (values.length === 0) {\n                    await this.handleListElement(parsingContext, util, null, value, depth, keys.slice(0, -1), depth - 1);\n                }\n            }\n            else {\n                // Copy the stack values up one level so that the next job can access them.\n                parsingContext.shiftStack(depth, 1);\n                // Execute the job one level higher\n                await parsingContext.newOnValueJob(keys.slice(0, -1), value, depth - 1, false);\n                // Remove any defined contexts at this level to avoid it to propagate to the next array element.\n                parsingContext.contextTree.removeContext(keys.slice(0, -1));\n            }\n        }\n    }\n    async handleListElement(parsingContext, util, value, valueOriginal, depth, listRootKeys, listRootDepth) {\n        // Buffer our value as an RDF list using the listRootKey as predicate\n        let listPointer = parsingContext.listPointerStack[depth];\n        if (valueOriginal !== null && (await util.unaliasKeywords(valueOriginal, listRootKeys, depth))['@value'] !== null) {\n            if (!listPointer || !listPointer.value) {\n                const linkTerm = util.dataFactory.blankNode();\n                listPointer = { value: linkTerm, listRootDepth, listId: linkTerm };\n            }\n            else {\n                // rdf:rest links are always emitted before the next element,\n                // as the blank node identifier is only created at that point.\n                // Because of this reason, the final rdf:nil is emitted when the stack depth is decreased.\n                const newLinkTerm = util.dataFactory.blankNode();\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfRest, newLinkTerm, util.getDefaultGraph()));\n                // Update the list pointer for the next element\n                listPointer.value = newLinkTerm;\n            }\n            // Emit a list element for the current value\n            // Omit rdf:first if the value is invalid\n            if (value) {\n                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer.value, util.rdfFirst, value, util.getDefaultGraph()));\n            }\n        }\n        else {\n            // A falsy list element if found.\n            // Mark it as an rdf:nil list until another valid list element comes in\n            if (!listPointer) {\n                listPointer = { listRootDepth, listId: util.rdfNil };\n            }\n        }\n        parsingContext.listPointerStack[depth] = listPointer;\n    }\n}\nexports.EntryHandlerArrayValue = EntryHandlerArrayValue;\n//# sourceMappingURL=EntryHandlerArrayValue.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerContainer = void 0;\nconst ContainerHandlerIdentifier_1 = require(\"../containerhandler/ContainerHandlerIdentifier\");\nconst ContainerHandlerIndex_1 = require(\"../containerhandler/ContainerHandlerIndex\");\nconst ContainerHandlerLanguage_1 = require(\"../containerhandler/ContainerHandlerLanguage\");\nconst ContainerHandlerType_1 = require(\"../containerhandler/ContainerHandlerType\");\nconst Util_1 = require(\"../Util\");\n/**\n * Handles values that are part of a container type (like @index),\n * as specified by {@link IContainerHandler}.\n */\nclass EntryHandlerContainer {\n    /**\n     * Check fit the given container is a simple @graph container.\n     * Concretely, it will check if no @index or @id is active as well.\n     * @param containers A container hash.\n     */\n    static isSimpleGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length === 2) || Object.keys(containers).length === 1);\n    }\n    /**\n     * Check fit the given container is a complex @graph container.\n     * Concretely, it will check if @index or @id is active as well next to @graph.\n     * @param containers A container hash.\n     */\n    static isComplexGraphContainer(containers) {\n        return '@graph' in containers\n            && (('@set' in containers && Object.keys(containers).length > 2)\n                || (!('@set' in containers) && Object.keys(containers).length > 1));\n    }\n    /**\n     * Create an graph container index that can be used for identifying a graph term inside the graphContainerTermStack.\n     * @param containers The applicable containers.\n     * @param depth The container depth.\n     * @param keys The array of keys.\n     * @return The graph index.\n     */\n    static getContainerGraphIndex(containers, depth, keys) {\n        let isSimpleGraphContainer = EntryHandlerContainer.isSimpleGraphContainer(containers);\n        let index = '';\n        for (let i = depth; i < keys.length; i++) {\n            if (!isSimpleGraphContainer || typeof keys[i] === 'number') {\n                index += ':' + keys[i];\n            }\n            // Only allow a second 'real' key if in a non-simple graph container.\n            if (!isSimpleGraphContainer && typeof keys[i] !== 'number') {\n                isSimpleGraphContainer = true;\n            }\n        }\n        return index;\n    }\n    /**\n     * Return the applicable container type at the given depth.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<{ containers: {[typeName: string]: boolean}, depth: number, fallback: boolean }>}\n     *          All applicable containers for the given depth,\n     *          the `depth` of the container root (can change when arrays are in the key chain),\n     *          and the `fallback` flag that indicates if the default container type was returned\n     *            (i.e., no dedicated container type is defined).\n     */\n    static async getContainerHandler(parsingContext, keys, depth) {\n        const fallback = {\n            containers: { '@set': true },\n            depth,\n            fallback: true,\n        };\n        // A flag that is enabled when @graph container should be tested in next iteration\n        let checkGraphContainer = false;\n        // Iterate from deeper to higher\n        const context = await parsingContext.getContext(keys, 2);\n        for (let i = depth - 1; i >= 0; i--) {\n            if (typeof keys[i] !== 'number') { // Skip array keys\n                // @graph containers without any other types are one level less deep, and require special handling\n                const containersSelf = Util_1.Util.getContextValue(context, '@container', keys[i], false);\n                if (containersSelf && EntryHandlerContainer.isSimpleGraphContainer(containersSelf)) {\n                    return {\n                        containers: containersSelf,\n                        depth: i + 1,\n                        fallback: false,\n                    };\n                }\n                const containersParent = Util_1.Util.getContextValue(context, '@container', keys[i - 1], false);\n                if (!containersParent) { // If we have the fallback container value\n                    if (checkGraphContainer) {\n                        // Return false if we were already expecting a @graph-@id of @graph-@index container\n                        return fallback;\n                    }\n                    // Check parent-parent, we may be in a @graph-@id of @graph-@index container, which have two levels\n                    checkGraphContainer = true;\n                }\n                else {\n                    // We had an invalid container next iteration, so we now have to check if we were in an @graph container\n                    const graphContainer = '@graph' in containersParent;\n                    // We're in a regular container\n                    for (const containerHandleName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n                        if (containersParent[containerHandleName]) {\n                            if (graphContainer) {\n                                // Only accept graph containers if their combined handlers can handle them.\n                                if (EntryHandlerContainer.CONTAINER_HANDLERS[containerHandleName].canCombineWithGraph()) {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                                else {\n                                    return fallback;\n                                }\n                            }\n                            else {\n                                // Only accept if we were not expecting a @graph-@id of @graph-@index container\n                                if (checkGraphContainer) {\n                                    return fallback;\n                                }\n                                else {\n                                    return {\n                                        containers: containersParent,\n                                        depth: i,\n                                        fallback: false,\n                                    };\n                                }\n                            }\n                        }\n                    }\n                    // Fail if no valid container handlers were found\n                    return fallback;\n                }\n            }\n        }\n        return fallback;\n    }\n    /**\n     * Check if we are handling a value at the given depth\n     * that is part of something that should be handled as a container,\n     * AND if this container should be buffered, so that it can be handled by a dedicated container handler.\n     *\n     * For instance, any container with @graph will NOT be buffered.\n     *\n     * This will ignore any arrays in the key chain.\n     *\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {any[]} keys The array of keys.\n     * @param {number} depth The current depth.\n     * @return {Promise<boolean>} If we are in the scope of a container handler.\n     */\n    static async isBufferableContainerHandler(parsingContext, keys, depth) {\n        const handler = await EntryHandlerContainer.getContainerHandler(parsingContext, keys, depth);\n        return !handler.fallback && !('@graph' in handler.containers);\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return !!await this.test(parsingContext, util, null, keys, depth);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        const containers = Util_1.Util.getContextValueContainer(await parsingContext.getContext(keys, 2), keys[depth - 1]);\n        for (const containerName in EntryHandlerContainer.CONTAINER_HANDLERS) {\n            if (containers[containerName]) {\n                return {\n                    containers,\n                    handler: EntryHandlerContainer.CONTAINER_HANDLERS[containerName],\n                };\n            }\n        }\n        return null;\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        return testResult.handler.handle(testResult.containers, parsingContext, util, keys, value, depth);\n    }\n}\nexports.EntryHandlerContainer = EntryHandlerContainer;\nEntryHandlerContainer.CONTAINER_HANDLERS = {\n    '@id': new ContainerHandlerIdentifier_1.ContainerHandlerIdentifier(),\n    '@index': new ContainerHandlerIndex_1.ContainerHandlerIndex(),\n    '@language': new ContainerHandlerLanguage_1.ContainerHandlerLanguage(),\n    '@type': new ContainerHandlerType_1.ContainerHandlerType(),\n};\n//# sourceMappingURL=EntryHandlerContainer.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerInvalidFallback = void 0;\n/**\n * A catch-all for properties, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerInvalidFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return true;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerInvalidFallback = EntryHandlerInvalidFallback;\n//# sourceMappingURL=EntryHandlerInvalidFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerPredicate = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../Util\");\n/**\n * Interprets keys as predicates.\n * The most common case in JSON-LD processing.\n */\nclass EntryHandlerPredicate {\n    /**\n     * Handle the given predicate-object by either emitting it,\n     * or by placing it in the appropriate stack for later emission when no @graph and/or @id has been defined.\n     * @param {ParsingContext} parsingContext A parsing context.\n     * @param {Util} util A utility instance.\n     * @param {any[]} keys A stack of keys.\n     * @param {number} depth The current depth.\n     * @param {Term} predicate The predicate.\n     * @param {Term} object The object.\n     * @param {boolean} reverse If the property is reversed.\n     * @return {Promise<void>} A promise resolving when handling is done.\n     */\n    static async handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse) {\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        const depthOffsetGraph = await util.getDepthOffsetGraph(depth, keys);\n        const depthPropertiesGraph = depth - depthOffsetGraph;\n        const subjects = parsingContext.idStack[depthProperties];\n        if (subjects) {\n            // Emit directly if the @id was already defined\n            for (const subject of subjects) {\n                // Check if we're in a @graph context\n                const atGraph = depthOffsetGraph >= 0;\n                if (atGraph) {\n                    const graphs = parsingContext.idStack[depthPropertiesGraph - 1];\n                    if (graphs) {\n                        for (const graph of graphs) {\n                            // Emit our quad if graph @id is known\n                            if (reverse) {\n                                util.validateReverseSubject(object);\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(object, predicate, subject, graph));\n                            }\n                            else {\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(subject, predicate, object, graph));\n                            }\n                        }\n                    }\n                    else {\n                        // Buffer our triple if graph @id is not known yet.\n                        if (reverse) {\n                            util.validateReverseSubject(object);\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1).push({ subject: object, predicate, object: subject });\n                        }\n                        else {\n                            parsingContext.getUnidentifiedGraphBufferSafe(depthPropertiesGraph - 1)\n                                .push({ subject, predicate, object });\n                        }\n                    }\n                }\n                else {\n                    // Emit if no @graph was applicable\n                    const graph = await util.getGraphContainerValue(keys, depthProperties);\n                    if (reverse) {\n                        util.validateReverseSubject(object);\n                        parsingContext.emitQuad(depth, util.dataFactory.quad(object, predicate, subject, graph));\n                    }\n                    else {\n                        parsingContext.emitQuad(depth, util.dataFactory.quad(subject, predicate, object, graph));\n                    }\n                }\n            }\n        }\n        else {\n            // Buffer until our @id becomes known, or we go up the stack\n            if (reverse) {\n                util.validateReverseSubject(object);\n            }\n            parsingContext.getUnidentifiedValueBufferSafe(depthProperties).push({ predicate, object, reverse });\n        }\n    }\n    isPropertyHandler() {\n        return true;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = keys[depth];\n        if (key) {\n            const context = await parsingContext.getContext(keys);\n            if (!parsingContext.jsonLiteralStack[depth] && await util.predicateToTerm(context, keys[depth])) {\n                // If this valid predicate is of type @json, mark it so in the stack so that no deeper handling of nodes occurs.\n                if (Util_1.Util.getContextValueType(context, key) === '@json') {\n                    parsingContext.jsonLiteralStack[depth + 1] = true;\n                }\n                return true;\n            }\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return keys[depth];\n    }\n    async handle(parsingContext, util, key, keys, value, depth, testResult) {\n        const keyOriginal = keys[depth];\n        const context = await parsingContext.getContext(keys);\n        const predicate = await util.predicateToTerm(context, key);\n        if (predicate) {\n            const objects = await util.valueToTerm(context, key, value, depth, keys);\n            if (objects.length) {\n                for (let object of objects) {\n                    const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, await util.unaliasKeywordParent(keys, depth));\n                    if (value) {\n                        // Special case if our term was defined as an @list, but does not occur in an array,\n                        // In that case we just emit it as an RDF list with a single element.\n                        const listValueContainer = '@list' in Util_1.Util.getContextValueContainer(context, key);\n                        if (listValueContainer || value['@list']) {\n                            if (((listValueContainer && !Array.isArray(value) && !value['@list'])\n                                || (value['@list'] && !Array.isArray(value['@list'])))\n                                && object !== util.rdfNil) {\n                                const listPointer = util.dataFactory.blankNode();\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfRest, util.rdfNil, util.getDefaultGraph()));\n                                parsingContext.emitQuad(depth, util.dataFactory.quad(listPointer, util.rdfFirst, object, util.getDefaultGraph()));\n                                object = listPointer;\n                            }\n                            // Lists are not allowed in @reverse'd properties\n                            if (reverse && !parsingContext.allowSubjectList) {\n                                throw new jsonld_context_parser_1.ErrorCoded(`Found illegal list value in subject position at ${key}`, jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_PROPERTY_VALUE);\n                            }\n                        }\n                    }\n                    await EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, object, reverse);\n                }\n            }\n        }\n    }\n}\nexports.EntryHandlerPredicate = EntryHandlerPredicate;\n//# sourceMappingURL=EntryHandlerPredicate.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeyword = void 0;\n/**\n * An abstract keyword entry handler.\n */\nclass EntryHandlerKeyword {\n    constructor(keyword) {\n        this.keyword = keyword;\n    }\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return key === this.keyword;\n    }\n}\nexports.EntryHandlerKeyword = EntryHandlerKeyword;\n//# sourceMappingURL=EntryHandlerKeyword.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordContext = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @context entries.\n */\nclass EntryHandlerKeywordContext extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@context');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // Error if an out-of-order context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (parsingContext.processingStack[depth]\n                || parsingContext.processingType[depth]\n                || parsingContext.idStack[depth] !== undefined)) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // Find the parent context to inherit from.\n        // We actually request a context for the current depth (with fallback to parent)\n        // because we want to take into account any property-scoped contexts that are defined for this depth.\n        const parentContext = parsingContext.getContext(keys);\n        // Set the context for this scope\n        const context = parsingContext.parseContext(value, (await parentContext).getContextRaw());\n        parsingContext.contextTree.setContext(keys.slice(0, -1), context);\n        parsingContext.emitContext(value);\n        await parsingContext.validateContext(await context);\n    }\n}\nexports.EntryHandlerKeywordContext = EntryHandlerKeywordContext;\n//# sourceMappingURL=EntryHandlerKeywordContext.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordGraph = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordGraph extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@graph');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // The current identifier identifies a graph for the deeper level.\n        parsingContext.graphStack[depth + 1] = true;\n    }\n}\nexports.EntryHandlerKeywordGraph = EntryHandlerKeywordGraph;\n//# sourceMappingURL=EntryHandlerKeywordGraph.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordId = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @id entries.\n */\nclass EntryHandlerKeywordId extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@id');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'string') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @id '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_ID_VALUE));\n        }\n        // Determine the canonical place for this id.\n        // For example, @nest parents should be ignored.\n        const depthProperties = await util.getPropertiesDepth(keys, depth);\n        // Error if an @id for this node already existed.\n        if (parsingContext.idStack[depthProperties] !== undefined) {\n            if (parsingContext.idStack[depthProperties][0].listHead) {\n                // Error if an @list was already defined for this node\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal neighbouring entries next to @list for key: '${keys[depth - 1]}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_SET_OR_LIST_OBJECT));\n            }\n            else {\n                // Otherwise, the previous id was just because of an @id entry.\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found duplicate @ids '${parsingContext\n                    .idStack[depthProperties][0].value}' and '${value}'`, jsonld_context_parser_1.ERROR_CODES.COLLIDING_KEYWORDS));\n            }\n        }\n        // Save our @id on the stack\n        parsingContext.idStack[depthProperties] = util.nullableTermToArray(await util.resourceToTerm(await parsingContext.getContext(keys), value));\n    }\n}\nexports.EntryHandlerKeywordId = EntryHandlerKeywordId;\n//# sourceMappingURL=EntryHandlerKeywordId.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordIncluded = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @included entries.\n */\nclass EntryHandlerKeywordIncluded extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@included');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @included '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        const valueUnliased = await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys));\n        if ('@value' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @value node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        if ('@list' in valueUnliased) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an illegal @included @list node '${JSON.stringify(value)}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_INCLUDED_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordIncluded = EntryHandlerKeywordIncluded;\n//# sourceMappingURL=EntryHandlerKeywordIncluded.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordNest = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @nest entries.\n */\nclass EntryHandlerKeywordNest extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@nest');\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        if (typeof value !== 'object') {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found invalid @nest entry for '${key}': '${value}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        if ('@value' in await util.unaliasKeywords(value, keys, depth, await parsingContext.getContext(keys))) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found an invalid @value node for '${key}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_NEST_VALUE));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordNest = EntryHandlerKeywordNest;\n//# sourceMappingURL=EntryHandlerKeywordNest.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordType = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\nconst Util_1 = require(\"../../Util\");\nconst EntryHandlerPredicate_1 = require(\"../EntryHandlerPredicate\");\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @graph entries.\n */\nclass EntryHandlerKeywordType extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@type');\n    }\n    isStackProcessor() {\n        return false;\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keyOriginal = keys[depth];\n        // The current identifier identifies an rdf:type predicate.\n        // But we only emit it once the node closes,\n        // as it's possible that the @type is used to identify the datatype of a literal, which we ignore here.\n        const context = await parsingContext.getContext(keys);\n        const predicate = util.rdfType;\n        const reverse = Util_1.Util.isPropertyReverse(context, keyOriginal, await util.unaliasKeywordParent(keys, depth));\n        // Handle multiple values if the value is an array\n        const elements = Array.isArray(value) ? value : [value];\n        for (const element of elements) {\n            if (typeof element !== 'string') {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Found illegal @type '${element}'`, jsonld_context_parser_1.ERROR_CODES.INVALID_TYPE_VALUE));\n            }\n            const type = util.createVocabOrBaseTerm(context, element);\n            if (type) {\n                await EntryHandlerPredicate_1.EntryHandlerPredicate.handlePredicateObject(parsingContext, util, keys, depth, predicate, type, reverse);\n            }\n        }\n        // Collect type-scoped contexts if they exist\n        let scopedContext = Promise.resolve(context);\n        let hasTypedScopedContext = false;\n        for (const element of elements.sort()) { // Spec requires lexicographical ordering\n            const typeContext = Util_1.Util.getContextValue(context, '@context', element, null);\n            if (typeContext) {\n                hasTypedScopedContext = true;\n                scopedContext = scopedContext.then((c) => parsingContext.parseContext(typeContext, c.getContextRaw()));\n            }\n        }\n        // Error if an out-of-order type-scoped context was found when support is not enabled.\n        if (parsingContext.streamingProfile\n            && (hasTypedScopedContext || !parsingContext.streamingProfileAllowOutOfOrderPlainType)\n            && (parsingContext.processingStack[depth] || parsingContext.idStack[depth])) {\n            parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded('Found an out-of-order type-scoped context, while streaming is enabled.' +\n                '(disable `streamingProfile`)', jsonld_context_parser_1.ERROR_CODES.INVALID_STREAMING_KEY_ORDER));\n        }\n        // If at least least one type-scoped context applies, set them in the tree.\n        if (hasTypedScopedContext) {\n            // Do not propagate by default\n            scopedContext = scopedContext.then((c) => {\n                if (!('@propagate' in c.getContextRaw())) {\n                    c.getContextRaw()['@propagate'] = false;\n                }\n                // Set the original context at this depth as a fallback\n                // This is needed when a context was already defined at the given depth,\n                // and this context needs to remain accessible from child nodes when propagation is disabled.\n                if (c.getContextRaw()['@propagate'] === false) {\n                    c.getContextRaw()['@__propagateFallback'] = context.getContextRaw();\n                }\n                return c;\n            });\n            // Set the new context in the context tree\n            parsingContext.contextTree.setContext(keys.slice(0, keys.length - 1), scopedContext);\n        }\n        // Flag that type has been processed at this depth\n        parsingContext.processingType[depth] = true;\n    }\n}\nexports.EntryHandlerKeywordType = EntryHandlerKeywordType;\n//# sourceMappingURL=EntryHandlerKeywordType.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordUnknownFallback = void 0;\nconst jsonld_context_parser_1 = require(\"jsonld-context-parser\");\n/**\n * A catch-all for keywords, that will either emit an error or ignore,\n * depending on whether or not the `strictValues` property is set.\n */\nclass EntryHandlerKeywordUnknownFallback {\n    isPropertyHandler() {\n        return false;\n    }\n    isStackProcessor() {\n        return true;\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        const key = await util.unaliasKeyword(keys[depth], keys, depth);\n        if (jsonld_context_parser_1.Util.isPotentialKeyword(key)) {\n            // Don't emit anything inside free-floating lists\n            if (!inProperty) {\n                if (key === '@list') {\n                    return false;\n                }\n            }\n            return true;\n        }\n        return false;\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return jsonld_context_parser_1.Util.isPotentialKeyword(key);\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        const keywordType = EntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES[key];\n        if (keywordType !== undefined) {\n            if (keywordType && typeof value !== keywordType.type) {\n                parsingContext.emitError(new jsonld_context_parser_1.ErrorCoded(`Invalid value type for '${key}' with value '${value}'`, keywordType.errorCode));\n            }\n        }\n        else if (parsingContext.strictValues) {\n            parsingContext.emitError(new Error(`Unknown keyword '${key}' with value '${value}'`));\n        }\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordUnknownFallback = EntryHandlerKeywordUnknownFallback;\nEntryHandlerKeywordUnknownFallback.VALID_KEYWORDS_TYPES = {\n    '@index': { type: 'string', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_INDEX_VALUE },\n    '@list': null,\n    '@reverse': { type: 'object', errorCode: jsonld_context_parser_1.ERROR_CODES.INVALID_REVERSE_VALUE },\n    '@set': null,\n    '@value': null,\n};\n//# sourceMappingURL=EntryHandlerKeywordUnknownFallback.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.EntryHandlerKeywordValue = void 0;\nconst EntryHandlerKeyword_1 = require(\"./EntryHandlerKeyword\");\n/**\n * Handles @value entries.\n */\nclass EntryHandlerKeywordValue extends EntryHandlerKeyword_1.EntryHandlerKeyword {\n    constructor() {\n        super('@value');\n    }\n    async validate(parsingContext, util, keys, depth, inProperty) {\n        // If this is @value, mark it so in the stack so that no deeper handling of nodes occurs.\n        const key = keys[depth];\n        if (key && !parsingContext.literalStack[depth] && await this.test(parsingContext, util, key, keys, depth)) {\n            parsingContext.literalStack[depth] = true;\n        }\n        return super.validate(parsingContext, util, keys, depth, inProperty);\n    }\n    async test(parsingContext, util, key, keys, depth) {\n        return await util.unaliasKeyword(keys[depth], keys.slice(0, keys.length - 1), depth - 1, true) === '@value';\n    }\n    async handle(parsingContext, util, key, keys, value, depth) {\n        // If the value is valid, indicate that we are processing a literal.\n        // The actual value will be determined at the parent level when the @value is part of an object,\n        // because we may want to take into account additional entries such as @language.\n        // See {@link Util.valueToTerm}\n        // Indicate that we are processing a literal, and that no later predicates should be parsed at this depth.\n        parsingContext.literalStack[depth] = true;\n        // Void any buffers that we may have accumulated up until now\n        delete parsingContext.unidentifiedValuesBuffer[depth];\n        delete parsingContext.unidentifiedGraphsBuffer[depth];\n        // Indicate that we have not emitted at this depth\n        parsingContext.emittedStack[depth] = false;\n    }\n}\nexports.EntryHandlerKeywordValue = EntryHandlerKeywordValue;\n//# sourceMappingURL=EntryHandlerKeywordValue.js.map"],"names":["DataFactory","module","exports","BlankNode","constructor","id","this","value","nextId","equals","other","termType","prototype","DefaultGraph","fromTermRaw","Literal","NamedNode","Quad","Variable","namedNode","blankNode","literal","languageOrDatatype","indexOf","variable","defaultGraph","defaultGraphInstance","triple","subject","predicate","object","quad","graph","fromTerm","original","call","fromQuad","language","datatype","stringDatatype","langStringDatatype","iri","name","Error","Sink","ParserStream","Parser","options","super","rdf","JsonLdParser","Transform","relativeIriProtocol","termCleanup","factory","term","startsWith","slice","length","quadCleanup","cleanup","input","baseIRI","context","parser","dataFactory","streamingProfile","pipe","transform","objectMode","encoding","callback","on","Object","entries","forEach","prefix","emit","err","destroy","Impl","import","output","assign","readable","__createBinding","create","o","m","k","k2","undefined","defineProperty","enumerable","get","__exportStar","p","hasOwnProperty","ContextTree","subTrees","getContext","keys","head","tail","subTree","subContext","then","depth","setContext","removeContext","path","jsonld_context_parser_1","stream_1","EntryHandlerArrayValue_1","EntryHandlerContainer_1","EntryHandlerInvalidFallback_1","EntryHandlerPredicate_1","EntryHandlerKeywordContext_1","EntryHandlerKeywordGraph_1","EntryHandlerKeywordId_1","EntryHandlerKeywordIncluded_1","EntryHandlerKeywordNest_1","EntryHandlerKeywordType_1","EntryHandlerKeywordUnknownFallback_1","EntryHandlerKeywordValue_1","ParsingContext_1","Util_1","http_link_header_1","readableObjectMode","parsingContext","ParsingContext","util","Util","jsonParser","contextJobs","typeJobs","contextAwaitingJobs","lastDepth","lastKeys","lastOnValueJob","Promise","resolve","attachJsonParserListeners","mode","static","mediaType","headers","endsWith","ErrorCoded","ERROR_CODES","LOADING_DOCUMENT_FAILED","has","key","linkHeader","parse","link","MULTIPLE_CONTEXT_LINK_HEADERS","uri","ignoreMissingContextLinkHeader","contentType","match","exec","stream","PassThrough","error","parsed","data","push","_transform","chunk","write","async","lastDepthCheck","flushStacks","listPointer","listPointerStack","rdfRest","rdfNil","getDefaultGraph","listId","listHead","idStack","listRootDepth","splice","EntryHandlerContainer","isBufferableContainerHandler","pendingContainerFlushBuffers","flushBuffer","unaliasKeyword","parentKey","unaliasKeywordParent","emittedStack","handleKey","isValidKeyword","INVALID_REVERSE_PROPERTY_MAP","inProperty","validationStack","property","i","Math","max","validationResult","validateKey","valid","isLiteral","entryHandler","ENTRY_HANDLERS","testResult","test","handle","isStackProcessor","processingStack","Array","isArray","validateValueIndexes","unaliasedKeywordCacheStack","processingType","graphStack","graphContainerTermStack","jsonLiteralStack","literalStack","subjects","valueBuffer","unidentifiedValuesBuffer","depthOffsetGraph","getDepthOffsetGraph","graphs","getGraphContainerValue","bufferedValue","reverse","emitQuad","subGraphBuffer","getUnidentifiedGraphBufferSafe","graphBuffer","unidentifiedGraphsBuffer","topLevelProperties","validate","isPropertyHandler","onValue","stack","fill","map","v","isParsingContextInner","valueJobCb","newOnValueJob","contextTree","jobs","job","executeBufferedJobs","onError","applicableTypeJobs","applicableTypeJobIds","typeJob","isPrefixArray","sortedTypeJobs","sort","job1","job2","sortedApplicableTypeJobIds","jobId","DEFAULT_PROCESSING_MODE","EntryHandlerArrayValue","EntryHandlerKeywordContext","EntryHandlerKeywordId","EntryHandlerKeywordIncluded","EntryHandlerKeywordGraph","EntryHandlerKeywordNest","EntryHandlerKeywordType","EntryHandlerKeywordValue","EntryHandlerKeywordUnknownFallback","EntryHandlerPredicate","EntryHandlerInvalidFallback","ErrorCoded_1","ContextTree_1","JsonLdParser_1","contextParser","ContextParser","documentLoader","skipValidation","skipContextValidation","produceGeneralizedRdf","allowSubjectList","processingMode","strictValues","rdfDirection","normalizeLanguageTags","streamingProfileAllowOutOfOrderPlainType","activeProcessingMode","parseFloat","rootContext","parseContext","validateContext","JsonLdContextNormalized","parentContext","ignoreProtection","activeVersion","getContextRaw","PROCESSING_MODE_CONFLICT","INVALID_VERSION_VALUE","offset","keysOriginal","contextData","getContextPropagationAware","contextRaw","contextKeyEntry","scopedContext","propagate","originalDepth","hasApplicablePropertyScopedContext","lastKey","lastKeyValue","pendingFlushBuffer","emitError","emitContext","getUnidentifiedValueBufferSafe","buffer","getExpandOptions","EXPAND_OPTIONS","shiftStack","depthOffset","deeperIdStack","allowPrefixForcing","allowPrefixNonGenDelims","allowVocabRelativeToBase","rdf_data_factory_1","canonicalizeJson","rdfFirst","RDF","rdfType","rdfJson","contextKey","fallback","entry","type","getContextValue","valueType","isContextValueReverse","isValidIri","needle","haystack","indexHashes","index","existingIndexValue","CONFLICTING_INDEXES","getContextValueType","valueToJsonString","getContextValueContainer","getContextSelfOrPropertyScoped","unaliasKeywords","val","valueLanguage","valueDirection","valueIndex","subValue","JSON","stringify","INVALID_VALUE_OBJECT","INVALID_VALUE_OBJECT_VALUE","INVALID_INDEX_VALUE","INVALID_LANGUAGE_TAGGED_VALUE","validateLanguage","INVALID_LANGUAGE_TAGGED_STRING","toLowerCase","validateDirection","nullableTermToArray","createLanguageDirectionLiteral","INVALID_TYPED_VALUE","typeTerm","createVocabOrBaseTerm","valueToTerm","INVALID_SET_OR_LIST_OBJECT","listValue","graphContainerEntries","values","resourceToTerm","stringValueToTerm","Boolean","toString","XSD_BOOLEAN","XSD_INTEGER","XSD_DOUBLE","predicateToTerm","expanded","expandTerm","substr","INVALID_IRI_MAPPING","expandOptions","intToString","Number","isFinite","isInteger","toExponential","replace","defaultDatatype","contextType","contextLanguage","getContextValueLanguage","contextDirection","getContextValueDirection","direction","valueNode","disableCache","cachedUnaliasedKeyword","isPotentialKeyword","unliased","hash","newHash","containers","getContainerHandler","isComplexGraphContainer","validateReverseSubject","INVALID_REVERSE_PROPERTY_VALUE","depthContainer","graphContainerIndex","getContainerGraphIndex","graphId","keyUnaliased","getContainerKey","lastValidDepth","XSD","ContainerHandlerIdentifier","canCombineWithGraph","maybeId","ids","some","handlePendingContainerFlushBuffers","ContainerHandlerIndex","graphContainer","indexKey","indexPropertyRaw","getContextValueIndex","INVALID_TERM_DEFINITION","indexProperty","indexValues","indexValue","handlePredicateObject","ContainerHandlerLanguage","INVALID_LANGUAGE_MAP_VALUE","ContainerHandlerType","containerTypeType","entryHasIdentifier","keyOriginal","listRootKey","keyOption","handleListElement","valueOriginal","listRootKeys","newLinkTerm","linkTerm","ContainerHandlerIdentifier_1","ContainerHandlerIndex_1","ContainerHandlerLanguage_1","ContainerHandlerType_1","isSimpleGraphContainer","checkGraphContainer","containersSelf","containersParent","containerHandleName","CONTAINER_HANDLERS","handler","containerName","depthProperties","getPropertiesDepth","depthPropertiesGraph","atGraph","objects","isPropertyReverse","listValueContainer","EntryHandlerKeyword","keyword","EntryHandlerKeyword_1","INVALID_STREAMING_KEY_ORDER","INVALID_ID_VALUE","COLLIDING_KEYWORDS","INVALID_INCLUDED_VALUE","valueUnliased","INVALID_NEST_VALUE","elements","element","INVALID_TYPE_VALUE","hasTypedScopedContext","typeContext","c","keywordType","VALID_KEYWORDS_TYPES","errorCode","INVALID_REVERSE_VALUE"],"sourceRoot":""}